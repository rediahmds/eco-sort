{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rediahmds/eco-sort/blob/main/train/train_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset"
      ],
      "metadata": {
        "id": "HYavOwVuEkGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn1Y2iaEEjhQ",
        "outputId": "2caae128-6558-4636-c579-6989b38b0c0b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download"
      ],
      "metadata": {
        "id": "oCK3f0-SFms6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "alistair_ds = kagglehub.dataset_download(\"alistairking/recyclable-and-household-waste-classification\")\n",
        "print(\"Path to dataset files:\", alistair_ds)\n",
        "\n",
        "mostafa_ds = kagglehub.dataset_download(\"mostafaabla/garbage-classification\")\n",
        "print(\"Path to dataset files:\", mostafa_ds)\n",
        "\n",
        "joe_ds = kagglehub.dataset_download(\"joebeachcapital/realwaste\")\n",
        "print(\"Path to dataset files:\", joe_ds)\n",
        "\n",
        "glhdamar_ds = kagglehub.dataset_download(\"glhdamar/new-trash-classfication-dataset\")\n",
        "print(\"Path to dataset files:\", glhdamar_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W_LNqHXEsGo",
        "outputId": "264e6aaf-f7d1-4365-dade-ddc50d6789d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/glhdamar/new-trash-classfication-dataset?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391M/391M [00:05<00:00, 68.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/glhdamar/new-trash-classfication-dataset/versions/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show directory tree"
      ],
      "metadata": {
        "id": "of2TWdqofglL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def print_directory_tree(root: Path, prefix: str = \"\"):\n",
        "    \"\"\"\n",
        "    Mencetak struktur direktori dengan tampilan seperti pohon.\n",
        "    Hanya menampilkan folder (tanpa file).\n",
        "    \"\"\"\n",
        "    subdirs = sorted([p for p in root.iterdir() if p.is_dir()])\n",
        "    for i, subdir in enumerate(subdirs):\n",
        "        connector = \"â””â”€â”€ \" if i == len(subdirs) - 1 else \"â”œâ”€â”€ \"\n",
        "        print(f\"{prefix}{connector}{subdir.name}\")\n",
        "        extension = \"    \" if i == len(subdirs) - 1 else \"â”‚   \"\n",
        "        print_directory_tree(subdir, prefix + extension)\n",
        "\n",
        "# Path ke folder utama\n",
        "alistair_path = Path(alistair_ds) / \"images\" / \"images\"\n",
        "mostafa_path = Path(mostafa_ds) / \"garbage_classification\"\n",
        "joe_path = Path(joe_ds) / \"realwaste-main\" / \"RealWaste\"\n",
        "glhdamar_path = Path(glhdamar_ds) / \"new-dataset-trash-type-v2\"\n",
        "\n",
        "# Cetak pohon direktori\n",
        "print(alistair_path.name)\n",
        "print_directory_tree(alistair_path)\n",
        "\n",
        "print(mostafa_path.name)\n",
        "print_directory_tree(mostafa_path)\n",
        "\n",
        "print(joe_path.name)\n",
        "print_directory_tree(joe_path)\n",
        "\n",
        "print(glhdamar_ds)\n",
        "print_directory_tree(glhdamar_path)\n"
      ],
      "metadata": {
        "id": "tI9mimjhfgJE",
        "outputId": "a8c6cbf8-c14a-4c0c-bd1d-aa5395efb17f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/glhdamar/new-trash-classfication-dataset/versions/3\n",
            "â”œâ”€â”€ cardboard\n",
            "â”œâ”€â”€ e-waste\n",
            "â”œâ”€â”€ glass\n",
            "â”œâ”€â”€ metal\n",
            "â”œâ”€â”€ organic\n",
            "â”œâ”€â”€ paper\n",
            "â”œâ”€â”€ plastic\n",
            "â”œâ”€â”€ textile\n",
            "â””â”€â”€ trash\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy Dataset"
      ],
      "metadata": {
        "id": "OC657aDaFl7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def copy_n_files(src_dir, dst_dir, n, randomize=False):\n",
        "    src_path = Path(src_dir)\n",
        "    dst_path = Path(dst_dir)\n",
        "\n",
        "    # Buat folder tujuan jika belum ada\n",
        "    dst_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Ambil semua file dari direktori sumber\n",
        "    all_files = [f for f in src_path.iterdir() if f.is_file()]\n",
        "\n",
        "    # Pastikan n tidak lebih besar dari jumlah file\n",
        "    n = min(n, len(all_files))\n",
        "\n",
        "    # Tentukan file mana yang akan disalin\n",
        "    if randomize:\n",
        "        files_to_copy = random.sample(all_files, n)\n",
        "    else:\n",
        "        files_to_copy = sorted(all_files)[:n]\n",
        "\n",
        "    # Copy file satu per satu\n",
        "    for file in files_to_copy:\n",
        "        shutil.copy(file, dst_path)\n",
        "        print(f\"Copied: {file.name}\")\n",
        "\n",
        "    print(f\"\\nTotal {n} files copied from '{src_dir}' to '{dst_dir}' (random: {randomize}).\")\n"
      ],
      "metadata": {
        "id": "wocD3w5HFks7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Customize Alistair Dataset"
      ],
      "metadata": {
        "id": "UI9l1d2avRO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "source_root = alistair_path\n",
        "target_root = Path(\"dataset/train\")\n",
        "target_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "class_map = {\n",
        "    \"food_waste\": \"organic\",\n",
        "    \"eggshells\": \"organic\",\n",
        "    \"coffee_grounds\": \"organic\",\n",
        "    \"tea_bags\": \"organic\",\n",
        "    \"plastic_soda_bottles\": \"plastic\",\n",
        "    \"plastic_trash_bags\": \"plastic\",\n",
        "    \"plastic_food_containers\": \"plastic\",\n",
        "    \"plastic_shopping_bags\": \"plastic\",\n",
        "    \"plastic_straws\": \"plastic\",\n",
        "    \"plastic_water_bottles\": \"plastic\",\n",
        "    \"plastic_detergent_bottles\": \"plastic\",\n",
        "    \"plastic_cup_lids\": \"plastic\",\n",
        "    \"glass_food_jars\": \"glass\",\n",
        "    \"glass_beverage_bottles\": \"glass\",\n",
        "    \"glass_cosmetic_containers\": \"glass\",\n",
        "    \"aluminum_soda_cans\": \"metal\",\n",
        "    \"aluminum_food_cans\": \"metal\",\n",
        "    \"steel_food_cans\": \"metal\",\n",
        "    \"aerosol_cans\": \"metal\",\n",
        "    \"cardboard_boxes\": \"paper\",\n",
        "    \"cardboard_packaging\": \"paper\",\n",
        "    \"magazines\": \"paper\",\n",
        "    \"newspaper\": \"paper\",\n",
        "    \"office_paper\": \"paper\",\n",
        "    \"paper_cups\": \"paper\",\n",
        "    \"styrofoam_cups\": \"styrofoam\",\n",
        "    \"styrofoam_food_containers\": \"styrofoam\",\n",
        "    \"clothing\": \"textiles\",\n",
        "    \"shoes\": \"textiles\"\n",
        "}\n",
        "\n",
        "print(\"ðŸš€ Memulai pengelompokan dataset dengan penamaan ulang...\\n\")\n",
        "\n",
        "for class_name, parent_class in class_map.items():\n",
        "    for subset in [\"default\", \"real_world\"]:\n",
        "        class_dir = source_root / class_name / subset\n",
        "        if class_dir.exists():\n",
        "            img_list = list(class_dir.glob(\"*.*\"))\n",
        "            print(f\"ðŸ“ Menyalin {len(img_list)} gambar dari '{class_name}/{subset}' ke '{parent_class}'\")\n",
        "            for i, img in enumerate(tqdm(img_list, desc=f\"{class_name}/{subset}\", leave=False)):\n",
        "                dest_dir = target_root / parent_class\n",
        "                dest_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                # Penamaan ulang\n",
        "                ext = img.suffix\n",
        "                new_name = f\"{subset}_{class_name}_{i:04d}{ext}\"\n",
        "                shutil.copy(img, dest_dir / new_name)\n",
        "\n",
        "print(\"\\nâœ… Pengelompokan selesai tanpa konflik penamaan.\")\n",
        "print(\"ðŸ“‚ Dataset tersimpan di:\", target_root.resolve())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA5K6m3NvLHI",
        "outputId": "79e2d253-443c-4df6-8433-159f2db8b23b",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Memulai pengelompokan dataset dengan penamaan ulang...\n",
            "\n",
            "ðŸ“ Menyalin 250 gambar dari 'food_waste/default' ke 'organic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'food_waste/real_world' ke 'organic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'eggshells/default' ke 'organic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'eggshells/real_world' ke 'organic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'coffee_grounds/default' ke 'organic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'coffee_grounds/real_world' ke 'organic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'tea_bags/default' ke 'organic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'tea_bags/real_world' ke 'organic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_soda_bottles/default' ke 'plastic'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_soda_bottles/real_world' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_trash_bags/default' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_trash_bags/real_world' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_food_containers/default' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_food_containers/real_world' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_shopping_bags/default' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_shopping_bags/real_world' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_straws/default' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_straws/real_world' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_water_bottles/default' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_water_bottles/real_world' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_detergent_bottles/default' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_detergent_bottles/real_world' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_cup_lids/default' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'plastic_cup_lids/real_world' ke 'plastic'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'glass_food_jars/default' ke 'glass'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'glass_food_jars/real_world' ke 'glass'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'glass_beverage_bottles/default' ke 'glass'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'glass_beverage_bottles/real_world' ke 'glass'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'glass_cosmetic_containers/default' ke 'glass'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'glass_cosmetic_containers/real_world' ke 'glass'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'aluminum_soda_cans/default' ke 'metal'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'aluminum_soda_cans/real_world' ke 'metal'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'aluminum_food_cans/default' ke 'metal'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'aluminum_food_cans/real_world' ke 'metal'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'steel_food_cans/default' ke 'metal'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'steel_food_cans/real_world' ke 'metal'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'aerosol_cans/default' ke 'metal'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'aerosol_cans/real_world' ke 'metal'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'cardboard_boxes/default' ke 'paper'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'cardboard_boxes/real_world' ke 'paper'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'cardboard_packaging/default' ke 'paper'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'cardboard_packaging/real_world' ke 'paper'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'magazines/default' ke 'paper'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'magazines/real_world' ke 'paper'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'newspaper/default' ke 'paper'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'newspaper/real_world' ke 'paper'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'office_paper/default' ke 'paper'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'office_paper/real_world' ke 'paper'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'paper_cups/default' ke 'paper'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'paper_cups/real_world' ke 'paper'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'styrofoam_cups/default' ke 'styrofoam'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'styrofoam_cups/real_world' ke 'styrofoam'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'styrofoam_food_containers/default' ke 'styrofoam'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'styrofoam_food_containers/real_world' ke 'styrofoam'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'clothing/default' ke 'textiles'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'clothing/real_world' ke 'textiles'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'shoes/default' ke 'textiles'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Menyalin 250 gambar dari 'shoes/real_world' ke 'textiles'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Pengelompokan selesai tanpa konflik penamaan.\n",
            "ðŸ“‚ Dataset tersimpan di: /content/dataset/train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {glhdamar_ds}/new-dataset-trash-type-v2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNMNyF6y8oaS",
        "outputId": "5f5a127d-8191-47b9-f151-d88519d644c1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard  glass  organic  plastic    textile\n",
            "e-waste    metal  paper    README.md  trash\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment all for first run\n",
        "\n",
        "copy_n_files(f\"{mostafa_ds}/garbage_classification/paper\", \"dataset/train/paper\", 500, randomize=True)\n",
        "copy_n_files(f\"{mostafa_ds}/garbage_classification/cardboard\", \"dataset/train/paper\", 500, randomize=True)\n",
        "\n",
        "copy_n_files(f\"{mostafa_ds}/garbage_classification/white-glass\", \"dataset/train/glass\", 600, randomize=True)\n",
        "copy_n_files(f\"{mostafa_ds}/garbage_classification/brown-glass\", \"dataset/train/glass\", 600, randomize=True)\n",
        "copy_n_files(f\"{mostafa_ds}/garbage_classification/green-glass\", \"dataset/train/glass\", 600, randomize=True)\n",
        "\n",
        "copy_n_files(f\"{mostafa_ds}/garbage_classification/clothes\", \"dataset/train/textiles\", 1500, randomize=True)\n",
        "copy_n_files(f\"{mostafa_ds}/garbage_classification/shoes\", \"dataset/train/textiles\", 1500, randomize=True)\n",
        "\n",
        "copy_n_files(f\"{mostafa_ds}/garbage_classification/metal\", \"dataset/train/metal\", 750, randomize=True)\n",
        "copy_n_files(f\"{joe_ds}/realwaste-main/RealWaste/Metal\", \"dataset/train/metal\", 750, randomize=True)\n",
        "\n",
        "copy_n_files(f\"{mostafa_ds}/garbage_classification/biological\", \"dataset/train/organic\", 980, randomize=True)\n",
        "copy_n_files(f\"{glhdamar_ds}/new-dataset-trash-type-v2/organic\", \"dataset/train/organic\", 960, randomize=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDJbvgChFdWQ",
        "outputId": "49459dba-bc0d-420b-ff9c-b9aa62f2a90d",
        "collapsed": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied: biological588.jpg\n",
            "Copied: Vegetation_210.jpg\n",
            "Copied: biological256.jpg\n",
            "Copied: Vegetation_320.jpg\n",
            "Copied: Vegetation_92.jpg\n",
            "Copied: Food Organics_145.jpg\n",
            "Copied: Vegetation_187.jpg\n",
            "Copied: biological756.jpg\n",
            "Copied: Vegetation_344.jpg\n",
            "Copied: Vegetation_39.jpg\n",
            "Copied: biological273.jpg\n",
            "Copied: biological509.jpg\n",
            "Copied: organic_008875_photo.jpg\n",
            "Copied: biological823.jpg\n",
            "Copied: biological678.jpg\n",
            "Copied: biological66.jpg\n",
            "Copied: biological973.jpg\n",
            "Copied: biological212.jpg\n",
            "Copied: organic_002456_photo.jpg\n",
            "Copied: biological52.jpg\n",
            "Copied: organic_008724_photo.jpg\n",
            "Copied: Vegetation_84.jpg\n",
            "Copied: organic_003474_photo.jpg\n",
            "Copied: Food Organics_149.jpg\n",
            "Copied: Vegetation_387.jpg\n",
            "Copied: biological118.jpg\n",
            "Copied: organic_007215_photo.jpg\n",
            "Copied: biological587.jpg\n",
            "Copied: Food Organics_208.jpg\n",
            "Copied: biological946.jpg\n",
            "Copied: biological166.jpg\n",
            "Copied: Vegetation_269.jpg\n",
            "Copied: Food Organics_369.jpg\n",
            "Copied: Vegetation_403.jpg\n",
            "Copied: biological517.jpg\n",
            "Copied: biological47.jpg\n",
            "Copied: biological217.jpg\n",
            "Copied: biological330.jpg\n",
            "Copied: organic_000476_photo.jpg\n",
            "Copied: biological371.jpg\n",
            "Copied: biological664.jpg\n",
            "Copied: biological595.jpg\n",
            "Copied: Vegetation_24.jpg\n",
            "Copied: Vegetation_55.jpg\n",
            "Copied: biological578.jpg\n",
            "Copied: Food Organics_216.jpg\n",
            "Copied: Food Organics_116.jpg\n",
            "Copied: Vegetation_212.jpg\n",
            "Copied: biological561.jpg\n",
            "Copied: organic_011480_photo.jpg\n",
            "Copied: biological351.jpg\n",
            "Copied: organic_002547_photo.jpg\n",
            "Copied: biological201.jpg\n",
            "Copied: biological931.jpg\n",
            "Copied: biological916.jpg\n",
            "Copied: organic_007623_photo.jpg\n",
            "Copied: biological938.jpg\n",
            "Copied: Food Organics_109.jpg\n",
            "Copied: Food Organics_277.jpg\n",
            "Copied: Food Organics_120.jpg\n",
            "Copied: biological5.jpg\n",
            "Copied: organic_006332_photo.jpg\n",
            "Copied: biological715.jpg\n",
            "Copied: Vegetation_266.jpg\n",
            "Copied: Vegetation_395.jpg\n",
            "Copied: biological974.jpg\n",
            "Copied: Food Organics_343.jpg\n",
            "Copied: organic_009103_photo.jpg\n",
            "Copied: Vegetation_67.jpg\n",
            "Copied: organic_004005_photo.jpg\n",
            "Copied: organic_010273_photo.jpg\n",
            "Copied: Vegetation_377.jpg\n",
            "Copied: organic_011153_photo.jpg\n",
            "Copied: Vegetation_328.jpg\n",
            "Copied: organic_007777_photo.jpg\n",
            "Copied: biological840.jpg\n",
            "Copied: Food Organics_376.jpg\n",
            "Copied: biological412.jpg\n",
            "Copied: biological945.jpg\n",
            "Copied: Vegetation_147.jpg\n",
            "Copied: biological636.jpg\n",
            "Copied: biological290.jpg\n",
            "Copied: organic_007498_photo.jpg\n",
            "Copied: biological386.jpg\n",
            "Copied: biological752.jpg\n",
            "Copied: biological103.jpg\n",
            "Copied: Food Organics_76.jpg\n",
            "Copied: Vegetation_342.jpg\n",
            "Copied: Vegetation_182.jpg\n",
            "Copied: biological319.jpg\n",
            "Copied: organic_013281_photo.jpg\n",
            "Copied: biological188.jpg\n",
            "Copied: Food Organics_403.jpg\n",
            "Copied: Vegetation_227.jpg\n",
            "Copied: biological195.jpg\n",
            "Copied: biological8.jpg\n",
            "Copied: biological537.jpg\n",
            "Copied: Vegetation_252.jpg\n",
            "Copied: Vegetation_112.jpg\n",
            "Copied: biological285.jpg\n",
            "Copied: biological531.jpg\n",
            "Copied: biological713.jpg\n",
            "Copied: Food Organics_301.jpg\n",
            "Copied: organic_003885_photo.jpg\n",
            "Copied: organic_005943_photo.jpg\n",
            "Copied: Vegetation_168.jpg\n",
            "Copied: biological436.jpg\n",
            "Copied: organic_005804_photo.jpg\n",
            "Copied: biological585.jpg\n",
            "Copied: Vegetation_89.jpg\n",
            "Copied: organic_005807_photo.jpg\n",
            "Copied: biological33.jpg\n",
            "Copied: organic_013264_photo.jpg\n",
            "Copied: Vegetation_390.jpg\n",
            "Copied: organic_005205_photo.jpg\n",
            "Copied: biological749.jpg\n",
            "Copied: Vegetation_216.jpg\n",
            "Copied: biological288.jpg\n",
            "Copied: organic_001290_photo.jpg\n",
            "Copied: organic_009464_photo.jpg\n",
            "Copied: biological128.jpg\n",
            "Copied: organic_007998_photo.jpg\n",
            "Copied: biological984.jpg\n",
            "Copied: organic_000684_photo.jpg\n",
            "Copied: Food Organics_17.jpg\n",
            "Copied: biological947.jpg\n",
            "Copied: Vegetation_198.jpg\n",
            "Copied: Vegetation_367.jpg\n",
            "Copied: organic_006030_photo.jpg\n",
            "Copied: Vegetation_88.jpg\n",
            "Copied: organic_002158_photo.jpg\n",
            "Copied: biological514.jpg\n",
            "Copied: biological451.jpg\n",
            "Copied: Vegetation_125.jpg\n",
            "Copied: Vegetation_164.jpg\n",
            "Copied: biological781.jpg\n",
            "Copied: biological771.jpg\n",
            "Copied: organic_002748_photo.jpg\n",
            "Copied: biological360.jpg\n",
            "Copied: biological602.jpg\n",
            "Copied: Food Organics_321.jpg\n",
            "Copied: organic_012328_photo.jpg\n",
            "Copied: Food Organics_391.jpg\n",
            "Copied: biological613.jpg\n",
            "Copied: biological967.jpg\n",
            "Copied: Food Organics_18.jpg\n",
            "Copied: organic_001893_photo.jpg\n",
            "Copied: biological46.jpg\n",
            "Copied: organic_012040_photo.jpg\n",
            "Copied: Vegetation_172.jpg\n",
            "Copied: Vegetation_219.jpg\n",
            "Copied: Food Organics_1.jpg\n",
            "Copied: Food Organics_315.jpg\n",
            "Copied: biological183.jpg\n",
            "Copied: biological846.jpg\n",
            "Copied: biological86.jpg\n",
            "Copied: biological557.jpg\n",
            "Copied: organic_007264_photo.jpg\n",
            "Copied: biological175.jpg\n",
            "Copied: biological158.jpg\n",
            "Copied: organic_009917_photo.jpg\n",
            "Copied: Vegetation_173.jpg\n",
            "Copied: biological564.jpg\n",
            "Copied: biological949.jpg\n",
            "Copied: biological700.jpg\n",
            "Copied: biological869.jpg\n",
            "Copied: Food Organics_207.jpg\n",
            "Copied: organic_009674_photo.jpg\n",
            "Copied: Vegetation_71.jpg\n",
            "Copied: organic_010755_photo.jpg\n",
            "Copied: biological493.jpg\n",
            "Copied: biological342.jpg\n",
            "Copied: Food Organics_196.jpg\n",
            "Copied: Vegetation_389.jpg\n",
            "Copied: Food Organics_140.jpg\n",
            "Copied: Vegetation_335.jpg\n",
            "Copied: Vegetation_373.jpg\n",
            "Copied: biological820.jpg\n",
            "Copied: biological267.jpg\n",
            "Copied: biological688.jpg\n",
            "Copied: Vegetation_417.jpg\n",
            "Copied: organic_006119_photo.jpg\n",
            "Copied: Vegetation_293.jpg\n",
            "Copied: organic_005494_photo.jpg\n",
            "Copied: biological403.jpg\n",
            "Copied: organic_000653_photo.jpg\n",
            "Copied: biological701.jpg\n",
            "Copied: biological642.jpg\n",
            "Copied: organic_006765_photo.jpg\n",
            "Copied: organic_000416_photo.jpg\n",
            "Copied: biological523.jpg\n",
            "Copied: biological114.jpg\n",
            "Copied: organic_012425_photo.jpg\n",
            "Copied: Vegetation_330.jpg\n",
            "Copied: Vegetation_331.jpg\n",
            "Copied: organic_012034_photo.jpg\n",
            "Copied: biological705.jpg\n",
            "Copied: Vegetation_73.jpg\n",
            "Copied: biological677.jpg\n",
            "Copied: Food Organics_190.jpg\n",
            "Copied: Food Organics_235.jpg\n",
            "Copied: Food Organics_353.jpg\n",
            "Copied: Food Organics_62.jpg\n",
            "Copied: biological551.jpg\n",
            "Copied: organic_004139_photo.jpg\n",
            "Copied: Food Organics_71.jpg\n",
            "Copied: biological927.jpg\n",
            "Copied: biological172.jpg\n",
            "Copied: organic_003818_photo.jpg\n",
            "Copied: organic_009911_photo.jpg\n",
            "Copied: biological142.jpg\n",
            "Copied: organic_009233_photo.jpg\n",
            "Copied: Food Organics_313.jpg\n",
            "Copied: organic_011861_photo.jpg\n",
            "Copied: organic_001934_photo.jpg\n",
            "Copied: biological44.jpg\n",
            "Copied: organic_010156_photo.jpg\n",
            "Copied: organic_013219_photo.jpg\n",
            "Copied: biological328.jpg\n",
            "Copied: Vegetation_19.jpg\n",
            "Copied: biological838.jpg\n",
            "Copied: biological454.jpg\n",
            "Copied: organic_012391_photo.jpg\n",
            "Copied: Vegetation_102.jpg\n",
            "Copied: organic_011179_photo.jpg\n",
            "Copied: biological478.jpg\n",
            "Copied: biological177.jpg\n",
            "Copied: Food Organics_66.jpg\n",
            "Copied: organic_000136_photo.jpg\n",
            "Copied: Food Organics_80.jpg\n",
            "Copied: biological461.jpg\n",
            "Copied: biological286.jpg\n",
            "Copied: organic_003123_photo.jpg\n",
            "Copied: organic_001225_photo.jpg\n",
            "Copied: biological935.jpg\n",
            "Copied: Vegetation_264.jpg\n",
            "Copied: Food Organics_97.jpg\n",
            "Copied: biological876.jpg\n",
            "Copied: biological428.jpg\n",
            "Copied: biological123.jpg\n",
            "Copied: Food Organics_243.jpg\n",
            "Copied: biological814.jpg\n",
            "Copied: biological437.jpg\n",
            "Copied: biological453.jpg\n",
            "Copied: Vegetation_160.jpg\n",
            "Copied: Vegetation_302.jpg\n",
            "Copied: organic_001441_photo.jpg\n",
            "Copied: Food Organics_43.jpg\n",
            "Copied: Food Organics_234.jpg\n",
            "Copied: biological755.jpg\n",
            "Copied: biological204.jpg\n",
            "Copied: Vegetation_148.jpg\n",
            "Copied: Vegetation_321.jpg\n",
            "Copied: biological471.jpg\n",
            "Copied: biological776.jpg\n",
            "Copied: biological484.jpg\n",
            "Copied: Food Organics_157.jpg\n",
            "Copied: biological888.jpg\n",
            "Copied: Food Organics_28.jpg\n",
            "Copied: biological689.jpg\n",
            "Copied: biological725.jpg\n",
            "Copied: biological723.jpg\n",
            "Copied: biological174.jpg\n",
            "Copied: biological227.jpg\n",
            "Copied: Vegetation_430.jpg\n",
            "Copied: organic_004867_photo.jpg\n",
            "Copied: biological718.jpg\n",
            "Copied: biological475.jpg\n",
            "Copied: biological67.jpg\n",
            "Copied: biological255.jpg\n",
            "Copied: Food Organics_121.jpg\n",
            "Copied: Food Organics_214.jpg\n",
            "Copied: Food Organics_51.jpg\n",
            "Copied: biological301.jpg\n",
            "Copied: Vegetation_305.jpg\n",
            "Copied: Food Organics_304.jpg\n",
            "Copied: Vegetation_325.jpg\n",
            "Copied: Food Organics_318.jpg\n",
            "Copied: organic_012306_photo.jpg\n",
            "Copied: organic_012151_photo.jpg\n",
            "Copied: Vegetation_267.jpg\n",
            "Copied: Vegetation_157.jpg\n",
            "Copied: biological467.jpg\n",
            "Copied: biological226.jpg\n",
            "Copied: biological879.jpg\n",
            "Copied: biological835.jpg\n",
            "Copied: biological634.jpg\n",
            "Copied: Vegetation_275.jpg\n",
            "Copied: Vegetation_194.jpg\n",
            "Copied: Food Organics_40.jpg\n",
            "Copied: organic_005344_photo.jpg\n",
            "Copied: Food Organics_338.jpg\n",
            "Copied: organic_002903_photo.jpg\n",
            "Copied: biological407.jpg\n",
            "Copied: Vegetation_402.jpg\n",
            "Copied: biological546.jpg\n",
            "Copied: biological975.jpg\n",
            "Copied: Vegetation_323.jpg\n",
            "Copied: Vegetation_211.jpg\n",
            "Copied: Food Organics_407.jpg\n",
            "Copied: biological259.jpg\n",
            "Copied: Food Organics_103.jpg\n",
            "Copied: biological566.jpg\n",
            "Copied: organic_000927_photo.jpg\n",
            "Copied: Vegetation_393.jpg\n",
            "Copied: Vegetation_418.jpg\n",
            "Copied: organic_008056_photo.jpg\n",
            "Copied: Vegetation_284.jpg\n",
            "Copied: biological254.jpg\n",
            "Copied: biological743.jpg\n",
            "Copied: Vegetation_62.jpg\n",
            "Copied: Food Organics_258.jpg\n",
            "Copied: organic_007140_photo.jpg\n",
            "Copied: Vegetation_368.jpg\n",
            "Copied: biological162.jpg\n",
            "Copied: Food Organics_22.jpg\n",
            "Copied: biological146.jpg\n",
            "Copied: organic_008113_photo.jpg\n",
            "Copied: Vegetation_326.jpg\n",
            "Copied: Food Organics_168.jpg\n",
            "Copied: Vegetation_369.jpg\n",
            "Copied: Food Organics_182.jpg\n",
            "Copied: Food Organics_34.jpg\n",
            "Copied: biological98.jpg\n",
            "Copied: biological19.jpg\n",
            "Copied: biological27.jpg\n",
            "Copied: organic_003080_photo.jpg\n",
            "Copied: organic_009952_photo.jpg\n",
            "Copied: Vegetation_90.jpg\n",
            "Copied: Food Organics_124.jpg\n",
            "Copied: organic_012587_photo.jpg\n",
            "Copied: organic_010124_photo.jpg\n",
            "Copied: Vegetation_205.jpg\n",
            "Copied: Vegetation_381.jpg\n",
            "Copied: biological971.jpg\n",
            "Copied: biological770.jpg\n",
            "Copied: biological258.jpg\n",
            "Copied: biological801.jpg\n",
            "Copied: organic_005199_photo.jpg\n",
            "Copied: biological353.jpg\n",
            "Copied: biological440.jpg\n",
            "Copied: Food Organics_280.jpg\n",
            "Copied: biological167.jpg\n",
            "Copied: biological383.jpg\n",
            "Copied: biological625.jpg\n",
            "Copied: Food Organics_35.jpg\n",
            "Copied: Vegetation_242.jpg\n",
            "Copied: Food Organics_133.jpg\n",
            "Copied: organic_003369_photo.jpg\n",
            "Copied: Food Organics_281.jpg\n",
            "Copied: biological902.jpg\n",
            "Copied: biological363.jpg\n",
            "Copied: biological180.jpg\n",
            "Copied: biological940.jpg\n",
            "Copied: Food Organics_309.jpg\n",
            "Copied: organic_006879_photo.jpg\n",
            "Copied: biological29.jpg\n",
            "Copied: biological110.jpg\n",
            "Copied: biological370.jpg\n",
            "Copied: biological932.jpg\n",
            "Copied: biological151.jpg\n",
            "Copied: Food Organics_46.jpg\n",
            "Copied: Food Organics_49.jpg\n",
            "Copied: Vegetation_58.jpg\n",
            "Copied: biological881.jpg\n",
            "Copied: Food Organics_23.jpg\n",
            "Copied: organic_000074_photo.jpg\n",
            "Copied: biological343.jpg\n",
            "Copied: Vegetation_309.jpg\n",
            "Copied: biological524.jpg\n",
            "Copied: biological117.jpg\n",
            "Copied: Vegetation_295.jpg\n",
            "Copied: biological839.jpg\n",
            "Copied: biological550.jpg\n",
            "Copied: biological702.jpg\n",
            "Copied: Vegetation_346.jpg\n",
            "Copied: Vegetation_324.jpg\n",
            "Copied: Food Organics_333.jpg\n",
            "Copied: Vegetation_416.jpg\n",
            "Copied: biological889.jpg\n",
            "Copied: biological448.jpg\n",
            "Copied: biological533.jpg\n",
            "Copied: biological852.jpg\n",
            "Copied: Vegetation_50.jpg\n",
            "Copied: organic_002836_photo.jpg\n",
            "Copied: Vegetation_175.jpg\n",
            "Copied: organic_004279_photo.jpg\n",
            "Copied: Vegetation_97.jpg\n",
            "Copied: biological917.jpg\n",
            "Copied: biological704.jpg\n",
            "Copied: biological854.jpg\n",
            "Copied: biological980.jpg\n",
            "Copied: Food Organics_19.jpg\n",
            "Copied: Food Organics_25.jpg\n",
            "Copied: biological304.jpg\n",
            "Copied: biological455.jpg\n",
            "Copied: Food Organics_349.jpg\n",
            "Copied: organic_005379_photo.jpg\n",
            "Copied: Food Organics_213.jpg\n",
            "Copied: Vegetation_146.jpg\n",
            "Copied: Vegetation_1.jpg\n",
            "Copied: Food Organics_295.jpg\n",
            "Copied: biological866.jpg\n",
            "Copied: biological501.jpg\n",
            "Copied: Vegetation_119.jpg\n",
            "Copied: biological221.jpg\n",
            "Copied: organic_006717_photo.jpg\n",
            "Copied: Food Organics_221.jpg\n",
            "Copied: biological849.jpg\n",
            "Copied: organic_003504_photo.jpg\n",
            "Copied: biological668.jpg\n",
            "Copied: Food Organics_217.jpg\n",
            "Copied: biological241.jpg\n",
            "Copied: biological508.jpg\n",
            "Copied: biological584.jpg\n",
            "Copied: Food Organics_319.jpg\n",
            "Copied: biological599.jpg\n",
            "Copied: organic_002367_photo.jpg\n",
            "Copied: biological764.jpg\n",
            "Copied: Vegetation_196.jpg\n",
            "Copied: biological400.jpg\n",
            "Copied: Vegetation_422.jpg\n",
            "Copied: organic_000867_photo.jpg\n",
            "Copied: biological35.jpg\n",
            "Copied: biological225.jpg\n",
            "Copied: organic_004769_photo.jpg\n",
            "Copied: Food Organics_52.jpg\n",
            "Copied: biological766.jpg\n",
            "Copied: biological809.jpg\n",
            "Copied: biological831.jpg\n",
            "Copied: organic_001334_photo.jpg\n",
            "Copied: biological24.jpg\n",
            "Copied: organic_005046_photo.jpg\n",
            "Copied: biological657.jpg\n",
            "Copied: biological644.jpg\n",
            "Copied: organic_010992_photo.jpg\n",
            "Copied: biological237.jpg\n",
            "Copied: biological338.jpg\n",
            "Copied: Food Organics_327.jpg\n",
            "Copied: biological822.jpg\n",
            "Copied: Food Organics_383.jpg\n",
            "Copied: organic_001899_photo.jpg\n",
            "Copied: biological468.jpg\n",
            "Copied: organic_006417_photo.jpg\n",
            "Copied: biological834.jpg\n",
            "Copied: biological306.jpg\n",
            "Copied: biological73.jpg\n",
            "Copied: biological432.jpg\n",
            "Copied: organic_012818_photo.jpg\n",
            "Copied: biological522.jpg\n",
            "Copied: Vegetation_375.jpg\n",
            "Copied: biological842.jpg\n",
            "Copied: biological211.jpg\n",
            "Copied: Food Organics_394.jpg\n",
            "Copied: biological694.jpg\n",
            "Copied: organic_012482_photo.jpg\n",
            "Copied: organic_001685_photo.jpg\n",
            "Copied: biological619.jpg\n",
            "Copied: Food Organics_378.jpg\n",
            "Copied: organic_010705_photo.jpg\n",
            "Copied: Vegetation_149.jpg\n",
            "Copied: Vegetation_77.jpg\n",
            "Copied: biological91.jpg\n",
            "Copied: organic_003419_photo.jpg\n",
            "Copied: biological295.jpg\n",
            "Copied: biological500.jpg\n",
            "Copied: Vegetation_139.jpg\n",
            "Copied: organic_010342_photo.jpg\n",
            "Copied: biological897.jpg\n",
            "Copied: Food Organics_159.jpg\n",
            "Copied: biological315.jpg\n",
            "Copied: organic_001863_photo.jpg\n",
            "Copied: biological965.jpg\n",
            "Copied: Vegetation_66.jpg\n",
            "Copied: organic_012272_photo.jpg\n",
            "Copied: biological806.jpg\n",
            "Copied: Food Organics_164.jpg\n",
            "Copied: biological729.jpg\n",
            "Copied: biological186.jpg\n",
            "Copied: organic_005012_photo.jpg\n",
            "Copied: biological646.jpg\n",
            "Copied: biological580.jpg\n",
            "Copied: Vegetation_179.jpg\n",
            "Copied: biological275.jpg\n",
            "Copied: biological55.jpg\n",
            "Copied: Vegetation_104.jpg\n",
            "Copied: Vegetation_159.jpg\n",
            "Copied: organic_003837_photo.jpg\n",
            "Copied: Vegetation_391.jpg\n",
            "Copied: biological187.jpg\n",
            "Copied: Food Organics_132.jpg\n",
            "Copied: Vegetation_200.jpg\n",
            "Copied: Vegetation_413.jpg\n",
            "Copied: biological182.jpg\n",
            "Copied: organic_007271_photo.jpg\n",
            "Copied: biological717.jpg\n",
            "Copied: organic_008981_photo.jpg\n",
            "Copied: organic_004159_photo.jpg\n",
            "Copied: biological302.jpg\n",
            "Copied: Vegetation_91.jpg\n",
            "Copied: biological414.jpg\n",
            "Copied: Food Organics_178.jpg\n",
            "Copied: biological108.jpg\n",
            "Copied: biological505.jpg\n",
            "Copied: biological699.jpg\n",
            "Copied: Food Organics_283.jpg\n",
            "Copied: biological908.jpg\n",
            "Copied: organic_006088_photo.jpg\n",
            "Copied: organic_011519_photo.jpg\n",
            "Copied: Food Organics_179.jpg\n",
            "Copied: biological950.jpg\n",
            "Copied: biological955.jpg\n",
            "Copied: biological603.jpg\n",
            "Copied: biological296.jpg\n",
            "Copied: biological378.jpg\n",
            "Copied: organic_011770_photo.jpg\n",
            "Copied: Vegetation_300.jpg\n",
            "Copied: biological905.jpg\n",
            "Copied: Vegetation_345.jpg\n",
            "Copied: organic_006758_photo.jpg\n",
            "Copied: biological788.jpg\n",
            "Copied: biological589.jpg\n",
            "Copied: biological525.jpg\n",
            "Copied: organic_004411_photo.jpg\n",
            "Copied: organic_007677_photo.jpg\n",
            "Copied: Food Organics_24.jpg\n",
            "Copied: Food Organics_14.jpg\n",
            "Copied: biological765.jpg\n",
            "Copied: biological470.jpg\n",
            "Copied: biological983.jpg\n",
            "Copied: Food Organics_380.jpg\n",
            "Copied: biological539.jpg\n",
            "Copied: biological57.jpg\n",
            "Copied: biological26.jpg\n",
            "Copied: Food Organics_169.jpg\n",
            "Copied: biological953.jpg\n",
            "Copied: biological325.jpg\n",
            "Copied: biological488.jpg\n",
            "Copied: biological77.jpg\n",
            "Copied: organic_003357_photo.jpg\n",
            "Copied: organic_004082_photo.jpg\n",
            "Copied: organic_002156_photo.jpg\n",
            "Copied: biological811.jpg\n",
            "Copied: biological43.jpg\n",
            "Copied: Vegetation_152.jpg\n",
            "Copied: Vegetation_106.jpg\n",
            "Copied: biological648.jpg\n",
            "Copied: Vegetation_141.jpg\n",
            "Copied: biological721.jpg\n",
            "Copied: biological982.jpg\n",
            "Copied: Food Organics_176.jpg\n",
            "Copied: organic_002053_photo.jpg\n",
            "Copied: Vegetation_27.jpg\n",
            "Copied: organic_011188_photo.jpg\n",
            "Copied: biological152.jpg\n",
            "Copied: Vegetation_419.jpg\n",
            "Copied: Food Organics_401.jpg\n",
            "Copied: Food Organics_311.jpg\n",
            "Copied: organic_005460_photo.jpg\n",
            "Copied: Food Organics_357.jpg\n",
            "Copied: Food Organics_111.jpg\n",
            "Copied: Vegetation_158.jpg\n",
            "Copied: organic_006269_photo.jpg\n",
            "Copied: biological389.jpg\n",
            "Copied: Vegetation_176.jpg\n",
            "Copied: biological143.jpg\n",
            "Copied: Vegetation_288.jpg\n",
            "Copied: biological577.jpg\n",
            "Copied: Vegetation_135.jpg\n",
            "Copied: organic_013462_photo.jpg\n",
            "Copied: Vegetation_297.jpg\n",
            "Copied: Vegetation_399.jpg\n",
            "Copied: Vegetation_70.jpg\n",
            "Copied: Vegetation_15.jpg\n",
            "Copied: Food Organics_316.jpg\n",
            "Copied: organic_006421_photo.jpg\n",
            "Copied: biological473.jpg\n",
            "Copied: organic_013452_photo.jpg\n",
            "Copied: organic_009099_photo.jpg\n",
            "Copied: Food Organics_114.jpg\n",
            "Copied: biological297.jpg\n",
            "Copied: organic_004301_photo.jpg\n",
            "Copied: Vegetation_123.jpg\n",
            "Copied: Vegetation_45.jpg\n",
            "Copied: biological614.jpg\n",
            "Copied: biological272.jpg\n",
            "Copied: biological761.jpg\n",
            "Copied: biological277.jpg\n",
            "Copied: biological216.jpg\n",
            "Copied: biological875.jpg\n",
            "Copied: biological41.jpg\n",
            "Copied: biological289.jpg\n",
            "Copied: Food Organics_337.jpg\n",
            "Copied: Food Organics_171.jpg\n",
            "Copied: biological492.jpg\n",
            "Copied: organic_013413_photo.jpg\n",
            "Copied: Food Organics_366.jpg\n",
            "Copied: Vegetation_145.jpg\n",
            "Copied: Vegetation_308.jpg\n",
            "Copied: biological64.jpg\n",
            "Copied: biological507.jpg\n",
            "Copied: Vegetation_238.jpg\n",
            "Copied: biological547.jpg\n",
            "Copied: Food Organics_228.jpg\n",
            "Copied: biological631.jpg\n",
            "Copied: biological844.jpg\n",
            "Copied: biological608.jpg\n",
            "Copied: biological395.jpg\n",
            "Copied: Food Organics_8.jpg\n",
            "Copied: biological937.jpg\n",
            "Copied: Food Organics_388.jpg\n",
            "Copied: Vegetation_374.jpg\n",
            "Copied: biological375.jpg\n",
            "Copied: biological411.jpg\n",
            "Copied: organic_010171_photo.jpg\n",
            "Copied: biological14.jpg\n",
            "Copied: Vegetation_226.jpg\n",
            "Copied: organic_009890_photo.jpg\n",
            "Copied: Vegetation_423.jpg\n",
            "Copied: Food Organics_308.jpg\n",
            "Copied: biological921.jpg\n",
            "Copied: biological50.jpg\n",
            "Copied: organic_001994_photo.jpg\n",
            "Copied: biological209.jpg\n",
            "Copied: biological367.jpg\n",
            "Copied: biological922.jpg\n",
            "Copied: Vegetation_349.jpg\n",
            "Copied: biological964.jpg\n",
            "Copied: organic_005245_photo.jpg\n",
            "Copied: Vegetation_174.jpg\n",
            "Copied: Food Organics_58.jpg\n",
            "Copied: Vegetation_392.jpg\n",
            "Copied: Food Organics_84.jpg\n",
            "Copied: organic_007681_photo.jpg\n",
            "Copied: biological572.jpg\n",
            "Copied: biological230.jpg\n",
            "Copied: Food Organics_50.jpg\n",
            "Copied: Food Organics_259.jpg\n",
            "Copied: Food Organics_255.jpg\n",
            "Copied: Vegetation_201.jpg\n",
            "Copied: Food Organics_278.jpg\n",
            "Copied: Vegetation_404.jpg\n",
            "Copied: Vegetation_140.jpg\n",
            "Copied: Vegetation_414.jpg\n",
            "Copied: biological261.jpg\n",
            "Copied: organic_011782_photo.jpg\n",
            "Copied: Food Organics_352.jpg\n",
            "Copied: Food Organics_368.jpg\n",
            "Copied: Vegetation_246.jpg\n",
            "Copied: Vegetation_9.jpg\n",
            "Copied: biological51.jpg\n",
            "Copied: organic_003223_photo.jpg\n",
            "Copied: biological499.jpg\n",
            "Copied: Food Organics_400.jpg\n",
            "Copied: Food Organics_355.jpg\n",
            "Copied: biological732.jpg\n",
            "Copied: Vegetation_261.jpg\n",
            "Copied: biological189.jpg\n",
            "Copied: organic_007544_photo.jpg\n",
            "Copied: Vegetation_336.jpg\n",
            "Copied: biological612.jpg\n",
            "Copied: Food Organics_293.jpg\n",
            "Copied: Vegetation_409.jpg\n",
            "Copied: organic_012236_photo.jpg\n",
            "Copied: biological369.jpg\n",
            "Copied: Food Organics_91.jpg\n",
            "Copied: biological310.jpg\n",
            "Copied: organic_001703_photo.jpg\n",
            "Copied: biological640.jpg\n",
            "Copied: organic_011442_photo.jpg\n",
            "Copied: Food Organics_300.jpg\n",
            "Copied: Food Organics_142.jpg\n",
            "Copied: biological837.jpg\n",
            "Copied: Vegetation_248.jpg\n",
            "Copied: organic_006002_photo.jpg\n",
            "Copied: Vegetation_247.jpg\n",
            "Copied: biological445.jpg\n",
            "Copied: Vegetation_257.jpg\n",
            "Copied: Vegetation_167.jpg\n",
            "Copied: biological144.jpg\n",
            "Copied: Food Organics_395.jpg\n",
            "Copied: biological157.jpg\n",
            "Copied: biological799.jpg\n",
            "Copied: biological356.jpg\n",
            "Copied: biological830.jpg\n",
            "Copied: Vegetation_190.jpg\n",
            "Copied: Vegetation_5.jpg\n",
            "Copied: Vegetation_235.jpg\n",
            "Copied: Vegetation_262.jpg\n",
            "Copied: Food Organics_56.jpg\n",
            "Copied: organic_012101_photo.jpg\n",
            "Copied: Food Organics_220.jpg\n",
            "Copied: Vegetation_209.jpg\n",
            "Copied: Vegetation_353.jpg\n",
            "Copied: Vegetation_274.jpg\n",
            "Copied: Food Organics_284.jpg\n",
            "Copied: biological229.jpg\n",
            "Copied: biological449.jpg\n",
            "Copied: Vegetation_362.jpg\n",
            "Copied: Food Organics_191.jpg\n",
            "Copied: Vegetation_364.jpg\n",
            "Copied: organic_003108_photo.jpg\n",
            "Copied: Vegetation_180.jpg\n",
            "Copied: Food Organics_323.jpg\n",
            "Copied: biological620.jpg\n",
            "Copied: Food Organics_242.jpg\n",
            "Copied: biological176.jpg\n",
            "Copied: biological464.jpg\n",
            "Copied: organic_012144_photo.jpg\n",
            "Copied: organic_011573_photo.jpg\n",
            "Copied: organic_005407_photo.jpg\n",
            "Copied: organic_009003_photo.jpg\n",
            "Copied: Food Organics_375.jpg\n",
            "Copied: Vegetation_255.jpg\n",
            "Copied: biological45.jpg\n",
            "Copied: Vegetation_208.jpg\n",
            "Copied: Vegetation_80.jpg\n",
            "Copied: Vegetation_314.jpg\n",
            "Copied: organic_006404_photo.jpg\n",
            "Copied: Vegetation_186.jpg\n",
            "Copied: organic_011252_photo.jpg\n",
            "Copied: Food Organics_156.jpg\n",
            "Copied: biological883.jpg\n",
            "Copied: Food Organics_137.jpg\n",
            "Copied: organic_003292_photo.jpg\n",
            "Copied: biological10.jpg\n",
            "Copied: biological447.jpg\n",
            "Copied: biological780.jpg\n",
            "Copied: organic_000999_photo.jpg\n",
            "Copied: organic_011659_photo.jpg\n",
            "Copied: biological495.jpg\n",
            "Copied: Vegetation_37.jpg\n",
            "Copied: biological213.jpg\n",
            "Copied: Vegetation_429.jpg\n",
            "Copied: Food Organics_292.jpg\n",
            "Copied: Food Organics_405.jpg\n",
            "Copied: biological506.jpg\n",
            "Copied: biological481.jpg\n",
            "Copied: organic_008878_photo.jpg\n",
            "Copied: biological554.jpg\n",
            "Copied: Food Organics_364.jpg\n",
            "Copied: organic_008455_photo.jpg\n",
            "Copied: Food Organics_263.jpg\n",
            "Copied: Food Organics_201.jpg\n",
            "Copied: biological503.jpg\n",
            "Copied: biological270.jpg\n",
            "Copied: Vegetation_388.jpg\n",
            "Copied: organic_007791_photo.jpg\n",
            "Copied: organic_005434_photo.jpg\n",
            "Copied: organic_007793_photo.jpg\n",
            "Copied: Vegetation_101.jpg\n",
            "Copied: Food Organics_398.jpg\n",
            "Copied: Food Organics_265.jpg\n",
            "Copied: Vegetation_378.jpg\n",
            "Copied: biological617.jpg\n",
            "Copied: biological89.jpg\n",
            "Copied: organic_002607_photo.jpg\n",
            "Copied: biological214.jpg\n",
            "Copied: biological240.jpg\n",
            "Copied: Vegetation_195.jpg\n",
            "Copied: Food Organics_197.jpg\n",
            "Copied: organic_005312_photo.jpg\n",
            "Copied: biological104.jpg\n",
            "Copied: biological111.jpg\n",
            "Copied: biological127.jpg\n",
            "Copied: biological511.jpg\n",
            "Copied: biological661.jpg\n",
            "Copied: biological841.jpg\n",
            "Copied: organic_010503_photo.jpg\n",
            "Copied: biological969.jpg\n",
            "Copied: Food Organics_5.jpg\n",
            "Copied: Food Organics_253.jpg\n",
            "Copied: Vegetation_278.jpg\n",
            "Copied: biological528.jpg\n",
            "Copied: biological265.jpg\n",
            "Copied: biological129.jpg\n",
            "Copied: Food Organics_312.jpg\n",
            "Copied: organic_007963_photo.jpg\n",
            "Copied: biological210.jpg\n",
            "Copied: biological452.jpg\n",
            "Copied: biological687.jpg\n",
            "Copied: Food Organics_11.jpg\n",
            "Copied: Vegetation_178.jpg\n",
            "Copied: Food Organics_279.jpg\n",
            "Copied: organic_003288_photo.jpg\n",
            "Copied: Vegetation_270.jpg\n",
            "Copied: organic_001569_photo.jpg\n",
            "Copied: organic_005004_photo.jpg\n",
            "Copied: biological943.jpg\n",
            "Copied: biological563.jpg\n",
            "Copied: organic_008910_photo.jpg\n",
            "Copied: biological754.jpg\n",
            "Copied: Vegetation_76.jpg\n",
            "Copied: biological803.jpg\n",
            "Copied: biological184.jpg\n",
            "Copied: Vegetation_18.jpg\n",
            "Copied: biological132.jpg\n",
            "Copied: organic_010698_photo.jpg\n",
            "Copied: organic_012954_photo.jpg\n",
            "Copied: Food Organics_105.jpg\n",
            "Copied: organic_010678_photo.jpg\n",
            "Copied: biological137.jpg\n",
            "Copied: organic_013824_photo.jpg\n",
            "Copied: biological446.jpg\n",
            "Copied: biological675.jpg\n",
            "Copied: biological855.jpg\n",
            "Copied: organic_007530_photo.jpg\n",
            "Copied: Vegetation_79.jpg\n",
            "Copied: biological918.jpg\n",
            "Copied: biological753.jpg\n",
            "Copied: biological426.jpg\n",
            "Copied: biological920.jpg\n",
            "Copied: biological970.jpg\n",
            "Copied: biological966.jpg\n",
            "Copied: biological692.jpg\n",
            "Copied: biological246.jpg\n",
            "Copied: Food Organics_267.jpg\n",
            "Copied: biological220.jpg\n",
            "Copied: Vegetation_3.jpg\n",
            "Copied: Food Organics_241.jpg\n",
            "Copied: biological556.jpg\n",
            "Copied: organic_013328_photo.jpg\n",
            "Copied: Vegetation_380.jpg\n",
            "Copied: Vegetation_47.jpg\n",
            "Copied: biological291.jpg\n",
            "Copied: organic_002058_photo.jpg\n",
            "Copied: Food Organics_55.jpg\n",
            "Copied: Vegetation_304.jpg\n",
            "Copied: Vegetation_313.jpg\n",
            "Copied: Food Organics_360.jpg\n",
            "Copied: Vegetation_214.jpg\n",
            "Copied: Vegetation_56.jpg\n",
            "Copied: biological42.jpg\n",
            "Copied: Food Organics_165.jpg\n",
            "Copied: Food Organics_317.jpg\n",
            "Copied: Food Organics_410.jpg\n",
            "Copied: Food Organics_354.jpg\n",
            "Copied: Food Organics_166.jpg\n",
            "Copied: biological570.jpg\n",
            "Copied: Vegetation_17.jpg\n",
            "Copied: biological590.jpg\n",
            "Copied: biological458.jpg\n",
            "Copied: organic_006907_photo.jpg\n",
            "Copied: Food Organics_147.jpg\n",
            "Copied: biological479.jpg\n",
            "Copied: Food Organics_389.jpg\n",
            "Copied: biological610.jpg\n",
            "Copied: Vegetation_400.jpg\n",
            "Copied: biological663.jpg\n",
            "Copied: Vegetation_237.jpg\n",
            "Copied: biological759.jpg\n",
            "Copied: biological365.jpg\n",
            "Copied: biological125.jpg\n",
            "Copied: Food Organics_249.jpg\n",
            "Copied: biological346.jpg\n",
            "Copied: organic_013823_photo.jpg\n",
            "Copied: organic_008302_photo.jpg\n",
            "Copied: Vegetation_407.jpg\n",
            "Copied: biological748.jpg\n",
            "Copied: Vegetation_138.jpg\n",
            "Copied: biological535.jpg\n",
            "Copied: biological956.jpg\n",
            "Copied: biological434.jpg\n",
            "Copied: Food Organics_65.jpg\n",
            "Copied: organic_013502_photo.jpg\n",
            "Copied: biological656.jpg\n",
            "Copied: biological156.jpg\n",
            "Copied: Food Organics_336.jpg\n",
            "Copied: Food Organics_79.jpg\n",
            "Copied: organic_001401_photo.jpg\n",
            "Copied: biological242.jpg\n",
            "Copied: biological736.jpg\n",
            "Copied: organic_002225_photo.jpg\n",
            "Copied: Food Organics_351.jpg\n",
            "Copied: Vegetation_233.jpg\n",
            "Copied: Food Organics_94.jpg\n",
            "Copied: organic_000243_photo.jpg\n",
            "Copied: biological549.jpg\n",
            "Copied: biological439.jpg\n",
            "Copied: Food Organics_3.jpg\n",
            "Copied: biological382.jpg\n",
            "Copied: Vegetation_54.jpg\n",
            "Copied: biological280.jpg\n",
            "Copied: Food Organics_129.jpg\n",
            "Copied: biological527.jpg\n",
            "Copied: Food Organics_37.jpg\n",
            "Copied: Food Organics_298.jpg\n",
            "Copied: Food Organics_212.jpg\n",
            "Copied: organic_004778_photo.jpg\n",
            "Copied: organic_007435_photo.jpg\n",
            "Copied: Vegetation_165.jpg\n",
            "Copied: biological253.jpg\n",
            "Copied: Vegetation_386.jpg\n",
            "Copied: organic_010745_photo.jpg\n",
            "Copied: biological567.jpg\n",
            "Copied: Vegetation_291.jpg\n",
            "Copied: Food Organics_306.jpg\n",
            "Copied: Food Organics_331.jpg\n",
            "Copied: biological311.jpg\n",
            "Copied: organic_001757_photo.jpg\n",
            "Copied: biological887.jpg\n",
            "Copied: organic_007137_photo.jpg\n",
            "Copied: Food Organics_21.jpg\n",
            "Copied: biological373.jpg\n",
            "Copied: Food Organics_141.jpg\n",
            "Copied: organic_003331_photo.jpg\n",
            "Copied: organic_002264_photo.jpg\n",
            "Copied: biological775.jpg\n",
            "Copied: biological860.jpg\n",
            "Copied: biological84.jpg\n",
            "Copied: biological890.jpg\n",
            "Copied: Vegetation_72.jpg\n",
            "Copied: biological92.jpg\n",
            "Copied: organic_005290_photo.jpg\n",
            "Copied: organic_003221_photo.jpg\n",
            "Copied: biological364.jpg\n",
            "Copied: biological726.jpg\n",
            "Copied: Vegetation_7.jpg\n",
            "Copied: Food Organics_209.jpg\n",
            "Copied: biological760.jpg\n",
            "Copied: organic_012187_photo.jpg\n",
            "Copied: biological958.jpg\n",
            "Copied: organic_012999_photo.jpg\n",
            "Copied: Food Organics_294.jpg\n",
            "Copied: biological856.jpg\n",
            "Copied: Food Organics_219.jpg\n",
            "Copied: organic_005801_photo.jpg\n",
            "Copied: Vegetation_166.jpg\n",
            "Copied: biological76.jpg\n",
            "Copied: biological635.jpg\n",
            "Copied: Food Organics_104.jpg\n",
            "Copied: biological734.jpg\n",
            "Copied: organic_000506_photo.jpg\n",
            "Copied: organic_002472_photo.jpg\n",
            "Copied: Vegetation_333.jpg\n",
            "Copied: Vegetation_203.jpg\n",
            "Copied: organic_013265_photo.jpg\n",
            "Copied: biological859.jpg\n",
            "Copied: Food Organics_54.jpg\n",
            "Copied: organic_005914_photo.jpg\n",
            "Copied: Vegetation_356.jpg\n",
            "Copied: biological691.jpg\n",
            "Copied: organic_005235_photo.jpg\n",
            "Copied: biological679.jpg\n",
            "Copied: biological530.jpg\n",
            "Copied: biological121.jpg\n",
            "Copied: Vegetation_20.jpg\n",
            "Copied: organic_004194_photo.jpg\n",
            "Copied: biological81.jpg\n",
            "Copied: organic_008564_photo.jpg\n",
            "Copied: Vegetation_144.jpg\n",
            "Copied: biological163.jpg\n",
            "Copied: Vegetation_132.jpg\n",
            "Copied: organic_006661_photo.jpg\n",
            "Copied: organic_001408_photo.jpg\n",
            "Copied: biological372.jpg\n",
            "Copied: organic_004149_photo.jpg\n",
            "Copied: Food Organics_125.jpg\n",
            "Copied: organic_004498_photo.jpg\n",
            "Copied: Food Organics_361.jpg\n",
            "\n",
            "Total 960 files copied from '/root/.cache/kagglehub/datasets/glhdamar/new-trash-classfication-dataset/versions/3/new-dataset-trash-type-v2/organic' to 'dataset/train/organic' (random: True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO: Check for duplicates"
      ],
      "metadata": {
        "id": "wxK1bgraC08p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Validation Dataset\n",
        "\n",
        "This dataset will be created by moving some files from training dataset."
      ],
      "metadata": {
        "id": "Ml-cAB1aAMS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def move_validation_split_custom(train_dir, val_dir, per_class_counts: dict, random_select=True):\n",
        "    train_dir = Path(train_dir)\n",
        "    val_dir = Path(val_dir)\n",
        "    val_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for class_name, n in per_class_counts.items():\n",
        "        class_dir = train_dir / class_name\n",
        "        if not class_dir.exists():\n",
        "            print(f\"âš ï¸ Folder tidak ditemukan: {class_dir}\")\n",
        "            continue\n",
        "\n",
        "        images = sorted([p for p in class_dir.glob(\"*.*\") if p.suffix.lower() in {'.jpg', '.jpeg', '.png'}])\n",
        "        selected = random.sample(images, min(n, len(images))) if random_select else images[:n]\n",
        "        val_class_dir = val_dir / class_name\n",
        "        val_class_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        print(f\"ðŸ“ {class_name}: Memindahkan {len(selected)} file...\")\n",
        "        for img in tqdm(selected, desc=f\"  Pindah {class_name}\", leave=False):\n",
        "            shutil.move(str(img), str(val_class_dir / img.name))\n",
        "\n",
        "    print(\"\\nâœ… Selesai membuat validasi set proporsional.\")\n"
      ],
      "metadata": {
        "id": "XqGECqIqAg-p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15% validasi per kelas\n",
        "per_class_counts = {\n",
        "    \"glass\": 495,\n",
        "    \"metal\": 525,\n",
        "    \"organic\": 300,\n",
        "    \"paper\": 600,\n",
        "    \"plastic\": 600,\n",
        "    \"styrofoam\": 150,\n",
        "    \"textiles\": 600\n",
        "}\n",
        "\n",
        "move_validation_split_custom(\"dataset/train\", \"dataset/test\", per_class_counts, random_select=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wov1MSNIAxgs",
        "outputId": "6c5fc246-a641-444c-fdf1-7d296aae8203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ glass: Memindahkan 495 file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ metal: Memindahkan 525 file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ organic: Memindahkan 300 file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ paper: Memindahkan 600 file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ plastic: Memindahkan 600 file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ styrofoam: Memindahkan 150 file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ textiles: Memindahkan 600 file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                          "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Selesai membuat validasi set proporsional.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Distribution checking"
      ],
      "metadata": {
        "id": "NZwJYq_hH4zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "train_dataset = ImageFolder(\"dataset/train\")\n",
        "label_counts = Counter([label for _, label in train_dataset])\n",
        "print(\"Label mapping:\", train_dataset.class_to_idx)\n",
        "print(\"Distribusi kelas:\", label_counts)\n",
        "\n",
        "test_dataset = ImageFolder(\"dataset/test\")\n",
        "label_counts = Counter([label for _, label in test_dataset])\n",
        "print(\"Distribusi kelas:\", label_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "3j6nGKt8H5mS",
        "outputId": "3ac4e639-977f-4618-ee05-f2edce5c755b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label mapping: {'glass': 0, 'metal': 1, 'organic': 2, 'paper': 3, 'plastic': 4, 'styrofoam': 5, 'textiles': 6}\n",
            "Distribusi kelas: Counter({3: 4000, 4: 4000, 6: 4000, 2: 3536, 1: 3500, 0: 3300, 5: 1000})\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dataset/test'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-18-608419030.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Distribusi kelas:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset/test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mlabel_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Distribusi kelas:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/test'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to Google Drive (Optional)\n",
        "\n",
        "This functionality allows to save the trained models to current Google account"
      ],
      "metadata": {
        "id": "obb9veKNvMCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3Np0okOuQR2",
        "outputId": "67666a6d-b828-487a-cd63-6bd875231f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation"
      ],
      "metadata": {
        "id": "atrzVjhIJPyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup ClearML\n",
        "\n",
        "Go ahead and sign-up/sign-in to [AI Infrastructure Platform | Maximize AI Performance & Scalability | ClearML](https://clear.ml/)\n",
        "\n",
        "After that, go to Settings -> Workspace -> Create new credentials\n",
        "\n",
        "The new credentials will be created and shows two options:\n",
        "\n",
        "Local Python (Recommended)\n",
        "Jupyter Notebook\n",
        "Both actually are the same things, it only differs on how to use the new credentials.\n",
        "\n",
        "This time, use the clearml CLI app to consume the credentials, when prompted, paste it."
      ],
      "metadata": {
        "id": "s6PsY9duJkpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clearml"
      ],
      "metadata": {
        "id": "1MObF1_cNqbO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a76b6448-75ab-438c-8a2b-08203c40c7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: clearml in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (25.3.0)\n",
            "Requirement already satisfied: furl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.1.4)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (4.24.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.0.2)\n",
            "Requirement already satisfied: pathlib2>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.3.7.post1)\n",
            "Requirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from clearml) (5.9.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from clearml) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.9.0.post0)\n",
            "Requirement already satisfied: pyjwt<2.11.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.10.1)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.11/dist-packages (from clearml) (6.0.2)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.4.0)\n",
            "Requirement already satisfied: Pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (11.2.1)\n",
            "Requirement already satisfied: referencing<0.40 in /usr/local/lib/python3.11/dist-packages (from clearml) (0.36.2)\n",
            "Requirement already satisfied: requests>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.32.3)\n",
            "Requirement already satisfied: orderedmultidict>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from furl>=2.0.0->clearml) (1.0.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml) (2025.4.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing<0.40->clearml) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!clearml-init"
      ],
      "metadata": {
        "id": "TbVTxN62NtHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf156978-9c80-4cda-d0b6-794ce8279c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClearML SDK setup process\n",
            "Configuration file already exists: /root/clearml.conf\n",
            "Leaving setup, feel free to edit the configuration file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ry525mbBaZW",
        "outputId": "80699240-5b2b-4c07-fead-2495bf57d01e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b>Time Out Preventer (Advanced) </b></strong>\n",
        "%%capture\n",
        "AUTO_RECONNECT = True #@param {type:\"boolean\"}\n",
        "#@markdown **Run this code to prevent Google Colab from Timeout**\n",
        "from os import makedirs\n",
        "makedirs(\"/root/.config/rclone\", exist_ok = True)\n",
        "if AUTO_RECONNECT:\n",
        "  import IPython\n",
        "  from google.colab import output\n",
        "\n",
        "  display(IPython.display.Javascript('''\n",
        "  function ClickConnect(){\n",
        "    btn = document.querySelector(\"colab-connect-button\")\n",
        "    if (btn != null){\n",
        "      console.log(\"Click colab-connect-button\");\n",
        "      btn.click()\n",
        "      }\n",
        "\n",
        "    btn = document.getElementById('ok')\n",
        "    if (btn != null){\n",
        "      console.log(\"Click reconnect\");\n",
        "      btn.click()\n",
        "      }\n",
        "    }\n",
        "\n",
        "  setInterval(ClickConnect,60000)\n",
        "  '''))"
      ],
      "metadata": {
        "id": "1B-wiSQryw5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Options (Choose one of these)"
      ],
      "metadata": {
        "id": "kVvKfsV9rx3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (1) Training with early stopping - Recommended"
      ],
      "metadata": {
        "id": "ILDzO2myN_Pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import time\n",
        "import os\n",
        "from clearml import Task, Logger, OutputModel\n",
        "\n",
        "\n",
        "\n",
        "# ðŸ” Transformasi\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "# ðŸ“ Load dataset\n",
        "train_dataset = datasets.ImageFolder(\"dataset/train\", transform=transform)\n",
        "val_dataset = datasets.ImageFolder(\"dataset/test\", transform=transform)\n",
        "class_names = train_dataset.classes\n",
        "\n",
        "print(\"Label mapping:\", train_dataset.class_to_idx)\n",
        "print(\"Train distribusi:\", Counter([label for _, label in train_dataset]))\n",
        "print(\"Val distribusi:\", Counter([label for _, label in val_dataset]))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "# âš™ï¸ Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
        "model = model.to(device)\n",
        "\n",
        "# Inbalanced dataset\n",
        "labels = [label for _, label in train_dataset]\n",
        "class_weights = compute_class_weight(class_weight='balanced',\n",
        "                                     classes=np.unique(labels),\n",
        "                                     y=labels)\n",
        "\n",
        "weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "# ðŸ” Training loop\n",
        "epochs = 32\n",
        "patience = 12\n",
        "train_accs, val_accs = [], []\n",
        "train_losses, val_losses = [], []\n",
        "best_val_acc = 0\n",
        "early_stop_counter = 0\n",
        "\n",
        "# Model Storage\n",
        "model_name = model.__class__.__name__\n",
        "best_model_path = f\"/content/drive/MyDrive/{model_name}_best_model.pt\"\n",
        "latest_model_path = f\"/content/drive/MyDrive/{model_name}_latest_model.pt\"\n",
        "os.makedirs(os.path.dirname(\"/content/drive/MyDrive/Cool Lee Yeah/8th Semester/Skripsi/AI Models\"), exist_ok=True)\n",
        "\n",
        "task = Task.init(\n",
        "    project_name=\"EcoSort CNN\",\n",
        "    task_name=f\"{model_name} Training {time.strftime('%a, %b %-d, %Y - %H:%M:%S')}\",\n",
        "    task_type=Task.TaskTypes.training\n",
        ")\n",
        "logger = task.get_logger()\n",
        "\n",
        "# ðŸ” Logging sample predictions\n",
        "def log_predictions(images, labels, preds, class_names, epoch):\n",
        "    fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
        "    for i in range(min(5, len(images))):\n",
        "        img = images[i].cpu().permute(1, 2, 0) * 0.5 + 0.5  # unnormalize\n",
        "        axs[i].imshow(img.numpy())\n",
        "        axs[i].axis('off')\n",
        "        axs[i].set_title(f\"T: {class_names[labels[i]]}\\nP: {class_names[preds[i]]}\")\n",
        "    logger.report_matplotlib_figure(title=\"Sample Predictions\", series=\"Validation\", figure=fig, iteration=epoch)\n",
        "    plt.close(fig)\n",
        "\n",
        "# ðŸƒ Training starts\n",
        "try:\n",
        "  for epoch in range(epochs):\n",
        "      start_time = time.time()\n",
        "      model.train()\n",
        "      train_loss = 0\n",
        "      correct, total = 0, 0\n",
        "\n",
        "      for images, labels in train_loader:\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          train_loss += loss.item()\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          correct += torch.sum(preds == labels)\n",
        "          total += labels.size(0)\n",
        "\n",
        "      train_acc = correct / total\n",
        "      train_accs.append(train_acc.item())\n",
        "      train_losses.append(train_loss / len(train_loader))\n",
        "\n",
        "      # ClearML Logging (Train)\n",
        "      logger.report_scalar(\"Accuracy\", \"Train\", value=train_acc.item(), iteration=epoch)\n",
        "      logger.report_scalar(\"Loss\", \"Train\", value=train_loss / len(train_loader), iteration=epoch)\n",
        "      logger.report_scalar(\"LR\", \"Learning Rate\", value=optimizer.param_groups[0]['lr'], iteration=epoch)\n",
        "\n",
        "      # ðŸ” Validasi\n",
        "      model.eval()\n",
        "      val_loss = 0\n",
        "      correct, total = 0, 0\n",
        "      y_true, y_pred = [], []\n",
        "      last_batch_images, last_batch_labels, last_batch_preds = None, None, None\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for images, labels in val_loader:\n",
        "              images, labels = images.to(device), labels.to(device)\n",
        "              outputs = model(images)\n",
        "              loss = criterion(outputs, labels)\n",
        "\n",
        "              val_loss += loss.item()\n",
        "              _, preds = torch.max(outputs, 1)\n",
        "              correct += torch.sum(preds == labels)\n",
        "              total += labels.size(0)\n",
        "\n",
        "              y_true.extend(labels.cpu().numpy())\n",
        "              y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "              last_batch_images = images\n",
        "              last_batch_labels = labels\n",
        "              last_batch_preds = preds\n",
        "\n",
        "      val_acc = correct / total\n",
        "      val_accs.append(val_acc.item())\n",
        "      val_losses.append(val_loss / len(val_loader))\n",
        "\n",
        "      # ClearML Logging (Val)\n",
        "      logger.report_scalar(\"Accuracy\", \"Validation\", value=val_acc.item(), iteration=epoch)\n",
        "      logger.report_scalar(\"Loss\", \"Validation\", value=val_loss / len(val_loader), iteration=epoch)\n",
        "\n",
        "      # Classification Report\n",
        "      report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
        "      for class_name in class_names:\n",
        "          logger.report_scalar(\"Precision\", class_name, value=report[class_name][\"precision\"], iteration=epoch)\n",
        "          logger.report_scalar(\"Recall\", class_name, value=report[class_name][\"recall\"], iteration=epoch)\n",
        "          logger.report_scalar(\"F1-Score\", class_name, value=report[class_name][\"f1-score\"], iteration=epoch)\n",
        "      logger.report_scalar(\"F1-Score\", \"Macro Avg\", value=report[\"macro avg\"][\"f1-score\"], iteration=epoch)\n",
        "\n",
        "      # Confusion Matrix\n",
        "      cm = confusion_matrix(y_true, y_pred)\n",
        "      fig, ax = plt.subplots(figsize=(6, 6))\n",
        "      disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "      disp.plot(cmap=\"Blues\", ax=ax)\n",
        "      plt.title(\"Confusion Matrix\")\n",
        "      logger.report_matplotlib_figure(title=\"Confusion Matrix\", series=\"Validation\", figure=fig, iteration=epoch)\n",
        "      plt.close(fig)\n",
        "\n",
        "      # Sample Prediction Logging\n",
        "      log_predictions(last_batch_images, last_batch_labels, last_batch_preds, class_names, epoch)\n",
        "      print(f\"ðŸ” Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.4f} - Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "      # Save model\n",
        "      if val_acc >= best_val_acc:\n",
        "          best_val_acc = val_acc\n",
        "          early_stop_counter = 0\n",
        "          torch.save(model.state_dict(), best_model_path)\n",
        "          print(f\"ðŸ† (Best) Model saved\")\n",
        "\n",
        "      else:\n",
        "          torch.save(model.state_dict(), latest_model_path)\n",
        "          print(f\"ðŸ“¦ (Latest) Model saved\")\n",
        "          early_stop_counter += 1\n",
        "          if early_stop_counter >= patience:\n",
        "              print(\"â¹ï¸ Early stopping triggered.\")\n",
        "              break\n",
        "\n",
        "      duration = time.time() - start_time\n",
        "      eta = (epochs - epoch - 1) * duration\n",
        "      print(f\"â±ï¸ Epoch time: Took {duration:.2f}s - ETA: ~{eta/60:.1f} min\")\n",
        "      logger.report_scalar(\"Epoch Time (sec)\", \"Duration\", value=duration, iteration=epoch)\n",
        "      print(\"\\n\")\n",
        "\n",
        "  # ðŸŽ‰ Done\n",
        "  print(\"=== Final Classification Report ===\")\n",
        "  print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "  task.mark_completed()\n",
        "\n",
        "except Exception:\n",
        "    task.mark_failed()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUEZ24awJXcT",
        "outputId": "5b6de304-a12c-4e98-e282-bebdcd5cf377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClearML Task: created new task id=b32342711e1d410c997b8345a8047d0c\n",
            "2025-07-19 07:52:39,981 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
            "ClearML results page: https://app.clear.ml/projects/06fa9058610d4908bdf75f3a0a10c4b2/experiments/b32342711e1d410c997b8345a8047d0c/output/log\n",
            "Label mapping: {'glass': 0, 'metal': 1, 'organic': 2, 'paper': 3, 'plastic': 4, 'styrofoam': 5, 'textiles': 6}\n",
            "Train distribusi: Counter({3: 3400, 4: 3400, 6: 3400, 1: 2975, 0: 2805, 2: 1700, 5: 850})\n",
            "Val distribusi: Counter({3: 600, 4: 600, 6: 600, 1: 525, 0: 495, 2: 300, 5: 150})\n",
            "2025-07-19 07:54:41,080 - clearml.model - INFO - Selected model id: 19f8b6976a0344a0ae63d4f6f4dc3be5\n",
            "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n",
            "Epoch 1/32 - Train Acc: 0.6450 - Val Acc: 0.6786\n",
            "2025-07-19 07:59:01,379 - clearml.frameworks - INFO - Found existing registered model id=d733f9cedb084ef884057ff923d1bfd9 [/content/drive/MyDrive/best_model.pt] reusing it.\n",
            "ðŸŒŸ Epoch 1/32 - Val Acc: 0.6786 (Best) - Model saved\n",
            "Time: 167.27 seconds\n",
            "â±ï¸ Epoch time: 167.27s - ETA: ~86.4 min\n",
            "\n",
            "\n",
            "Epoch 2/32 - Train Acc: 0.7353 - Val Acc: 0.7578\n",
            "ðŸŒŸ Epoch 2/32 - Val Acc: 0.7578 (Best) - Model saved\n",
            "Time: 167.97 seconds\n",
            "â±ï¸ Epoch time: 167.97s - ETA: ~84.0 min\n",
            "\n",
            "\n",
            "Epoch 3/32 - Train Acc: 0.7777 - Val Acc: 0.7893\n",
            "ðŸŒŸ Epoch 3/32 - Val Acc: 0.7893 (Best) - Model saved\n",
            "Time: 168.68 seconds\n",
            "â±ï¸ Epoch time: 168.68s - ETA: ~81.5 min\n",
            "\n",
            "\n",
            "Epoch 4/32 - Train Acc: 0.8047 - Val Acc: 0.8199\n",
            "ðŸŒŸ Epoch 4/32 - Val Acc: 0.8199 (Best) - Model saved\n",
            "Time: 169.68 seconds\n",
            "â±ï¸ Epoch time: 169.68s - ETA: ~79.2 min\n",
            "\n",
            "\n",
            "Epoch 5/32 - Train Acc: 0.8285 - Val Acc: 0.7924\n",
            "ðŸ“¦ Epoch 5/32 - Val Acc: 0.7924 - Model saved\n",
            "Time: 166.05 seconds\n",
            "â±ï¸ Epoch time: 166.05s - ETA: ~74.7 min\n",
            "\n",
            "\n",
            "Epoch 6/32 - Train Acc: 0.8487 - Val Acc: 0.8269\n",
            "ðŸŒŸ Epoch 6/32 - Val Acc: 0.8269 (Best) - Model saved\n",
            "Time: 168.65 seconds\n",
            "â±ï¸ Epoch time: 168.65s - ETA: ~73.1 min\n",
            "\n",
            "\n",
            "Epoch 7/32 - Train Acc: 0.8641 - Val Acc: 0.8156\n",
            "ðŸ“¦ Epoch 7/32 - Val Acc: 0.8156 - Model saved\n",
            "Time: 168.41 seconds\n",
            "â±ï¸ Epoch time: 168.41s - ETA: ~70.2 min\n",
            "\n",
            "\n",
            "Epoch 8/32 - Train Acc: 0.8800 - Val Acc: 0.8428\n",
            "ðŸŒŸ Epoch 8/32 - Val Acc: 0.8428 (Best) - Model saved\n",
            "Time: 168.41 seconds\n",
            "â±ï¸ Epoch time: 168.41s - ETA: ~67.4 min\n",
            "\n",
            "\n",
            "Epoch 9/32 - Train Acc: 0.8939 - Val Acc: 0.8554\n",
            "ðŸŒŸ Epoch 9/32 - Val Acc: 0.8554 (Best) - Model saved\n",
            "Time: 167.36 seconds\n",
            "â±ï¸ Epoch time: 167.36s - ETA: ~64.2 min\n",
            "\n",
            "\n",
            "Epoch 10/32 - Train Acc: 0.9037 - Val Acc: 0.8590\n",
            "ðŸŒŸ Epoch 10/32 - Val Acc: 0.8590 (Best) - Model saved\n",
            "Time: 167.43 seconds\n",
            "â±ï¸ Epoch time: 167.43s - ETA: ~61.4 min\n",
            "\n",
            "\n",
            "Epoch 11/32 - Train Acc: 0.9145 - Val Acc: 0.8697\n",
            "ðŸŒŸ Epoch 11/32 - Val Acc: 0.8697 (Best) - Model saved\n",
            "Time: 168.61 seconds\n",
            "â±ï¸ Epoch time: 168.61s - ETA: ~59.0 min\n",
            "\n",
            "\n",
            "Epoch 12/32 - Train Acc: 0.9236 - Val Acc: 0.8526\n",
            "ðŸ“¦ Epoch 12/32 - Val Acc: 0.8526 - Model saved\n",
            "Time: 166.65 seconds\n",
            "â±ï¸ Epoch time: 166.65s - ETA: ~55.5 min\n",
            "\n",
            "\n",
            "Epoch 13/32 - Train Acc: 0.9303 - Val Acc: 0.8566\n",
            "ðŸ“¦ Epoch 13/32 - Val Acc: 0.8566 - Model saved\n",
            "Time: 166.94 seconds\n",
            "â±ï¸ Epoch time: 166.94s - ETA: ~52.9 min\n",
            "\n",
            "\n",
            "Epoch 14/32 - Train Acc: 0.9339 - Val Acc: 0.8725\n",
            "ðŸŒŸ Epoch 14/32 - Val Acc: 0.8725 (Best) - Model saved\n",
            "Time: 166.11 seconds\n",
            "â±ï¸ Epoch time: 166.11s - ETA: ~49.8 min\n",
            "\n",
            "\n",
            "Epoch 15/32 - Train Acc: 0.9394 - Val Acc: 0.8685\n",
            "ðŸ“¦ Epoch 15/32 - Val Acc: 0.8685 - Model saved\n",
            "Time: 169.02 seconds\n",
            "â±ï¸ Epoch time: 169.02s - ETA: ~47.9 min\n",
            "\n",
            "\n",
            "Epoch 16/32 - Train Acc: 0.9434 - Val Acc: 0.8593\n",
            "ðŸ“¦ Epoch 16/32 - Val Acc: 0.8593 - Model saved\n",
            "Time: 167.06 seconds\n",
            "â±ï¸ Epoch time: 167.06s - ETA: ~44.5 min\n",
            "\n",
            "\n",
            "Epoch 17/32 - Train Acc: 0.9472 - Val Acc: 0.8667\n",
            "ðŸ“¦ Epoch 17/32 - Val Acc: 0.8667 - Model saved\n",
            "Time: 167.82 seconds\n",
            "â±ï¸ Epoch time: 167.82s - ETA: ~42.0 min\n",
            "\n",
            "\n",
            "Epoch 18/32 - Train Acc: 0.9471 - Val Acc: 0.8630\n",
            "ðŸ“¦ Epoch 18/32 - Val Acc: 0.8630 - Model saved\n",
            "Time: 166.94 seconds\n",
            "â±ï¸ Epoch time: 166.94s - ETA: ~39.0 min\n",
            "\n",
            "\n",
            "Epoch 19/32 - Train Acc: 0.9522 - Val Acc: 0.8550\n",
            "ðŸ“¦ Epoch 19/32 - Val Acc: 0.8550 - Model saved\n",
            "Time: 166.86 seconds\n",
            "â±ï¸ Epoch time: 166.86s - ETA: ~36.2 min\n",
            "\n",
            "\n",
            "Epoch 20/32 - Train Acc: 0.9558 - Val Acc: 0.8755\n",
            "ðŸŒŸ Epoch 20/32 - Val Acc: 0.8755 (Best) - Model saved\n",
            "Time: 168.83 seconds\n",
            "â±ï¸ Epoch time: 168.83s - ETA: ~33.8 min\n",
            "\n",
            "\n",
            "Epoch 21/32 - Train Acc: 0.9568 - Val Acc: 0.8670\n",
            "ðŸ“¦ Epoch 21/32 - Val Acc: 0.8670 - Model saved\n",
            "Time: 168.33 seconds\n",
            "â±ï¸ Epoch time: 168.33s - ETA: ~30.9 min\n",
            "\n",
            "\n",
            "Epoch 22/32 - Train Acc: 0.9598 - Val Acc: 0.8639\n",
            "ðŸ“¦ Epoch 22/32 - Val Acc: 0.8639 - Model saved\n",
            "Time: 167.26 seconds\n",
            "â±ï¸ Epoch time: 167.26s - ETA: ~27.9 min\n",
            "\n",
            "\n",
            "Epoch 23/32 - Train Acc: 0.9610 - Val Acc: 0.8639\n",
            "ðŸ“¦ Epoch 23/32 - Val Acc: 0.8639 - Model saved\n",
            "Time: 166.74 seconds\n",
            "â±ï¸ Epoch time: 166.74s - ETA: ~25.0 min\n",
            "\n",
            "\n",
            "Epoch 24/32 - Train Acc: 0.9636 - Val Acc: 0.8853\n",
            "ðŸŒŸ Epoch 24/32 - Val Acc: 0.8853 (Best) - Model saved\n",
            "Time: 168.96 seconds\n",
            "â±ï¸ Epoch time: 168.96s - ETA: ~22.5 min\n",
            "\n",
            "\n",
            "Epoch 25/32 - Train Acc: 0.9634 - Val Acc: 0.8749\n",
            "ðŸ“¦ Epoch 25/32 - Val Acc: 0.8749 - Model saved\n",
            "Time: 169.34 seconds\n",
            "â±ï¸ Epoch time: 169.34s - ETA: ~19.8 min\n",
            "\n",
            "\n",
            "Epoch 26/32 - Train Acc: 0.9666 - Val Acc: 0.8826\n",
            "ðŸ“¦ Epoch 26/32 - Val Acc: 0.8826 - Model saved\n",
            "Time: 167.78 seconds\n",
            "â±ï¸ Epoch time: 167.78s - ETA: ~16.8 min\n",
            "\n",
            "\n",
            "Epoch 27/32 - Train Acc: 0.9693 - Val Acc: 0.8804\n",
            "ðŸ“¦ Epoch 27/32 - Val Acc: 0.8804 - Model saved\n",
            "Time: 168.70 seconds\n",
            "â±ï¸ Epoch time: 168.70s - ETA: ~14.1 min\n",
            "\n",
            "\n",
            "Epoch 28/32 - Train Acc: 0.9662 - Val Acc: 0.8853\n",
            "ðŸŒŸ Epoch 28/32 - Val Acc: 0.8853 (Best) - Model saved\n",
            "Time: 167.83 seconds\n",
            "â±ï¸ Epoch time: 167.83s - ETA: ~11.2 min\n",
            "\n",
            "\n",
            "Epoch 29/32 - Train Acc: 0.9697 - Val Acc: 0.8538\n",
            "ðŸ“¦ Epoch 29/32 - Val Acc: 0.8538 - Model saved\n",
            "Time: 168.73 seconds\n",
            "â±ï¸ Epoch time: 168.73s - ETA: ~8.4 min\n",
            "\n",
            "\n",
            "Epoch 30/32 - Train Acc: 0.9690 - Val Acc: 0.8780\n",
            "ðŸ“¦ Epoch 30/32 - Val Acc: 0.8780 - Model saved\n",
            "Time: 170.11 seconds\n",
            "â±ï¸ Epoch time: 170.11s - ETA: ~5.7 min\n",
            "\n",
            "\n",
            "Epoch 31/32 - Train Acc: 0.9716 - Val Acc: 0.8657\n",
            "ðŸ“¦ Epoch 31/32 - Val Acc: 0.8657 - Model saved\n",
            "Time: 169.17 seconds\n",
            "â±ï¸ Epoch time: 169.17s - ETA: ~2.8 min\n",
            "\n",
            "\n",
            "Epoch 32/32 - Train Acc: 0.9710 - Val Acc: 0.8728\n",
            "ðŸ“¦ Epoch 32/32 - Val Acc: 0.8728 - Model saved\n",
            "Time: 168.81 seconds\n",
            "â±ï¸ Epoch time: 168.81s - ETA: ~0.0 min\n",
            "\n",
            "\n",
            "=== Final Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       glass       0.89      0.86      0.87       495\n",
            "       metal       0.88      0.90      0.89       525\n",
            "     organic       0.83      0.91      0.87       300\n",
            "       paper       0.88      0.83      0.85       600\n",
            "     plastic       0.85      0.84      0.85       600\n",
            "   styrofoam       0.78      0.91      0.84       150\n",
            "    textiles       0.92      0.90      0.91       600\n",
            "\n",
            "    accuracy                           0.87      3270\n",
            "   macro avg       0.86      0.88      0.87      3270\n",
            "weighted avg       0.87      0.87      0.87      3270\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (2) Training without early stopping"
      ],
      "metadata": {
        "id": "RRpj1OvSsAMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import time\n",
        "\n",
        "# Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "train_dataset = datasets.ImageFolder(\"dataset/train\", transform=transform)\n",
        "class_names = train_dataset.classes\n",
        "print(\"Label mapping:\", train_dataset.class_to_idx)\n",
        "print(\"Distribusi:\", Counter([label for _, label in train_dataset]))\n",
        "\n",
        "val_dataset = datasets.ImageFolder(\"dataset/test\", transform=transform)\n",
        "print(\"Label mapping:\", val_dataset.class_to_idx)\n",
        "print(\"Distribusi:\", Counter([label for _, label in val_dataset]))\n",
        "\n",
        "# Split\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "# Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training\n",
        "epochs = 6\n",
        "train_accs, val_accs = [], []\n",
        "best_val_acc = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    correct, total, loss_total = 0, 0, 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_total += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += torch.sum(preds == labels)\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "    train_accs.append(train_acc.item())\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.4f}\")\n",
        "\n",
        "    # Validasi\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += torch.sum(preds == labels)\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_acc = correct / total\n",
        "    val_accs.append(val_acc.item())\n",
        "    print(f\"            â†’ Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "# Simpan\n",
        "torch.save(model.state_dict(), \"model_cnn.pt\")\n",
        "print(\"âœ… Model disimpan.\")"
      ],
      "metadata": {
        "id": "z04jGaYgsFLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "OG66ezAGOKAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Š Evaluasi dengan laporan & Confusion Matrix\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "for images, labels in val_loader:\n",
        "    images = images.to(device)\n",
        "    outputs = model(images)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "print(\"\\n=== Classification Report ===\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "disp.plot(cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Plot akurasi training & val\n",
        "plt.plot(train_accs, label=\"Train\")\n",
        "plt.plot(val_accs, label=\"Validation\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.title(\"Train vs Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9wqOURnbONd4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}