{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"include_colab_link":true},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/rediahmds/eco-sort/blob/main/train/train_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"## Connect to Google Drive","metadata":{"id":"Hi1UbGUd2K1n"}},{"cell_type":"code","source":"USE_CLEARML = False\nUSE_GOOGLE_COLAB = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T03:40:19.791873Z","iopub.execute_input":"2025-08-18T03:40:19.792179Z","iopub.status.idle":"2025-08-18T03:40:19.795758Z","shell.execute_reply.started":"2025-08-18T03:40:19.792156Z","shell.execute_reply":"2025-08-18T03:40:19.795009Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"if USE_GOOGLE_COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\nelse:\n    !pip install PyDrive2\n\n    from pydrive2.auth import GoogleAuth\n    from pydrive2.drive import GoogleDrive\n\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    GCP_CLIENT_SECRET = user_secrets.get_secret(\"GCP_CLIENT_SECRET\")\n\n    with open(\"client_secrets.json\", \"w\") as f:\n        f.write(GCP_CLIENT_SECRET)\n\n\n    gauth = GoogleAuth()\n    gauth.CommandLineAuth()\n\n    drive = GoogleDrive(gauth)\n\n    def save_to_gdrive(name: str, destination_dir_id: str):\n        pass","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htmo7u-i2J65","outputId":"eefefe31-2c91-4e31-8164-5a323fb19792","trusted":true,"execution":{"iopub.status.busy":"2025-08-18T03:40:41.996992Z","iopub.execute_input":"2025-08-18T03:40:41.997717Z","iopub.status.idle":"2025-08-18T03:41:00.867485Z","shell.execute_reply.started":"2025-08-18T03:40:41.997691Z","shell.execute_reply":"2025-08-18T03:41:00.866676Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: PyDrive2 in /usr/local/lib/python3.11/dist-packages (1.21.3)\nRequirement already satisfied: google-api-python-client>=1.12.5 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (2.173.0)\nRequirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (4.1.3)\nRequirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (6.0.2)\nRequirement already satisfied: cryptography<44 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (43.0.3)\nRequirement already satisfied: pyOpenSSL<=24.2.1,>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (24.2.1)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44->PyDrive2) (1.17.1)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (0.22.0)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (2.40.3)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (1.34.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (4.2.0)\nRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->PyDrive2) (0.6.1)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->PyDrive2) (0.4.2)\nRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->PyDrive2) (4.9.1)\nRequirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->PyDrive2) (1.17.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44->PyDrive2) (2.22)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (1.70.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (3.20.3)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2.32.4)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.12.5->PyDrive2) (5.5.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=1.12.5->PyDrive2) (3.0.9)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2025.6.15)\nGo to the following link in your browser:\n\n    https://accounts.google.com/o/oauth2/auth?client_id=991309652978-hpmqspbdt0bccglf6iklc3er1d9naa8q.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=online&response_type=code\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter verification code:  4/1AVMBsJi_wuOR6pc0GZNdNUT717q04oCK5bEDGodVgLO7sqpi2eIQUMS1uSY\n"},{"name":"stdout","text":"Authentication successful.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Prepare dataset (Run only once)\n\nRun for the first time only. when starting new session, dont run it.","metadata":{"id":"HYavOwVuEkGf"}},{"cell_type":"markdown","source":"### Download","metadata":{"id":"oCK3f0-SFms6"}},{"cell_type":"code","source":"import shutil\nimport os\n\ndef copy_file_to_folder(source_path: str, destination_folder: str, preserve_metadata: bool = False):\n    \"\"\"\n    Copies a file to a specified folder, creating the folder if it doesn't exist.\n\n    Args:\n        source_path (str): The full path to the source file.\n        destination_folder (str): The path to the destination folder.\n        preserve_metadata (bool): If True, preserves file metadata (uses shutil.copy2).\n                                  Defaults to False.\n\n    Returns:\n        bool: True if the copy was successful, False otherwise.\n    \"\"\"\n    try:\n        # Create the destination folder if it doesn't exist\n        os.makedirs(destination_folder, exist_ok=True)\n\n        # Choose the copy function based on the preserve_metadata flag\n        if preserve_metadata:\n            shutil.copy2(source_path, destination_folder)\n        else:\n            shutil.copy(source_path, destination_folder)\n\n        print(f\"File '{source_path}' copied successfully to '{destination_folder}'. ✅\")\n\n        return True\n\n    except FileNotFoundError:\n        print(f\"Error: The source file was not found at '{source_path}'.\")\n        return False\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return False","metadata":{"id":"wGsUlIFaIND-","trusted":true,"execution":{"iopub.status.busy":"2025-08-18T03:41:05.305828Z","iopub.execute_input":"2025-08-18T03:41:05.306172Z","iopub.status.idle":"2025-08-18T03:41:05.312091Z","shell.execute_reply.started":"2025-08-18T03:41:05.306144Z","shell.execute_reply":"2025-08-18T03:41:05.311357Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"if USE_GOOGLE_COLAB:\n    DATASET_PATH = \"/content/drive/MyDrive/Cool Lee Yeah/8th Semester/Skripsi/Datasets/dataset_no-styro.7z\"\n    copy_file_to_folder(DATASET_PATH, \"/content/\")\nelse:\n    GDRIVE_DATASET_FILE_ID = user_secrets.get_secret(\"GDRIVE_DATASET_FILE_ID\")\n    file_id = GDRIVE_DATASET_FILE_ID\n    local_filename = \"dataset.7z\" # save as\n\n    \n    try:\n        file_to_download = drive.CreateFile({'id': file_id})\n\n        print(f\"⬇️ Downloading file: '{file_to_download['title']}'...\")\n        file_to_download.GetContentFile(local_filename)\n\n        print(f\"✅ Downloaded successfully and saved as '{local_filename}'\")\n\n    except Exception as e:\n        print(f\"Error: {e}\")","metadata":{"id":"3JmiaTh-JqS9","outputId":"a8853a9a-6860-4ca8-a233-e1dc6ff39815","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T03:42:05.422722Z","iopub.execute_input":"2025-08-18T03:42:05.423028Z","iopub.status.idle":"2025-08-18T03:43:04.022459Z","shell.execute_reply.started":"2025-08-18T03:42:05.423004Z","shell.execute_reply":"2025-08-18T03:43:04.021715Z"}},"outputs":[{"name":"stdout","text":"⬇️ Downloading file: 'dataset_all-class-improved.7z'...\n✅ Downloaded successfully and saved as 'dataset.7z'\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Extract the Dataset","metadata":{"id":"SNy902YmKCeq"}},{"cell_type":"code","source":"!7z x dataset.7z","metadata":{"id":"nt-XR1nuKIss","outputId":"b932b99f-dec0-4b18-9e94-4fec7d0512b1","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T03:43:46.151357Z","iopub.execute_input":"2025-08-18T03:43:46.151627Z","iopub.status.idle":"2025-08-18T03:45:25.359964Z","shell.execute_reply.started":"2025-08-18T03:43:46.151605Z","shell.execute_reply":"2025-08-18T03:45:25.359057Z"}},"outputs":[{"name":"stdout","text":"\n7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\np7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n\nScanning the drive for archives:\n  0M Sca        1 file, 2020477498 bytes (1927 MiB)\n\nExtracting archive: dataset.7z\n--\nPath = dataset.7z\nType = 7z\nPhysical Size = 2020477498\nHeaders Size = 222736\nMethod = LZMA2:24\nSolid = +\nBlocks = 1\n\n      0%      0% 582 - dataset/train/background/158.jp                                            0% 825 - dataset/train/background/377.jp                                            0% 1211 - dataset/train/background/724.j                                            0% 1361 - dataset/train/background/86.jp                                            0% 1532 - dataset/train/glass/Glass_113.jp                                              1% 1608 - dataset/train/glass/Glass_182.jp                                              1% 1650 - dataset/train/glass/Glass_22.j                                            1% 1725 - dataset/train/glass/Glass_288.jp                                              2% 1763 - dataset/train/glass/Glass_321.jp                                              2% 1836 - dataset/train/glass/Glass_388.jp                                              2% 1889 - dataset/train/glass/Glass_57.j                                            3% 1923 - dataset/train/glass/Glass_88.j                                            3% 2234 - dataset/train/glass/brown-glass373.j                                                  3% 2575 - dataset/train/glass/default_gl . rage_bottles_0072__Image_16.p                                                                            3% 2666 - dataset/train/glass/default_gla . age_bottles_0218__Image_211.pn                                                                              3% 2747 - dataset/train/glass/default_gla . ic_containers_0110__Image_59.p                                                                              3% 2826 - dataset/train/glass/default_glas . c_containers_0239__Image_250.pn                                                                                4% 2878 - dataset/train/glass/default_glass_food_jars_0063__Image_89.p                                                                          4% 2906 - dataset/train/glass/default_glass_food_jars_0114__Image_54.p                                                                          4% 2963 - dataset/train/glass/default_glass_food_jars_0199__Image_151.pn                                                                            4% 3015 - dataset/train/glass/glass 1034.j                                              5% 3058 - dataset/train/glass/glass 1120.j                                              5% 3061 - dataset/train/glass/glass 1126.j                                              5% 3105 - dataset/train/glass/glass 1208.j                                              5% 3176 - dataset/train/glass/glass 1342.j                                              6% 3215 - dataset/train/glass/glass 1402.j                                              6% 3233 - dataset/train/glass/glass 1430.j                                              6% 3291 - dataset/train/glass/glass 1515.j                                              7% 3342 - dataset/train/glass/glass 1604.j                                              7% 3368 - dataset/train/glass/glass 1644.j                                              8% 3417 - dataset/train/glass/glass 1725.j                                              8% 3440 - dataset/train/glass/glass 1759.j                                              8% 3489 - dataset/train/glass/glass 1831.j                                              8% 3557 - dataset/train/glass/glass 1933.j                                              9% 3565 - dataset/train/glass/glass 1948.j                                              9% 3603 - dataset/train/glass/glass 2006.j                                              9% 3656 - dataset/train/glass/glass 2084.j                                             10% 3692 - dataset/train/glass/glass 2144.j                                             10% 3736 - dataset/train/glass/glass 2212.j                                             11% 3796 - dataset/train/glass/glass 2316.j                                             11% 3841 - dataset/train/glass/glass 2386.j                                             11% 3873 - dataset/train/glass/glass 2444.j                                             12% 3926 - dataset/train/glass/glass 258.jp                                             12% 3975 - dataset/train/glass/glass 344.jp                                             12% 4053 - dataset/train/glass/glass 465.jp                                             12% 4080 - dataset/train/glass/glass 500.jp                                             13% 4090 - dataset/train/glass/glass 516.jp                                             13% 4134 - dataset/train/glass/glass 577.jp                                             13% 4169 - dataset/train/glass/glass 626.jp                                             13% 4187 - dataset/train/glass/glass 661.jp                                             13% 4219 - dataset/train/glass/glass 71.j                                           14% 4265 - dataset/train/glass/glass 780.jp                                             14% 4303 - dataset/train/glass/glass 875.jp                                             14% 4365 - dataset/train/glass/glass 973.jp                                             14% 4371 - dataset/train/glass/glass 981.jp                                             14% 4536 - dataset/train/glass/green-glass254.j                                                 14% 4635 - dataset/train/glass/green-glass348.j                                                 15% 4703 - dataset/train/glass/green-glass412.j                                                 15% 4854 - dataset/train/glass/green-glass575.j                                                 15% 4992 - dataset/train/glass/real_world_g . rage_bottles_0078__Image_112.pn                                                                               15% 5030 - dataset/train/glass/real_world_g . rage_bottles_0146__Image_158.pn                                                                               15% 5068 - dataset/train/glass/real_world_g . rage_bottles_0198__Image_117.pn                                                                               15% 5147 - dataset/train/glass/real_worl . containers_0089__Image_172.p                                                                         15% 5195 - dataset/train/glass/real_worl . containers_0175__Image_136.p                                                                         15% 5230 - dataset/train/glass/real_worl . containers_0233__Image_35.pn                                                                         15% 5305 - dataset/train/glass/real_world_glass_food_jars_0102__Image_247.p                                                                             16% 5352 - dataset/train/glass/real_world_glass_food_jars_0166__Image_10.pn                                                                             16% 5374 - dataset/train/glass/real_world_glass_food_jars_0198__Image_117.p                                                                             16% 5497 - dataset/train/glass/white-glass204.j                                                 16% 5623 - dataset/train/glass/white-glass356.j                                                 16% 5656 - dataset/train/glass/white-glass393.j                                                 16% 5761 - dataset/train/glass/white-glass516.j                                                 16% 5871 - dataset/train/glass/white-glass657.j                                                 16% 5986 - dataset/train/glass/white-glass80.jp                                                 16% 6049 - dataset/train/metal/Metal_143.jp                                             17% 6088 - dataset/train/metal/Metal_180.jp                                             17% 6152 - dataset/train/metal/Metal_240.jp                                             17% 6212 - dataset/train/metal/Metal_297.jp                                             18% 6273 - dataset/train/metal/Metal_354.jp                                             18% 6309 - dataset/train/metal/Metal_389.jp                                             18% 6375 - dataset/train/metal/Metal_451.jp                                             19% 6412 - dataset/train/metal/Metal_487.jp                                             19% 6478 - dataset/train/metal/Metal_548.jp                                             19% 6513 - dataset/train/metal/Metal_580.jp                                             20% 6578 - dataset/train/metal/Metal_646.jp                                             20% 6616 - dataset/train/metal/Metal_681.jp                                             20% 6689 - dataset/train/metal/Metal_752.jp                                             20% 6728 - dataset/train/metal/Metal_789.jp                                             21% 6755 - dataset/train/metal/default_aerosol_cans_0004__Image_37.pn                                                                       21% 6833 - dataset/train/metal/default_aerosol_cans_0132__Image_224.p                                                                       21% 6909 - dataset/train/metal/default_aluminum_food_cans_0024__Image_217.p                                                                             21% 6985 - dataset/train/metal/default_aluminum_food_cans_0147__Image_173.p                                                                             21% 7051 - dataset/train/metal/default_aluminum_soda_cans_0007__Image_85.pn                                                                             21% 7065 - dataset/train/metal/default_aluminum_soda_cans_0029__Image_57.pn                                                                             22% 7127 - dataset/train/metal/default_aluminum_soda_cans_0121__Image_196.p                                                                             22% 7198 - dataset/train/metal/default_aluminum_soda_cans_0229__Image_240.p                                                                             22% 7272 - dataset/train/metal/default_steel_food_cans_0123__Image_97.p                                                                         22% 7347 - dataset/train/metal/metal 1003.j                                             22% 7400 - dataset/train/metal/metal 1067.j                                             23% 7474 - dataset/train/metal/metal 116.jp                                             23% 7523 - dataset/train/metal/metal 1218.j                                             23% 7577 - dataset/train/metal/metal 1289.j                                             23% 7620 - dataset/train/metal/metal 1338.j                                             24% 7727 - dataset/train/metal/metal 1455.j                                             24% 7767 - dataset/train/metal/metal 150.jp                                             24% 7853 - dataset/train/metal/metal 1602.j                                             25% 7853 - dataset/train/metal/metal 1602.j                                             25% 7878 - dataset/train/metal/metal 1631.j                                             25% 7938 - dataset/train/metal/metal 1700.j                                             25% 7967 - dataset/train/metal/metal 1742.j                                             26% 8009 - dataset/train/metal/metal 1787.j                                             26% 8050 - dataset/train/metal/metal 1833.j                                             26% 8097 - dataset/train/metal/metal 1887.j                                             27% 8155 - dataset/train/metal/metal 1955.j                                             27% 8197 - dataset/train/metal/metal 2001.j                                             27% 8232 - dataset/train/metal/metal 2045.j                                             27% 8293 - dataset/train/metal/metal 2120.j                                             28% 8321 - dataset/train/metal/metal 2164.j                                             28% 8344 - dataset/train/metal/metal 2195.j                                             28% 8366 - dataset/train/metal/metal 2218.j                                             28% 8419 - dataset/train/metal/metal 228.jp                                             28% 8444 - dataset/train/metal/metal 2310.j                                             29% 8476 - dataset/train/metal/metal 2349.j                                             29% 8522 - dataset/train/metal/metal 2400.j                                             30% 8567 - dataset/train/metal/metal 2455.j                                             30% 8625 - dataset/train/metal/metal 2529.j                                             31% 8679 - dataset/train/metal/metal 268.jp                                             31% 8699 - dataset/train/metal/metal 297.jp                                             31% 8747 - dataset/train/metal/metal 346.jp                                             32% 8801 - dataset/train/metal/metal 408.jp                                             32% 8836 - dataset/train/metal/metal 444.jp                                             32% 8887 - dataset/train/metal/metal 506.jp                                             32% 8906 - dataset/train/metal/metal 525.jp                                             33% 8920 - dataset/train/metal/metal 541.jp                                             33% 8969 - dataset/train/metal/metal 593.jp                                             34% 9009 - dataset/train/metal/metal 645.jp                                             34% 9072 - dataset/train/metal/metal 722.jp                                             34% 9122 - dataset/train/metal/metal 781.jp                                             34% 9164 - dataset/train/metal/metal 835.jp                                             34% 9256 - dataset/train/metal/metal 938.jp                                             34% 9286 - dataset/train/metal/metal 973.jp                                             34% 9407 - dataset/train/metal/metal189.j                                           35% 9408 - dataset/train/metal/metal19.jp                                           35% 9552 - dataset/train/metal/metal321.j                                           35% 9654 - dataset/train/metal/metal417.j                                           35% 9666 - dataset/train/metal/metal429.j                                           35% 9800 - dataset/train/metal/metal562.j                                           35% 9931 - dataset/train/metal/metal691.j                                           35% 10053 - dataset/train/metal/real_world_aerosol_cans_0025__Image_3.p                                                                         35% 10054 - dataset/train/metal/real_world_aerosol_cans_0026__Image_135.p                                                                           35% 10125 - dataset/train/metal/real_world_aerosol_cans_0150__Image_79.pn                                                                           35% 10180 - dataset/train/metal/real_world . m_food_cans_0004__Image_37.p                                                                           35% 10191 - dataset/train/metal/real_world . m_food_cans_0021__Image_13.p                                                                           35% 10251 - dataset/train/metal/real_world . m_food_cans_0135__Image_70.p                                                                           36% 10268 - dataset/train/metal/real_worl . um_food_cans_0162__Image_7.pn                                                                           36% 10318 - dataset/train/metal/real_world . m_soda_cans_0010__Image_138.pn                                                                             36% 10373 - dataset/train/metal/real_world . m_soda_cans_0099__Image_51.p                                                                           36% 10374 - dataset/train/metal/real_world . m_soda_cans_0100__Image_23.p                                                                           36% 10431 - dataset/train/metal/real_world . m_soda_cans_0181__Image_118.pn                                                                             36% 10489 - dataset/train/metal/real_world_steel_food_cans_0015__Image_108.pn                                                                               36% 10490 - dataset/train/metal/real_world_steel_food_cans_0018__Image_126.pn                                                                               36% 10555 - dataset/train/metal/real_world_steel_food_cans_0137__Image_219.pn                                                                               37% 10595 - dataset/train/metal/real_world_steel_food_cans_0210__Image_65.p                                                                             37% 10642 - dataset/train/organic/Food Organics_125.j                                                       37% 10708 - dataset/train/organic/Food Organics_185.j                                                       38% 10758 - dataset/train/organic/Food Organics_23.jp                                                       38% 10781 - dataset/train/organic/Food Organics_250.j                                                       38% 10801 - dataset/train/organic/Food Organics_269.j                                                       39% 10827 - dataset/train/organic/Food Organics_292.j                                                       39% 10864 - dataset/train/organic/Food Organics_325.j                                                       39% 10905 - dataset/train/organic/Food Organics_362.j                                                       40% 10926 - dataset/train/organic/Food Organics_381.j                                                       40% 10947 - dataset/train/organic/Food Organics_40.jp                                                       40% 10998 - dataset/train/organic/Food Organics_76.jp                                                       40% 11021 - dataset/train/organic/Food Organics_98.jp                                                       41% 11441 - dataset/train/organic/O_2643.jp                                             41% 11455 - dataset/train/organic/O_2868.jp                                             41% 11866 - dataset/train/organic/O_6690.jp                                             41% 11925 - dataset/train/organic/O_7254.jp                                             41% 12213 - dataset/train/organic/Vegetation_101.jp                                                     41% 12232 - dataset/train/organic/Vegetation_119.jp                                                     41% 12251 - dataset/train/organic/Vegetation_136.jp                                                     42% 12271 - dataset/train/organic/Vegetation_154.jp                                                     42% 12290 - dataset/train/organic/Vegetation_171.jp                                                     42% 12310 - dataset/train/organic/Vegetation_19.j                                                   42% 12347 - dataset/train/organic/Vegetation_222.jp                                                     43% 12367 - dataset/train/organic/Vegetation_240.jp                                                     43% 12388 - dataset/train/organic/Vegetation_26.j                                                   43% 12430 - dataset/train/organic/Vegetation_298.jp                                                     43% 12452 - dataset/train/organic/Vegetation_317.jp                                                     44% 12493 - dataset/train/organic/Vegetation_354.jp                                                     44% 12513 - dataset/train/organic/Vegetation_372.jp                                                     44% 12534 - dataset/train/organic/Vegetation_391.jp                                                     45% 12578 - dataset/train/organic/Vegetation_430.jp                                                     45% 12599 - dataset/train/organic/Vegetation_57.j                                                   45% 12619 - dataset/train/organic/Vegetation_75.j                                                   45% 12640 - dataset/train/organic/Vegetation_94.j                                                   45% 12875 - dataset/train/organic/biological306.j                                                   45% 12966 - dataset/train/organic/biological390.j                                                   46% 13080 - dataset/train/organic/biological496.j                                                   46% 13284 - dataset/train/organic/biological681.j                                                   46% 13428 - dataset/train/organic/biological812.j                                                   46% 13504 - dataset/train/organic/biological882.j                                                   46% 13645 - dataset/train/organic/default_coffee_grounds_0048__Image_175.pn                                                                             46% 13698 - dataset/train/organic/default_coffee_grounds_0153__Image_123.pn                                                                             46% 13705 - dataset/train/organic/default_coffee_grounds_0170__Image_111.pn                                                                             46% 13748 - dataset/train/organic/default_coffee_grounds_0245__Image_30.p                                                                           47% 13803 - dataset/train/organic/default_eggshells_0084__Image_56.pn                                                                       47% 13859 - dataset/train/organic/default_eggshells_0165__Image_195.p                                                                       47% 13917 - dataset/train/organic/default_food_waste_0008__Image_150.pn                                                                         47% 13946 - dataset/train/organic/default_food_waste_0048__Image_175.pn                                                                         47% 13969 - dataset/train/organic/default_food_waste_0092__Image_197.pn                                                                         47% 14019 - dataset/train/organic/default_food_waste_0188__Image_179.pn                                                                         48% 14071 - dataset/train/organic/default_tea_bags_0042__Image_12.p                                                                     48% 14129 - dataset/train/organic/default_tea_bags_0130__Image_192.pn                                                                       48% 14195 - dataset/train/organic/default_tea_bags_0227__Image_145.pn                                                                       48% 14229 - dataset/train/organic/organic_001893_photo.jp                                                           48% 14366 - dataset/train/organic/organic_011861_photo.jp                                                           48% 14410 - dataset/train/organic/real_wo . ee_grounds_0020__Image_120.pn                                                                           48% 14461 - dataset/train/organic/real_world_coffee_grounds_0107__Image_33.pn                                                                               48% 14470 - dataset/train/organic/real_world_coffee_grounds_0124__Image_96.pn                                                                               49% 14511 - dataset/train/organic/real_wo . ee_grounds_0194__Image_170.pn                                                                           49% 14565 - dataset/train/organic/real_world_eggshells_0047__Image_200.pn                                                                           49% 14613 - dataset/train/organic/real_world_eggshells_0114__Image_54.p                                                                         49% 14625 - dataset/train/organic/real_world_eggshells_0134__Image_218.pn                                                                           49% 14680 - dataset/train/organic/real_world_eggshells_0219__Image_207.pn                                                                           49% 14733 - dataset/train/organic/real_world_food_waste_0071__Image_82.pn                                                                           49% 14770 - dataset/train/organic/real_world_food_waste_0146__Image_158.p                                                                           50% 14784 - dataset/train/organic/real_world_food_waste_0173__Image_186.p                                                                           50% 14839 - dataset/train/organic/real_world_tea_bags_0019__Image_160.p                                                                         50% 14893 - dataset/train/organic/real_world_tea_bags_0092__Image_197.p                                                                         50% 14938 - dataset/train/organic/real_world_tea_bags_0157__Image_48.pn                                                                         50% 14955 - dataset/train/organic/real_world_tea_bags_0179__Image_209.p                                                                         50% 15009 - dataset/train/paper/Cardboard_105.j                                                 51% 15063 - dataset/train/paper/Cardboard_154.j                                                 51% 15121 - dataset/train/paper/Cardboard_206.j                                                 51% 15160 - dataset/train/paper/Cardboard_241.j                                                 52% 15234 - dataset/train/paper/Cardboard_308.j                                                 52% 15272 - dataset/train/paper/Cardboard_342.j                                                 52% 15349 - dataset/train/paper/Cardboard_411.j                                                 53% 15383 - dataset/train/paper/Cardboard_442.j                                                 53% 15448 - dataset/train/paper/Cardboard_86.jp                                                 53% 15481 - dataset/train/paper/Paper_115.j                                             54% 15551 - dataset/train/paper/Paper_179.j                                             54% 15586 - dataset/train/paper/Paper_21.jp                                             54% 15659 - dataset/train/paper/Paper_276.j                                             55% 15694 - dataset/train/paper/Paper_307.j                                             55% 15757 - dataset/train/paper/Paper_364.j                                             55% 15809 - dataset/train/paper/Paper_410.j                                             56% 15865 - dataset/train/paper/Paper_461.j                                             56% 15899 - dataset/train/paper/Paper_492.j                                             56% 15962 - dataset/train/paper/Paper_99.jp                                             56% 16079 - dataset/train/paper/cardboard301.jp                                                 56% 16313 - dataset/train/paper/cardboard67.j                                               57% 16460 - dataset/train/paper/cardboard95.j                                               57% 16524 - dataset/train/paper/default_cardboard_boxes_0128__Image_231.p                                                                           57% 16607 - dataset/train/paper/default_c . _packaging_0061__Image_181.pn                                                                           57% 16680 - dataset/train/paper/default_cardboard_packaging_0226__Image_73.pn                                                                               57% 16772 - dataset/train/paper/default_magazines_0112__Image_90.pn                                                                     58% 16816 - dataset/train/paper/default_magazines_0169__Image_109.p                                                                     58% 16860 - dataset/train/paper/default_magazines_0239__Image_250.p                                                                     58% 16908 - dataset/train/paper/default_newspaper_0047__Image_200.p                                                                     58% 16931 - dataset/train/paper/default_newspaper_0074__Image_212.p                                                                     58% 16962 - dataset/train/paper/default_newspaper_0110__Image_59.pn                                                                     59% 17015 - dataset/train/paper/default_newspaper_0175__Image_136.p                                                                     59% 17063 - dataset/train/paper/default_newspaper_0234__Image_62.pn                                                                     59% 17099 - dataset/train/paper/default_office_paper_0024__Image_217.pn                                                                         59% 17129 - dataset/train/paper/default_office_paper_0066__Image_227.pn                                                                         59% 17201 - dataset/train/paper/default_office_paper_0153__Image_123.pn                                                                         59% 17272 - dataset/train/paper/default_office_paper_0235__Image_4.pn                                                                       59% 17343 - dataset/train/paper/default_paper_cups_0090__Image_228.pn                                                                       60% 17344 - dataset/train/paper/default_paper_cups_0091__Image_144.pn                                                                       60% 17414 - dataset/train/paper/default_paper_cups_0199__Image_151.pn                                                                       60% 17523 - dataset/train/paper/paper234.jp                                             60% 17634 - dataset/train/paper/paper435.jp                                             60% 17687 - dataset/train/paper/paper519.jp                                             60% 17842 - dataset/train/paper/paper833.jp                                             60% 17855 - dataset/train/paper/paper855.jp                                             60% 17972 - dataset/train/paper/real_world_cardboard_boxes_0059__Image_183.pn                                                                               60% 18037 - dataset/train/paper/real_world_cardboard_boxes_0155__Image_113.pn                                                                               61% 18042 - dataset/train/paper/real_world_cardboard_boxes_0162__Image_7.pn                                                                             61% 18114 - dataset/train/paper/real_world_ . d_packaging_0020__Image_120.p                                                                             61% 18182 - dataset/train/paper/real_world . rd_packaging_0126__Image_63.pn                                                                             61% 18192 - dataset/train/paper/real_world_ . d_packaging_0143__Image_178.p                                                                             61% 18265 - dataset/train/paper/real_world_magazines_0007__Image_85.p                                                                       61% 18312 - dataset/train/paper/real_world_magazines_0062__Image_11.p                                                                       62% 18357 - dataset/train/paper/real_world_magazines_0119__Image_236.pn                                                                         62% 18401 - dataset/train/paper/real_world_magazines_0181__Image_118.pn                                                                         62% 18449 - dataset/train/paper/real_world_magazines_0243__Image_98.p                                                                       62% 18500 - dataset/train/paper/real_world_newspaper_0048__Image_175.pn                                                                         62% 18501 - dataset/train/paper/real_world_newspaper_0049__Image_92.p                                                                       62% 18553 - dataset/train/paper/real_world_newspaper_0114__Image_54.p                                                                       62% 18609 - dataset/train/paper/real_world_newspaper_0177__Image_84.p                                                                       63% 18610 - dataset/train/paper/real_world_newspaper_0179__Image_209.pn                                                                         63% 18668 - dataset/train/paper/real_world_newspaper_0242__Image_161.pn                                                                         63% 18729 - dataset/train/paper/real_world_office_paper_0071__Image_82.pn                                                                           63% 18730 - dataset/train/paper/real_world_office_paper_0072__Image_16.pn                                                                           63% 18790 - dataset/train/paper/real_world_office_paper_0158__Image_229.p                                                                           63% 18856 - dataset/train/paper/real_world_office_paper_0246__Image_24.pn                                                                           63% 18873 - dataset/train/paper/real_world_paper_cups_0019__Image_160.p                                                                         64% 18927 - dataset/train/paper/real_world_paper_cups_0084__Image_56.pn                                                                         64% 18994 - dataset/train/paper/real_world_paper_cups_0177__Image_84.pn                                                                         64% 19005 - dataset/train/paper/real_world_paper_cups_0192__Image_94.pn                                                                         64% 19061 - dataset/train/plastic/Plastic_114.j                                                 64% 19123 - dataset/train/plastic/Plastic_170.j                                                 65% 19191 - dataset/train/plastic/Plastic_232.j                                                 65% 19228 - dataset/train/plastic/Plastic_266.j                                                 66% 19282 - dataset/train/plastic/Plastic_314.j                                                 66% 19335 - dataset/train/plastic/Plastic_362.j                                                 66% 19382 - dataset/train/plastic/Plastic_404.j                                                 67% 19439 - dataset/train/plastic/Plastic_456.j                                                 67% 19499 - dataset/train/plastic/Plastic_51.jp                                                 67% 19549 - dataset/train/plastic/Plastic_555.j                                                 68% 19604 - dataset/train/plastic/Plastic_604.j                                                 68% 19658 - dataset/train/plastic/Plastic_653.j                                                 69% 19710 - dataset/train/plastic/Plastic_70.jp                                                 69% 19762 - dataset/train/plastic/Plastic_747.j                                                 69% 19792 - dataset/train/plastic/Plastic_774.j                                                 70% 19857 - dataset/train/plastic/Plastic_832.j                                                 70% 19891 - dataset/train/plastic/Plastic_863.j                                                 70% 19959 - dataset/train/plastic/Plastic_95.jp                                                 70% 20030 - dataset/train/plastic/default_plastic_cup_lids_0122__Image_19.p                                                                             71% 20109 - dataset/train/plastic/default_plastic_cup_lids_0246__Image_24.p                                                                             71% 20216 - dataset/train/plastic/defaul . nt_bottles_0166__Image_10.pn                                                                         71% 20304 - dataset/train/plastic/default_p . od_containers_0071__Image_82.pn                                                                               71% 20368 - dataset/train/plastic/defaul . ntainers_0181__Image_118.p                                                                       72% 20435 - dataset/train/plastic/default_p . hopping_bags_0053__Image_187.pn                                                                               72% 20502 - dataset/train/plastic/default_p . hopping_bags_0168__Image_115.pn                                                                               72% 20568 - dataset/train/plastic/default_p . oda_bottles_0060__Image_188.p                                                                             72% 20637 - dataset/train/plastic/default_ . soda_bottles_0177__Image_84.pn                                                                             72% 20734 - dataset/train/plastic/default_plastic_straws_0105__Image_147.pn                                                                             73% 20820 - dataset/train/plastic/default_plastic_straws_0249__Image_165.pn                                                                             73% 20873 - dataset/train/plastic/default_ . trash_bags_0117__Image_238.p                                                                           73% 20885 - dataset/train/plastic/default_ . trash_bags_0149__Image_249.p                                                                           73% 20958 - dataset/train/plastic/default_p . ater_bottles_0045__Image_152.pn                                                                               73% 21031 - dataset/train/plastic/default_p . ater_bottles_0147__Image_173.pn                                                                               74% 21098 - dataset/train/plastic/plastic 101.j                                                 74% 21151 - dataset/train/plastic/plastic 1101.jp                                                   75% 21194 - dataset/train/plastic/plastic 1185.jp                                                   75% 21203 - dataset/train/plastic/plastic 1199.jp                                                   76% 21207 - dataset/train/plastic/plastic 1208.jp                                                   76% 21208 - dataset/train/plastic/plastic 121.j                                                 76% 21217 - dataset/train/plastic/plastic 1226.jp                                                   76% 21226 - dataset/train/plastic/plastic 1237.jp                                                   77% 21229 - dataset/train/plastic/plastic 1240.jp                                                   77% 21232 - dataset/train/plastic/plastic 1244.jp                                                   77% 21239 - dataset/train/plastic/plastic 1257.jp                                                   79% 21249 - dataset/train/plastic/plastic 1278.jp                                                   79% 21281 - dataset/train/plastic/plastic 1318.jp                                                   80% 21296 - dataset/train/plastic/plastic 1347.jp                                                   81% 21335 - dataset/train/plastic/plastic 1407.jp                                                   82% 21345 - dataset/train/plastic/plastic 1420.jp                                                   82% 21353 - dataset/train/plastic/plastic 1431.jp                                                   82% 21354 - dataset/train/plastic/plastic 1432.jp                                                   83% 21367 - dataset/train/plastic/plastic 1449.jp                                                   84% 21387 - dataset/train/plastic/plastic 1486.jp                                                   84% 21420 - dataset/train/plastic/plastic 1533.jp                                                   84% 21441 - dataset/train/plastic/plastic 1563.jp                                                   84% 21492 - dataset/train/plastic/plastic 1651.jp                                                   85% 21565 - dataset/train/plastic/plastic 1768.jp                                                   85% 21632 - dataset/train/plastic/plastic 1873.jp                                                   85% 21668 - dataset/train/plastic/plastic 1921.jp                                                   85% 21669 - dataset/train/plastic/plastic 1923.jp                                                   85% 21732 - dataset/train/plastic/plastic 2014.jp                                                   86% 21799 - dataset/train/plastic/plastic 2120.jp                                                   86% 21894 - dataset/train/plastic/plastic 2275.jp                                                   86% 21998 - dataset/train/plastic/plastic 2438.jp                                                   86% 22020 - dataset/train/plastic/plastic 2479.jp                                                   86% 22078 - dataset/train/plastic/plastic 2577.jp                                                   86% 22156 - dataset/train/plastic/plastic 311.j                                                 87% 22211 - dataset/train/plastic/plastic 387.j                                                 87% 22261 - dataset/train/plastic/plastic 456.j                                                 87% 22299 - dataset/train/plastic/plastic 522.j                                                 87% 22330 - dataset/train/plastic/plastic 578.j                                                 88% 22373 - dataset/train/plastic/plastic 653.j                                                 88% 22411 - dataset/train/plastic/plastic 726.j                                                 88% 22424 - dataset/train/plastic/plastic 751.j                                                 89% 22430 - dataset/train/plastic/plastic 761.j                                                 89% 22469 - dataset/train/plastic/plastic 824.j                                                 89% 22486 - dataset/train/plastic/plastic 86.jp                                                 90% 22533 - dataset/train/plastic/plastic 942.j                                                 90% 22585 - dataset/train/plastic/real_wor . ic_cup_lids_0020__Image_120.pn                                                                             90% 22586 - dataset/train/plastic/real_wor . ic_cup_lids_0021__Image_13.p                                                                           90% 22661 - dataset/train/plastic/real_wor . ic_cup_lids_0158__Image_229.pn                                                                             90% 22739 - dataset/train/plastic/real_wor . ent_bottles_0047__Image_200.pn                                                                             90% 22780 - dataset/train/plastic/real_wor . ent_bottles_0106__Image_106.pn                                                                             91% 22851 - dataset/train/plastic/real_wor . ent_bottles_0216__Image_61.p                                                                           91% 22922 - dataset/train/plastic/real_wo . containers_0098__Image_131.pn                                                                           91% 22967 - dataset/train/plastic/real_wo . containers_0170__Image_111.pn                                                                           91% 22985 - dataset/train/plastic/real_wo . containers_0207__Image_14.p                                                                         91% 23045 - dataset/train/plastic/real_w . ping_bags_0067__Image_18.p                                                                       91% 23107 - dataset/train/plastic/real_w . ping_bags_0178__Image_38.p                                                                       91% 23126 - dataset/train/plastic/real_w . ping_bags_0208__Image_128.pn                                                                         92% 23169 - dataset/train/plastic/real_w . _bottles_0034__Image_245.p                                                                       92% 23226 - dataset/train/plastic/real_w . _bottles_0134__Image_218.p                                                                       92% 23274 - dataset/train/plastic/real_w . _bottles_0211__Image_141.p                                                                       92% 23297 - dataset/train/plastic/real_world_plastic_straws_0006__Image_22.pn                                                                               92% 23344 - dataset/train/plastic/real_wo . tic_straws_0085__Image_168.pn                                                                           92% 23401 - dataset/train/plastic/real_wo . tic_straws_0172__Image_157.pn                                                                           92% 23458 - dataset/train/plastic/real_wor . ic_trash_bags_0003__Image_6.pn                                                                             93% 23462 - dataset/train/plastic/real_worl . c_trash_bags_0010__Image_138.pn                                                                               93% 23515 - dataset/train/plastic/real_worl . c_trash_bags_0095__Image_182.pn                                                                               93% 23551 - dataset/train/plastic/real_worl . c_trash_bags_0150__Image_79.p                                                                             93% 23579 - dataset/train/plastic/real_worl . c_trash_bags_0202__Image_190.pn                                                                               93% 23635 - dataset/train/plastic/real_w . r_bottles_0041__Image_39.p                                                                       93% 23657 - dataset/train/plastic/real_w . r_bottles_0073__Image_155.pn                                                                         93% 23693 - dataset/train/plastic/real_w . r_bottles_0128__Image_231.pn                                                                         94% 23753 - dataset/train/plastic/real_w . r_bottles_0220__Image_215.pn                                                                         94% 23757 - dataset/train/plastic/real_w . r_bottles_0226__Image_73.p                                                                       94% 23870 - dataset/train/textiles/clothes1283.jp                                                   94% 24017 - dataset/train/textiles/clothes1743.jp                                                   94% 24165 - dataset/train/textiles/clothes2214.jp                                                   94% 24260 - dataset/train/textiles/clothes2510.jp                                                   94% 24309 - dataset/train/textiles/clothes2676.jp                                                   95% 24456 - dataset/train/textiles/clothes317.j                                                 95% 24603 - dataset/train/textiles/clothes3582.jp                                                   95% 24712 - dataset/train/textiles/clothes3997.jp                                                   95% 24747 - dataset/train/textiles/clothes4105.jp                                                   95% 24894 - dataset/train/textiles/clothes4574.jp                                                   95% 25044 - dataset/train/textiles/clothes5046.jp                                                   95% 25045 - dataset/train/textiles/clothes5048.jp                                                   96% 25201 - dataset/train/textiles/clothes785.j                                                 96% 25298 - dataset/train/textiles/default_clothing_0027__Image_191.p                                                                       96% 25351 - dataset/train/textiles/default_clothing_0083__Image_244.p                                                                       96% 25404 - dataset/train/textiles/default_clothing_0137__Image_219.p                                                                       96% 25461 - dataset/train/textiles/default_clothing_0197__Image_202.p                                                                       97% 25514 - dataset/train/textiles/default_shoes_0002__Image_221.pn                                                                     97% 25578 - dataset/train/textiles/default_shoes_0069__Image_140.pn                                                                     97% 25645 - dataset/train/textiles/default_shoes_0136__Image_222.pn                                                                     97% 25669 - dataset/train/textiles/default_shoes_0160__Image_162.pn                                                                     97% 25713 - dataset/train/textiles/default_shoes_0204__Image_52.p                                                                   97% 25774 - dataset/train/textiles/real_world_clothing_0019__Image_160.pn                                                                           98% 25834 - dataset/train/textiles/real_world_clothing_0090__Image_228.pn                                                                           98% 25887 - dataset/train/textiles/real_world_clothing_0152__Image_110.pn                                                                           98% 25943 - dataset/train/textiles/real_world_clothing_0217__Image_47.p                                                                         98% 25983 - dataset/train/textiles/real_world_shoes_0010__Image_138.p                                                                       98% 25999 - dataset/train/textiles/real_world_shoes_0029__Image_57.pn                                                                       98% 26062 - dataset/train/textiles/real_world_shoes_0105__Image_147.p                                                                       99% 26128 - dataset/train/textiles/real_world_shoes_0188__Image_179.p                                                                       99% 26164 - dataset/train/textiles/real_world_shoes_0232__Image_27.pn                                                                       99% 26250 - dataset/train/textiles/shoes1081.jp                                                 99% 26355 - dataset/train/textiles/shoes1208.jp                                                 99% 26540 - dataset/train/textiles/shoes1432.jp                                                 99% 26633 - dataset/train/textiles/shoes1540.jp                                                 99% 26675 - dataset/train/textiles/shoes1596.jp                                                 99% 26843 - dataset/train/textiles/shoes1792.jp                                                 99% 26927 - dataset/train/textiles/shoes1896.jp                                                 99% 26970 - dataset/train/textiles/shoes1954.jp                                                 99% 27111 - dataset/train/textiles/shoes336.j                                               99% 27260 - dataset/train/textiles/shoes509.j                                               99% 27399 - dataset/train/textiles/shoes669.j                                               99% 27423 - dataset/train/textiles/shoes700.j                                               99% 27559 - dataset/train/textiles/shoes87.jp                                              Everything is Ok\n\nFolders: 9\nFiles: 27655\nSize:       2057930313\nCompressed: 2020477498\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Show directory tree","metadata":{"id":"of2TWdqofglL"}},{"cell_type":"markdown","source":"### Create Validation Dataset\n\nThis dataset will be created by moving some files from training dataset.","metadata":{"id":"Ml-cAB1aAMS1"}},{"cell_type":"code","source":"from pathlib import Path\nimport random\nfrom tqdm import tqdm\nimport shutil\n\nimport os\n\ndef count_files_in_folders(base_path):\n  \"\"\"\n  Counts the number of files in each subfolder of a given path.\n\n  Args:\n    base_path (str): The path to the parent directory (e.g., 'dataset/train').\n\n  Returns:\n    dict: A dictionary with subfolder names as keys and file counts as values.\n          Returns None if the path is not found.\n  \"\"\"\n  if not os.path.isdir(base_path):\n    print(f\"Error: Directory not found at '{base_path}'\")\n    return None\n\n  counts_per_class = {}\n  # Loop through each item in the base directory\n  for class_name in os.listdir(base_path):\n    class_path = os.path.join(base_path, class_name)\n    # Ensure it is a directory\n    if os.path.isdir(class_path):\n      # Count the number of files inside the subdirectory and store it\n      file_count = len(os.listdir(class_path))\n      counts_per_class[class_name] = file_count\n  return counts_per_class\n\ndef calculate_dataset_split(counts_per_class, percentage):\n  \"\"\"\n  Calculates the number of items per class for a split based on a percentage.\n  \"\"\"\n  if not 0 <= percentage <= 100:\n    raise ValueError(\"Percentage must be between 0 and 100.\")\n\n  split_counts_result = {}\n  for class_name, total_count in counts_per_class.items():\n    split_count = total_count * (percentage / 100)\n    # Round to the nearest integer as file counts cannot be fractional\n    split_counts_result[class_name] = round(split_count)\n  return split_counts_result\n\ndef move_validation_split_custom(train_dir, val_dir, per_class_counts: dict, random_select=True):\n    train_dir = Path(train_dir)\n    val_dir = Path(val_dir)\n    val_dir.mkdir(parents=True, exist_ok=True)\n\n    for class_name, n in per_class_counts.items():\n        class_dir = train_dir / class_name\n        if not class_dir.exists():\n            print(f\"⚠️ Folder tidak ditemukan: {class_dir}\")\n            continue\n\n        images = sorted([p for p in class_dir.glob(\"*.*\") if p.suffix.lower() in {'.jpg', '.jpeg', '.png'}])\n        selected = random.sample(images, min(n, len(images))) if random_select else images[:n]\n        val_class_dir = val_dir / class_name\n        val_class_dir.mkdir(parents=True, exist_ok=True)\n\n        print(f\"📁 {class_name}: Memindahkan {len(selected)} file...\")\n        for img in tqdm(selected, desc=f\"  Pindah {class_name}\", leave=False):\n            shutil.move(str(img), str(val_class_dir / img.name))\n\n    print(\"\\n✅ Selesai membuat validasi set proporsional.\")\n","metadata":{"id":"XqGECqIqAg-p","trusted":true,"execution":{"iopub.status.busy":"2025-08-18T03:45:31.277614Z","iopub.execute_input":"2025-08-18T03:45:31.278372Z","iopub.status.idle":"2025-08-18T03:45:31.293561Z","shell.execute_reply.started":"2025-08-18T03:45:31.278338Z","shell.execute_reply":"2025-08-18T03:45:31.293019Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Divide Dataset\n\nThere are two methods for this, `StratifiedShuffle` and `train_test_split`","metadata":{"id":"c2PqRXewJeuF"}},{"cell_type":"code","source":"from torchvision import datasets\n\nDATASET_PATH = \"dataset/train\"\nfull_dataset = datasets.ImageFolder(DATASET_PATH)\nclass_names = full_dataset.classes","metadata":{"id":"P-XfE16hRTkO","trusted":true,"execution":{"iopub.status.busy":"2025-08-18T03:46:23.460454Z","iopub.execute_input":"2025-08-18T03:46:23.461203Z","iopub.status.idle":"2025-08-18T03:46:23.523705Z","shell.execute_reply.started":"2025-08-18T03:46:23.461177Z","shell.execute_reply":"2025-08-18T03:46:23.523188Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"#### (1) Divide: Stratified Method","metadata":{"id":"_aWo6ngmJ67p"}},{"cell_type":"code","source":"from pathlib import Path\nfrom sklearn.model_selection import StratifiedShuffleSplit, train_test_split\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nimport shutil\nfrom tqdm import tqdm\n\ndef stratified_split_imagefolder(source_dir: Path | str,\n                                  target_train: Path | str,\n                                  target_val: Path | str,\n                                  val_ratio=0.2,\n                                  random_state=42):\n    source_dir = Path(source_dir)\n    target_train = Path(target_train)\n    target_val = Path(target_val)\n    target_train.mkdir(parents=True, exist_ok=True)\n    target_val.mkdir(parents=True, exist_ok=True)\n\n    transform = transforms.Compose([transforms.ToTensor()])\n    dataset = ImageFolder(str(source_dir), transform=transform)\n\n    paths = [Path(p) for p, _ in dataset.samples]\n    labels = [label for _, label in dataset.samples]\n    class_names = dataset.classes\n\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=val_ratio, random_state=random_state)\n    train_idx, val_idx = next(sss.split(paths, labels))\n\n    print(f\"📦 Total gambar: {len(paths)}\")\n    print(f\"✅ Train: {len(train_idx)}\")\n    print(f\"✅ Val  : {len(val_idx)}\")\n\n    def copy_split(index_list, target_root):\n        for idx in tqdm(index_list, desc=f\"Salin ke {target_root.name}\"):\n            src = paths[idx]\n            label_name = class_names[labels[idx]]\n            dest_dir = target_root / label_name\n            dest_dir.mkdir(parents=True, exist_ok=True)\n            shutil.copy(src, dest_dir / src.name)\n\n    copy_split(train_idx, target_train)\n    copy_split(val_idx, target_val)\n\n    print(\"✅ Stratified split selesai.\")\n","metadata":{"id":"HqOw6PC-SVXo","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:34:57.682300Z","iopub.execute_input":"2025-08-01T07:34:57.682801Z","iopub.status.idle":"2025-08-01T07:34:58.191992Z","shell.execute_reply.started":"2025-08-01T07:34:57.682777Z","shell.execute_reply":"2025-08-01T07:34:58.191415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stratified_split_imagefolder(\n    source_dir=\"dataset/train\",\n    target_train=\"dataset_stratified/train\",\n    target_val=\"dataset_stratified/test\",\n    val_ratio=0.2,\n    random_state=42\n)","metadata":{"id":"DpgKX4XNORyn","outputId":"245bfe34-7c14-40ce-e87f-dd5b640509de","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["📦 Total gambar: 22198\n","✅ Train: 17758\n","✅ Val  : 4440\n"]},{"output_type":"stream","name":"stderr","text":["Salin ke train: 100%|██████████| 17758/17758 [00:09<00:00, 1895.10it/s]\n","Salin ke test: 100%|██████████| 4440/4440 [00:01<00:00, 2892.72it/s]"]},{"output_type":"stream","name":"stdout","text":["✅ Stratified split selesai.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"execution_count":null},{"cell_type":"markdown","source":"#### (2) Divide: train_test_split","metadata":{"id":"4b3eMIiEKKJk"}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import datasets, transforms\nfrom collections import Counter\nimport torch\n\n\n\n\n# 🔁 Transformasi\n# Augmentasi\ntrain_transform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.RandomGrayscale(p=0.1),\n    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n# Transformasi untuk validasi/test tanpa augmentasi acak\nval_transform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\ntargets = full_dataset.targets\ntrain_idx, val_idx = train_test_split(\n    np.arange(len(targets)),      # Buat array dari index 0 sampai N-1\n    test_size=0.2,                # Alokasikan 20% untuk validasi\n    shuffle=True,\n    stratify=targets              # INI KUNCINYA: pastikan proporsi kelas sama\n)\n\ntrain_labels = [targets[i] for i in train_idx]\nprint(f\"Distribusi kelas di Training: {Counter(train_labels)}\")\nclass_counts = Counter(train_labels)\nnum_samples = len(train_labels)\nclass_weights = {\n    class_id: num_samples / count for class_id, count in class_counts.items()\n}\nweights = [class_weights[label] for label in train_labels]\nsampler = torch.utils.data.WeightedRandomSampler(\n    weights=torch.DoubleTensor(weights),\n    num_samples=num_samples\n)\n\nval_labels = [targets[i] for i in val_idx]\nprint(f\"Distribusi kelas di Validasi: {Counter(val_labels)}\")\n\ntrain_dataset = Subset(full_dataset, train_idx)\ntrain_dataset.dataset.transform = train_transform\n\nval_dataset = Subset(full_dataset, val_idx)\nval_dataset.dataset.transform = val_transform\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, sampler=sampler)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\nprint(f\"Total data: {len(full_dataset)} gambar\")\nprint(f\"Data Training: {len(train_dataset)} gambar\")\nprint(f\"Data Validasi: {len(val_dataset)} gambar\")\nprint(f\"Nama Kelas: {class_names}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfbdY9yfKUgt","outputId":"d0f00232-38c0-4f60-e0d6-d4c533fd05c6","trusted":true,"execution":{"iopub.status.busy":"2025-08-18T03:46:37.602632Z","iopub.execute_input":"2025-08-18T03:46:37.602939Z","iopub.status.idle":"2025-08-18T03:46:38.165245Z","shell.execute_reply.started":"2025-08-18T03:46:37.602887Z","shell.execute_reply":"2025-08-18T03:46:38.164525Z"}},"outputs":[{"name":"stdout","text":"Distribusi kelas di Training: Counter({5: 3782, 2: 3688, 1: 3590, 3: 3511, 4: 3233, 6: 3114, 0: 1206})\nDistribusi kelas di Validasi: Counter({5: 946, 2: 922, 1: 897, 3: 878, 4: 809, 6: 778, 0: 301})\nTotal data: 27655 gambar\nData Training: 22124 gambar\nData Validasi: 5531 gambar\nNama Kelas: ['background', 'glass', 'metal', 'organic', 'paper', 'plastic', 'textiles']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### Data Distribution checking","metadata":{"id":"NZwJYq_hH4zT"}},{"cell_type":"markdown","source":"## Training and Evaluation","metadata":{"id":"atrzVjhIJPyq"}},{"cell_type":"markdown","source":"#### Setup ClearML\n\nGo ahead and sign-up/sign-in to [AI Infrastructure Platform | Maximize AI Performance & Scalability | ClearML](https://clear.ml/)\n\nAfter that, go to Settings -> Workspace -> Create new credentials\n\nThe new credentials will be created and shows two options:\n\nLocal Python (Recommended)\nJupyter Notebook\nBoth actually are the same things, it only differs on how to use the new credentials.\n\nThis time, use the clearml CLI app to consume the credentials, when prompted, paste it.","metadata":{"id":"s6PsY9duJkpc"}},{"cell_type":"code","source":"!pip install clearml","metadata":{"id":"1MObF1_cNqbO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e959fcb4-4c4c-4ab7-aab5-244e36c391d4","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T04:49:22.457416Z","iopub.execute_input":"2025-08-17T04:49:22.457812Z","iopub.status.idle":"2025-08-17T04:49:27.227291Z","shell.execute_reply.started":"2025-08-17T04:49:22.457793Z","shell.execute_reply":"2025-08-17T04:49:27.226495Z"}},"outputs":[{"name":"stdout","text":"Collecting clearml\n  Downloading clearml-2.0.2-py2.py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (25.3.0)\nCollecting furl>=2.0.0 (from clearml)\n  Downloading furl-2.1.4-py2.py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (4.24.0)\nRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.11/dist-packages (from clearml) (1.26.4)\nCollecting pathlib2>=2.3.0 (from clearml)\n  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from clearml) (7.0.0)\nRequirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from clearml) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.9.0.post0)\nRequirement already satisfied: pyjwt<2.11.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.10.1)\nRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.11/dist-packages (from clearml) (6.0.2)\nRequirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (1.17.0)\nRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.5.0)\nRequirement already satisfied: Pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (11.2.1)\nRequirement already satisfied: referencing<0.40 in /usr/local/lib/python3.11/dist-packages (from clearml) (0.36.2)\nRequirement already satisfied: requests>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.32.4)\nCollecting orderedmultidict>=1.0.1 (from furl>=2.0.0->clearml)\n  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml) (2025.4.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml) (0.25.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (2.4.1)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing<0.40->clearml) (4.14.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.10->clearml) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.10->clearml) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.10->clearml) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.10->clearml) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.10->clearml) (2024.2.0)\nDownloading clearml-2.0.2-py2.py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading furl-2.1.4-py2.py3-none-any.whl (27 kB)\nDownloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\nDownloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: pathlib2, orderedmultidict, furl, clearml\nSuccessfully installed clearml-2.0.2 furl-2.1.4 orderedmultidict-1.0.1 pathlib2-2.3.7.post1\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"CLEARML_CONF = user_secrets.get_secret(\"CLEARML_CONF\")\n\n\nwith open(\"/root/clearml.conf\", \"w\") as f:\n    f.write(CLEARML_CONF)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:02:02.543762Z","iopub.execute_input":"2025-08-01T08:02:02.544414Z","iopub.status.idle":"2025-08-01T08:02:02.679335Z","shell.execute_reply.started":"2025-08-01T08:02:02.544386Z","shell.execute_reply":"2025-08-01T08:02:02.678790Z"},"id":"d1gbJSGZ1Z4b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!clearml-init","metadata":{"id":"TbVTxN62NtHk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"42518faa-461f-4c2d-fd90-33b5746a0466","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:04:10.593939Z","iopub.execute_input":"2025-08-01T08:04:10.594221Z","iopub.status.idle":"2025-08-01T08:04:15.812038Z","shell.execute_reply.started":"2025-08-01T08:04:10.594200Z","shell.execute_reply":"2025-08-01T08:04:15.811266Z"}},"outputs":[{"output_type":"stream","name":"stdout","text":["ClearML SDK setup process\n","\n","Please create new clearml credentials through the settings page in your `clearml-server` web app (e.g. http://localhost:8080//settings/workspace-configuration) \n","Or create a free account at https://app.clear.ml/settings/workspace-configuration\n","\n","In settings page, press \"Create new credentials\", then press \"Copy to clipboard\".\n","\n","Paste copied configuration here:\n","api {   # Redi Ahmad Supriyatna's workspace   web_server: https://app.clear.ml/   api_server: https://api.clear.ml   files_server: https://files.clear.ml   credentials {     \"access_key\" = \"XP018Y5KX0LBYJ9JY0LSA1F8BRATNJ\"     \"secret_key\" = \"Tt_arUNOmgaL3_VIsCUmPAHXGYRpY70dKLnyh7Vln6Ew5eRUHdeeU8ODfiEHoRd0kT8\"   } }\n","Detected credentials key=\"XP018Y5KX0LBYJ9JY0LSA1F8BRATNJ\" secret=\"Tt_a***\"\n","\n","ClearML Hosts configuration:\n","Web App: https://app.clear.ml/\n","API: https://api.clear.ml\n","File Store: https://files.clear.ml\n","\n","Verifying credentials ...\n","Credentials verified!\n","\n","New configuration stored in /root/clearml.conf\n","ClearML setup completed successfully.\n"]}],"execution_count":null},{"cell_type":"code","source":"!pip install torch torchvision matplotlib","metadata":{"id":"9Ry525mbBaZW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"21f5972d-0e61-4ed3-c39a-e5650c3c7ad9","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T04:49:37.389213Z","iopub.execute_input":"2025-08-17T04:49:37.389478Z","iopub.status.idle":"2025-08-17T04:50:45.481533Z","shell.execute_reply.started":"2025-08-17T04:49:37.389456Z","shell.execute_reply":"2025-08-17T04:50:45.480772Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"#@title <b>Time Out Preventer (Advanced) </b></strong>\n%%capture\nAUTO_RECONNECT = True #@param {type:\"boolean\"}\n#@markdown **Run this code to prevent Google Colab from Timeout**\nfrom os import makedirs\nmakedirs(\"/root/.config/rclone\", exist_ok = True)\nif AUTO_RECONNECT:\n  import IPython\n  from google.colab import output\n\n  display(IPython.display.Javascript('''\n  function ClickConnect(){\n    btn = document.querySelector(\"colab-connect-button\")\n    if (btn != null){\n      console.log(\"Click colab-connect-button\");\n      btn.click()\n      }\n\n    btn = document.getElementById('ok')\n    if (btn != null){\n      console.log(\"Click reconnect\");\n      btn.click()\n      }\n    }\n\n  setInterval(ClickConnect,60000)\n  '''))","metadata":{"id":"1B-wiSQryw5C"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"while True:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:06:17.949923Z","iopub.execute_input":"2025-08-01T08:06:17.950217Z","iopub.status.idle":"2025-08-01T08:08:02.367528Z","shell.execute_reply.started":"2025-08-01T08:06:17.950194Z","shell.execute_reply":"2025-08-01T08:08:02.366287Z"},"id":"FAHo8dPY1Z4d","outputId":"95a1a037-4257-4ca9-9837-d2cae90c3199"},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2044646855.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":null},{"cell_type":"markdown","source":"### Training Options (Choose one of these)","metadata":{"id":"kVvKfsV9rx3r"}},{"cell_type":"markdown","source":"####  Choose Base Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\n\ndef create_model(model_name: str, num_classes: int, feature_extract: bool = True):\n    \"\"\"\n    Memuat pre-trained model dari torchvision menggunakan pendekatan hardcode yang andal\n    dan menyesuaikannya untuk transfer learning. ✅\n\n    Args:\n        model_name (str): Nama model yang didukung (contoh: 'resnet50', 'mobilenet_v3_small').\n        num_classes (int): Jumlah kelas output untuk dataset baru.\n        feature_extract (bool): Jika True, bekukan bobot kecuali layer terakhir.\n                              Jika False, seluruh model akan dilatih (fine-tuning).\n\n    Returns:\n        torch.nn.Module: Model yang sudah disesuaikan dan siap pakai.\n    \"\"\"\n\n    \n    supported_models = {\n        # ResNet Family\n        \"resnet18\": (models.resnet18, models.ResNet18_Weights.DEFAULT),\n        \"resnet50\": (models.resnet50, models.ResNet50_Weights.DEFAULT),\n        # MobileNet Family\n        \"mobilenet_v2\": (models.mobilenet_v2, models.MobileNet_V2_Weights.DEFAULT),\n        \"mobilenet_v3_small\": (models.mobilenet_v3_small, models.MobileNet_V3_Small_Weights.DEFAULT),\n        \"mobilenet_v3_large\": (models.mobilenet_v3_large, models.MobileNet_V3_Large_Weights.DEFAULT),\n        # EfficientNet Family\n        \"efficientnet_b0\": (models.efficientnet_b0, models.EfficientNet_B0_Weights.DEFAULT),\n        \"efficientnet_b7\": (models.efficientnet_b7, models.EfficientNet_B7_Weights.DEFAULT),\n        # Other Architectures\n        \"vgg16\": (models.vgg16, models.VGG16_Weights.DEFAULT),\n        \"densenet121\": (models.densenet121, models.DenseNet121_Weights.DEFAULT),\n        \"vit_b_16\": (models.vit_b_16, models.ViT_B_16_Weights.DEFAULT),\n        \"swin_t\": (models.swin_t, models.Swin_T_Weights.DEFAULT),\n    }\n\n    if model_name not in supported_models:\n        raise ValueError(\n            f\"Model '{model_name}' tidak didukung.\\n\"\n            f\"Model yang tersedia: {list(supported_models.keys())}\"\n        )\n\n    # Ambil constructor dan bobot dari dictionary\n    model_constructor, weights = supported_models[model_name]\n\n    # Buat instance model dengan bobot pre-trained\n    model = model_constructor(weights=weights)\n\n    # --- Langkah 2: Membekukan Bobot (jika feature_extract=True) ---\n    if feature_extract:\n        for param in model.parameters():\n            param.requires_grad = False\n\n    # --- Langkah 3: Mengganti Layer Klasifikasi Terakhir ---\n    # Logika ini tetap sama karena sudah cukup robust\n    if hasattr(model, 'fc'): # Untuk ResNet, dll.\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n\n    elif hasattr(model, 'classifier'):\n        if isinstance(model.classifier, nn.Sequential): # Untuk VGG, MobileNet, EfficientNet\n            last_layer = model.classifier[-1]\n            if isinstance(last_layer, nn.Linear):\n                num_ftrs = last_layer.in_features\n                model.classifier[-1] = nn.Linear(num_ftrs, num_classes)\n            else:\n                raise TypeError(f\"Layer terakhir dari classifier ({type(last_layer)}) bukan nn.Linear.\")\n        elif isinstance(model.classifier, nn.Linear): # Untuk DenseNet\n            num_ftrs = model.classifier.in_features\n            model.classifier = nn.Linear(num_ftrs, num_classes)\n        else:\n            raise TypeError(f\"Tipe classifier ({type(model.classifier)}) tidak didukung.\")\n\n    elif hasattr(model, 'head'): # Untuk Vision Transformer, Swin Transformer\n        num_ftrs = model.head.in_features\n        model.head = nn.Linear(num_ftrs, num_classes)\n\n    else:\n        raise NameError(f\"Layer klasifikasi untuk '{model_name}' tidak ditemukan.\")\n\n    return (model_name, model)\n\n\ndef create_optimizer(model: nn.Module, base_lr: float = 1e-4, head_lr: float = 1e-3):\n    \"\"\"\n    Membuat optimizer dengan differential learning rates berdasarkan arsitektur model.\n    \"\"\"\n    head_params = []\n    \n    # Identifikasi parameter kepala (head) berdasarkan arsitektur\n    if hasattr(model, 'fc'):\n        head_params = list(model.fc.parameters())\n    elif hasattr(model, 'classifier'):\n        head_params = list(model.classifier.parameters())\n    elif hasattr(model, 'head'):\n        head_params = list(model.head.parameters())\n    else:\n        raise NameError(\"Tidak dapat menemukan layer kepala ('fc', 'classifier', atau 'head') pada model.\")\n        \n    # Dapatkan ID dari parameter kepala untuk memisahkannya dari parameter dasar\n    head_param_ids = {id(p) for p in head_params}\n    \n    # Parameter dasar adalah semua parameter yang BUKAN parameter kepala dan bisa dilatih\n    base_params = [p for p in model.parameters() if id(p) not in head_param_ids and p.requires_grad]\n    \n    # Hanya grup base yang relevan jika ada parameternya (misal, saat fine-tuning)\n    params_to_optimize = [{'params': head_params, 'lr': head_lr}]\n    if base_params:\n        params_to_optimize.insert(0, {'params': base_params, 'lr': base_lr})\n    \n    return torch.optim.Adam(params_to_optimize)","metadata":{"id":"GnSRiWhuqaNx","trusted":true,"execution":{"iopub.status.busy":"2025-08-18T05:32:23.949687Z","iopub.execute_input":"2025-08-18T05:32:23.949970Z","iopub.status.idle":"2025-08-18T05:32:23.962366Z","shell.execute_reply.started":"2025-08-18T05:32:23.949951Z","shell.execute_reply":"2025-08-18T05:32:23.961657Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_training_history(train_losses, val_losses, train_accs, val_accs):\n    \"\"\"\n    Fungsi untuk menampilkan grafik loss dan akurasi training & validation.\n    \"\"\"\n    # Buat 2 subplot berdampingan\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n    epochs_range = range(1, len(train_losses) + 1)\n\n    # Plot 1: Model Loss\n    ax1.plot(epochs_range, train_losses, 'o-', color='tab:blue', label='Training Loss')\n    ax1.plot(epochs_range, val_losses, 'o-', color='tab:orange', label='Validation Loss')\n    ax1.set_title('Model Loss', fontsize=16)\n    ax1.set_xlabel('Epoch', fontsize=12)\n    ax1.set_ylabel('Loss', fontsize=12)\n    ax1.legend(loc='upper right')\n    ax1.grid(True)\n\n    # Plot 2: Model Accuracy\n    ax2.plot(epochs_range, train_accs, 'o-', color='tab:green', label='Training Accuracy')\n    ax2.plot(epochs_range, val_accs, 'o-', color='tab:red', label='Validation Accuracy')\n    ax2.set_title('Model Accuracy', fontsize=16)\n    ax2.set_xlabel('Epoch', fontsize=12)\n    ax2.set_ylabel('Accuracy', fontsize=12)\n    ax2.legend(loc='lower right')\n    ax2.grid(True)\n    \n    plt.suptitle('Visualisasi Metrik Pelatihan', fontsize=20, y=1.02)\n    plt.tight_layout()\n    \n\ndef plot_confusion_matrix(y_true, y_pred, class_names):\n    \"\"\"\n    Fungsi untuk menampilkan confusion matrix.\n    \"\"\"\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(8, 6))\n    heatmap = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                          xticklabels=class_names, yticklabels=class_names)\n    heatmap.set_xlabel('Predicted Class', fontsize=12, labelpad=10)\n    heatmap.set_ylabel('True Class', fontsize=12, labelpad=10)\n    heatmap.set_title('Confusion Matrix', fontsize=16, pad=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T03:48:44.637290Z","iopub.execute_input":"2025-08-18T03:48:44.637591Z","iopub.status.idle":"2025-08-18T03:48:45.404340Z","shell.execute_reply.started":"2025-08-18T03:48:44.637571Z","shell.execute_reply":"2025-08-18T03:48:45.403729Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass FocalLoss(nn.Module):\n    \"\"\"\n    Implementasi Focal Loss yang stabil secara numerik.\n    \n    Focal Loss = -alpha * (1 - pt) ** gamma * log(pt)\n    \n    di mana pt adalah probabilitas dari kelas yang benar.\n    \"\"\"\n    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n        \"\"\"\n        Args:\n            alpha (Tensor, opsional): Tensor bobot untuk setiap kelas. \n                                     Bentuknya [num_classes].\n            gamma (float, opsional): Parameter pemfokusan. Default: 2.0.\n            reduction (str, opsional): 'mean', 'sum', atau 'none'. Default: 'mean'.\n        \"\"\"\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        \"\"\"\n        Args:\n            inputs (Tensor): Prediksi logits dari model (sebelum softmax). \n                             Bentuknya [batch_size, num_classes].\n            targets (Tensor): Label kelas yang sebenarnya (ground truth). \n                              Bentuknya [batch_size].\n        \"\"\"\n        # Hitung log probabilitas (lebih stabil dari softmax + log)\n        log_pt = F.log_softmax(inputs, dim=1)\n        \n        # Dapatkan log probabilitas dari kelas yang benar\n        log_pt = log_pt.gather(1, targets.view(-1, 1))\n        log_pt = log_pt.view(-1)\n        \n        # Hitung probabilitas (pt) dari log probabilitas\n        pt = log_pt.exp()\n\n        # Jika alpha (bobot kelas) diberikan\n        if self.alpha is not None:\n            # Pastikan alpha berada di device yang sama dengan target\n            if self.alpha.type() != targets.data.type():\n                self.alpha = self.alpha.type_as(targets.data)\n            \n            # Pilih bobot alpha sesuai dengan target kelas\n            at = self.alpha.gather(0, targets.data)\n            \n            # Hitung cross entropy loss dengan bobot alpha\n            log_pt = log_pt * at\n\n        # Hitung loss utama\n        loss = -1 * (1 - pt) ** self.gamma * log_pt\n\n        # Terapkan reduksi (mean atau sum)\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        else:\n            return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T03:48:48.518633Z","iopub.execute_input":"2025-08-18T03:48:48.519535Z","iopub.status.idle":"2025-08-18T03:48:48.530376Z","shell.execute_reply.started":"2025-08-18T03:48:48.519500Z","shell.execute_reply":"2025-08-18T03:48:48.529573Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"#### (1) Training with early stopping - Recommended","metadata":{"id":"ILDzO2myN_Pg"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom collections import Counter\nfrom sklearn.utils.class_weight import compute_class_weight\nimport time\nimport os\n\n\n# Impor ClearML hanya jika diperlukan\nif USE_CLEARML:\n    from clearml import Task, Logger\n\n# ⚙️ Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel_name, model = create_model(\n    model_name=\"resnet50\", \n    num_classes=len(class_names), \n    feature_extract=False\n)\nmodel = model.to(device)\n\n# Configure optimizer\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.0005) # \n# Learning rate yang lebih besar untuk classifier head yang baru\nHEAD_LR = 0.001\n\n# Learning rate yang jauh lebih kecil untuk layer-layer pre-trained\nBASE_LR = 0.0001\noptimizer = create_optimizer(model)\n# Cek untuk memastikan LR sudah benar\nprint(f\"Optimizer setup:\")\nprint(f\"  - Learning rate untuk base model (features): {optimizer.param_groups[0]['lr']}\")\nprint(f\"  - Learning rate untuk classifier head: {optimizer.param_groups[1]['lr']}\")\n\n\n# Penanganan Dataset Tidak Seimbang\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(class_names),\n    y=class_names\n)\nweights = torch.tensor(class_weights, dtype=torch.float).to(device)\n# criterion = nn.CrossEntropyLoss(weight=weights)\ncriterion = FocalLoss(alpha=weights, gamma=2.0)\n\n# Kurangi LR saat val_loss tidak membaik\nscheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True)\n\n# 🔁 Pengaturan Training Loop\nepochs = 32\npatience = 4\ntrain_accs, val_accs = [], []\ntrain_losses, val_losses = [], []\nbest_val_acc = 0\nearly_stop_counter = 0\n\n# Penyimpanan Model\n# if USE_GOOGLE_COLAB:\n#     save_dir = \"/content/drive/MyDrive/AI_Models\"\n\nsave_dir = \"Models\"\nos.makedirs(save_dir, exist_ok=True)\nbest_model_path = os.path.join(save_dir, f\"{model_name}_best_model.pt\")\nlatest_model_path = os.path.join(save_dir, f\"{model_name}_latest_model.pt\")\n\n# Inisialisasi ClearML jika diaktifkan\nif USE_CLEARML:\n    task = Task.init(\n        project_name=\"EcoSort CNN\",\n        task_name=f\"{model_name} Training {time.strftime('%a, %b %-d, %Y - %H:%M:%S')}\",\n        task_type=Task.TaskTypes.training\n    )\n    logger = task.get_logger()\n\n# 🔍 Fungsi logging yang lebih fleksibel\ndef log_matplotlib_figure(fig, title, series, epoch):\n    if USE_CLEARML:\n        logger.report_matplotlib_figure(title=title, series=series, figure=fig, iteration=epoch)\n    plt.close(fig)\n\n# 🏃 Training dimulai\ntry:\n    for epoch in range(epochs):\n        start_time = time.time()\n        model.train()\n        train_loss, correct, total = 0, 0, 0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            correct += torch.sum(preds == labels)\n            total += labels.size(0)\n        train_acc = correct / total\n        train_loss_avg = train_loss / len(train_loader)\n        train_accs.append(train_acc.item()); train_losses.append(train_loss_avg)\n\n        if USE_CLEARML:\n            logger.report_scalar(\"Accuracy\", \"Train\", value=train_acc.item(), iteration=epoch)\n            logger.report_scalar(\"Loss\", \"Train\", value=train_loss_avg, iteration=epoch)\n            logger.report_scalar(\"LR\", \"Learning Rate\", value=optimizer.param_groups[0]['lr'], iteration=epoch)\n\n        # 🔍 Validasi\n        model.eval()\n        val_loss, correct, total = 0, 0, 0\n        y_true, y_pred = [], []\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, preds = torch.max(outputs, 1)\n                correct += torch.sum(preds == labels)\n                total += labels.size(0)\n                y_true.extend(labels.cpu().numpy()); y_pred.extend(preds.cpu().numpy())\n        val_acc = correct / total\n        val_loss_avg = val_loss / len(val_loader)\n        val_accs.append(val_acc.item()); val_losses.append(val_loss_avg)\n        scheduler.step(val_loss_avg)\n\n        if USE_CLEARML:\n            logger.report_scalar(\"Accuracy\", \"Validation\", value=val_acc.item(), iteration=epoch)\n            logger.report_scalar(\"Loss\", \"Validation\", value=val_loss_avg, iteration=epoch)\n\n            # Classification Report & Metrics\n            report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n            for class_name, metrics in report.items():\n                if isinstance(metrics, dict): # Hindari 'accuracy' yang bukan dict\n                    logger.report_scalar(f\"F1-Score/{class_name}\", \"Validation\", value=metrics[\"f1-score\"], iteration=epoch)\n\n            # Confusion Matrix\n            cm = confusion_matrix(y_true, y_pred)\n            fig_cm, ax = plt.subplots(figsize=(8, 8))\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)\n            ax.set_title(\"Confusion Matrix\")\n            ax.set_xlabel(\"Predicted Label\")\n            ax.set_ylabel(\"True Label\")\n            log_matplotlib_figure(fig_cm, \"Confusion Matrix\", \"Validation\", epoch)\n\n        print(f\"🔁 Epoch {epoch+1}/{epochs}\")\n        print(f\"  → Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n        print(f\"  → Train Loss: {train_loss_avg:.4f} | Val Loss: {val_loss_avg:.4f}\")\n\n\n        # Simpan model\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            early_stop_counter = 0\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"🏆 Model terbaik disimpan ke {best_model_path}\")\n        else:\n            early_stop_counter += 1\n            torch.save(model.state_dict(), latest_model_path)\n            print(f\"📦 Model terbaru disimpan ke {latest_model_path}\")\n            if early_stop_counter >= patience:\n                print(\"⏹️ Early stopping terpicu.\")\n                break\n\n        duration = time.time() - start_time\n        print(f\"⏱️ Waktu epoch: {duration:.2f} detik\")\n        if USE_CLEARML:\n            logger.report_scalar(\"Epoch Time (sec)\", \"Duration\", value=duration, iteration=epoch)\n\n        print()\n\nfinally:\n    # 🎉 Selesai\n    print(\"\\n=== Laporan Klasifikasi Akhir ===\")\n    print(classification_report(y_true, y_pred, target_names=class_names))\n    if USE_CLEARML and 'task' in locals():\n        print(\"Menutup task ClearML.\")\n        task.close()\n\n    if train_losses and val_losses and train_accs and val_accs:\n        plot_training_history(train_losses, val_losses, train_accs, val_accs)\n        plot_confusion_matrix(y_true, y_pred, class_names)\n        plt.show()\n    else:\n        print(\"Tidak ada data histori training untuk diplot.\")","metadata":{"id":"nUEZ24awJXcT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e66e0e79-af49-4c9d-fd30-2beef996dae5","trusted":true,"execution":{"iopub.status.busy":"2025-08-18T05:34:19.266721Z","iopub.execute_input":"2025-08-18T05:34:19.267694Z"}},"outputs":[{"name":"stdout","text":"Optimizer setup:\n  - Learning rate untuk base model (features): 0.0001\n  - Learning rate untuk classifier head: 0.001\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"#### (2) Training without early stopping","metadata":{"id":"RRpj1OvSsAMc"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom collections import Counter\nimport time\n\n# Transform\ntransform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\n# Dataset\ntrain_dataset = datasets.ImageFolder(\"dataset/train\", transform=transform)\nclass_names = train_dataset.classes\nprint(\"Label mapping:\", train_dataset.class_to_idx)\nprint(\"Distribusi:\", Counter([label for _, label in train_dataset]))\n\nval_dataset = datasets.ImageFolder(\"dataset/test\", transform=transform)\nprint(\"Label mapping:\", val_dataset.class_to_idx)\nprint(\"Distribusi:\", Counter([label for _, label in val_dataset]))\n\n# Split\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16)\n\n# Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.resnet18(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, len(class_names))\nmodel = model.to(device)\n\n# Loss & Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# Training\nepochs = 6\ntrain_accs, val_accs = [], []\nbest_val_acc = 0\n\nfor epoch in range(epochs):\n    model.train()\n    correct, total, loss_total = 0, 0, 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        loss_total += loss.item()\n        _, preds = torch.max(outputs, 1)\n        correct += torch.sum(preds == labels)\n        total += labels.size(0)\n\n    train_acc = correct / total\n    train_accs.append(train_acc.item())\n    print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.4f}\")\n\n    # Validasi\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            correct += torch.sum(preds == labels)\n            total += labels.size(0)\n\n    val_acc = correct / total\n    val_accs.append(val_acc.item())\n    print(f\"            → Val Acc: {val_acc:.4f}\")\n\n# Simpan\ntorch.save(model.state_dict(), \"model_cnn.pt\")\nprint(\"✅ Model disimpan.\")","metadata":{"id":"z04jGaYgsFLW"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluation","metadata":{"id":"OG66ezAGOKAn"}},{"cell_type":"code","source":"# 📊 Evaluasi dengan laporan & Confusion Matrix\nmodel.eval()\ny_true, y_pred = [], []\n\nfor images, labels in val_loader:\n    images = images.to(device)\n    outputs = model(images)\n    _, preds = torch.max(outputs, 1)\n\n    y_true.extend(labels.numpy())\n    y_pred.extend(preds.cpu().numpy())\n\nprint(\"\\n=== Classification Report ===\")\nprint(classification_report(y_true, y_pred, target_names=class_names))\n\n# Confusion Matrix\ncm = confusion_matrix(y_true, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# Plot akurasi training & val\nplt.plot(train_accs, label=\"Train\")\nplt.plot(val_accs, label=\"Validation\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.title(\"Train vs Validation Accuracy\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"id":"9wqOURnbONd4"},"outputs":[],"execution_count":null}]}