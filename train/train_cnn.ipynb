{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"include_colab_link":true},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/rediahmds/eco-sort/blob/main/train/train_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"## Connect to Google Drive","metadata":{"id":"Hi1UbGUd2K1n"}},{"cell_type":"code","source":"USE_CLEARML = False\nUSE_GOOGLE_COLAB = False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if USE_GOOGLE_COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\nelse:\n    !pip install PyDrive2\n\n    from pydrive2.auth import GoogleAuth\n    from pydrive2.drive import GoogleDrive\n\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    GCP_CLIENT_SECRET = user_secrets.get_secret(\"GCP_CLIENT_SECRET\")\n\n    with open(\"client_secrets.json\", \"w\") as f:\n        f.write(GCP_CLIENT_SECRET)\n\n\n    gauth = GoogleAuth()\n    gauth.CommandLineAuth()\n\n    drive = GoogleDrive(gauth)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htmo7u-i2J65","outputId":"eefefe31-2c91-4e31-8164-5a323fb19792","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T04:44:05.885042Z","iopub.execute_input":"2025-08-17T04:44:05.885737Z","iopub.status.idle":"2025-08-17T04:44:27.467460Z","shell.execute_reply.started":"2025-08-17T04:44:05.885701Z","shell.execute_reply":"2025-08-17T04:44:27.466654Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: PyDrive2 in /usr/local/lib/python3.11/dist-packages (1.21.3)\nRequirement already satisfied: google-api-python-client>=1.12.5 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (2.173.0)\nRequirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (4.1.3)\nRequirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (6.0.2)\nRequirement already satisfied: cryptography<44 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (43.0.3)\nRequirement already satisfied: pyOpenSSL<=24.2.1,>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (24.2.1)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44->PyDrive2) (1.17.1)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (0.22.0)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (2.40.3)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (1.34.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (4.2.0)\nRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->PyDrive2) (0.6.1)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->PyDrive2) (0.4.2)\nRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->PyDrive2) (4.9.1)\nRequirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->PyDrive2) (1.17.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44->PyDrive2) (2.22)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (1.70.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (3.20.3)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2.32.4)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.12.5->PyDrive2) (5.5.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=1.12.5->PyDrive2) (3.0.9)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2025.6.15)\nGo to the following link in your browser:\n\n    https://accounts.google.com/o/oauth2/auth?client_id=991309652978-hpmqspbdt0bccglf6iklc3er1d9naa8q.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=online&response_type=code\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter verification code:  4/1AVMBsJgC73mrKqFVsFAiZZhT0GeIR5GP05WJmNcvWhFaBr7QJG1d1CWyl3U\n"},{"name":"stdout","text":"Authentication successful.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Prepare dataset (Run only once)\n\nRun for the first time only. when starting new session, dont run it.","metadata":{"id":"HYavOwVuEkGf"}},{"cell_type":"markdown","source":"### Download","metadata":{"id":"oCK3f0-SFms6"}},{"cell_type":"code","source":"import shutil\nimport os\n\ndef copy_file_to_folder(source_path: str, destination_folder: str, preserve_metadata: bool = False):\n    \"\"\"\n    Copies a file to a specified folder, creating the folder if it doesn't exist.\n\n    Args:\n        source_path (str): The full path to the source file.\n        destination_folder (str): The path to the destination folder.\n        preserve_metadata (bool): If True, preserves file metadata (uses shutil.copy2).\n                                  Defaults to False.\n\n    Returns:\n        bool: True if the copy was successful, False otherwise.\n    \"\"\"\n    try:\n        # Create the destination folder if it doesn't exist\n        os.makedirs(destination_folder, exist_ok=True)\n\n        # Choose the copy function based on the preserve_metadata flag\n        if preserve_metadata:\n            shutil.copy2(source_path, destination_folder)\n        else:\n            shutil.copy(source_path, destination_folder)\n\n        print(f\"File '{source_path}' copied successfully to '{destination_folder}'. ✅\")\n\n        return True\n\n    except FileNotFoundError:\n        print(f\"Error: The source file was not found at '{source_path}'.\")\n        return False\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return False","metadata":{"id":"wGsUlIFaIND-","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T04:44:38.053138Z","iopub.execute_input":"2025-08-17T04:44:38.053890Z","iopub.status.idle":"2025-08-17T04:44:38.059477Z","shell.execute_reply.started":"2025-08-17T04:44:38.053858Z","shell.execute_reply":"2025-08-17T04:44:38.058922Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"if USE_GOOGLE_COLAB:\n    DATASET_PATH = \"/content/drive/MyDrive/Cool Lee Yeah/8th Semester/Skripsi/Datasets/dataset_no-styro.7z\"\n    copy_file_to_folder(DATASET_PATH, \"/content/\")\nelse:\n    GDRIVE_DATASET_FILE_ID = user_secrets.get_secret(\"GDRIVE_DATASET_FILE_ID\")\n    file_id = GDRIVE_DATASET_FILE_ID\n    local_filename = \"dataset.7z\" # save as\n\n    try:\n        file_to_download = drive.CreateFile({'id': file_id})\n\n        print(f\"⬇️ Downloading file: '{file_to_download['title']}'...\")\n        file_to_download.GetContentFile(local_filename)\n\n        print(f\"✅ Downloaded successfully and saved as '{local_filename}'\")\n\n    except Exception as e:\n        print(f\"Error: {e}\")","metadata":{"id":"3JmiaTh-JqS9","outputId":"a8853a9a-6860-4ca8-a233-e1dc6ff39815","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T04:44:55.836112Z","iopub.execute_input":"2025-08-17T04:44:55.836586Z","iopub.status.idle":"2025-08-17T04:45:19.037391Z","shell.execute_reply.started":"2025-08-17T04:44:55.836561Z","shell.execute_reply":"2025-08-17T04:45:19.036758Z"}},"outputs":[{"name":"stdout","text":"⬇️ Downloading file: 'dataset_no-styro.7z'...\n✅ Downloaded successfully and saved as 'dataset.7z'\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Extract the Dataset","metadata":{"id":"SNy902YmKCeq"}},{"cell_type":"code","source":"!7z x dataset.7z","metadata":{"id":"nt-XR1nuKIss","outputId":"b932b99f-dec0-4b18-9e94-4fec7d0512b1","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-17T04:46:11.130561Z","iopub.execute_input":"2025-08-17T04:46:11.131254Z","iopub.status.idle":"2025-08-17T04:47:18.675418Z","shell.execute_reply.started":"2025-08-17T04:46:11.131225Z","shell.execute_reply":"2025-08-17T04:47:18.674691Z"}},"outputs":[{"name":"stdout","text":"\n7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\np7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n\nScanning the drive for archives:\n  0M Sca        1 file, 1234923334 bytes (1178 MiB)\n\nExtracting archive: dataset.7z\n--\nPath = dataset.7z\nType = 7z\nPhysical Size = 1234923334\nHeaders Size = 178477\nMethod = LZMA2:24\nSolid = +\nBlocks = 1\n\n      0% 9 - dataset/train/background/0.jp                                        0% 582 - dataset/train/background/158.jp                                            0% 828 - dataset/train/background/38.j                                          0% 1211 - dataset/train/background/724.j                                            0% 1363 - dataset/train/background/861.j                                            1% 1532 - dataset/train/glass/Glass_113.jp                                              1% 1608 - dataset/train/glass/Glass_182.jp                                              2% 1650 - dataset/train/glass/Glass_22.j                                            2% 1725 - dataset/train/glass/Glass_288.jp                                              3% 1763 - dataset/train/glass/Glass_321.jp                                              3% 1836 - dataset/train/glass/Glass_388.jp                                              4% 1889 - dataset/train/glass/Glass_57.j                                            5% 1923 - dataset/train/glass/Glass_88.j                                            5% 2234 - dataset/train/glass/brown-glass371.j                                                  5% 2565 - dataset/train/glass/default_gla . age_bottles_0048__Image_175.pn                                                                              5% 2620 - dataset/train/glass/default_gla . age_bottles_0131__Image_193.pn                                                                              6% 2683 - dataset/train/glass/default_gla . age_bottles_0239__Image_250.pn                                                                              6% 2752 - dataset/train/glass/default_glas . c_containers_0108__Image_167.pn                                                                                6% 2831 - dataset/train/glass/default_glas . c_containers_0238__Image_230.pn                                                                                6% 2902 - dataset/train/glass/default_glass_food_jars_0097__Image_121.pn                                                                            7% 2967 - dataset/train/glass/default_glass_food_jars_0197__Image_202.pn                                                                            7% 3172 - dataset/train/glass/green-glass271.j                                                  7% 3304 - dataset/train/glass/green-glass395.j                                                  7% 3446 - dataset/train/glass/green-glass541.j                                                  7% 3619 - dataset/train/glass/real_world_ . erage_bottles_0088__Image_67.p                                                                              8% 3694 - dataset/train/glass/real_world_ . erage_bottles_0206__Image_17.p                                                                              8% 3775 - dataset/train/glass/real_worl . containers_0099__Image_51.pn                                                                          8% 3825 - dataset/train/glass/real_worl . containers_0188__Image_179.p                                                                          9% 3857 - dataset/train/glass/real_worl . containers_0243__Image_98.pn                                                                          9% 3932 - dataset/train/glass/real_world_glass_food_jars_0110__Image_59.pn                                                                              9% 4000 - dataset/train/glass/real_world_glass_food_jars_0205__Image_95.pn                                                                              9% 4039 - dataset/train/glass/white-glass112.j                                                  9% 4220 - dataset/train/glass/white-glass329.j                                                  9% 4339 - dataset/train/glass/white-glass467.j                                                 10% 4458 - dataset/train/glass/white-glass617.j                                                 10% 4617 - dataset/train/glass/white-glass91.jp                                                 10% 4673 - dataset/train/metal/Metal_145.jp                                             11% 4712 - dataset/train/metal/Metal_182.jp                                             11% 4776 - dataset/train/metal/Metal_242.jp                                             12% 4836 - dataset/train/metal/Metal_299.jp                                             12% 4898 - dataset/train/metal/Metal_357.jp                                             13% 4946 - dataset/train/metal/Metal_402.jp                                             13% 5000 - dataset/train/metal/Metal_454.jp                                             14% 5035 - dataset/train/metal/Metal_488.jp                                             14% 5102 - dataset/train/metal/Metal_55.j                                           15% 5135 - dataset/train/metal/Metal_580.jp                                             15% 5203 - dataset/train/metal/Metal_649.jp                                             16% 5239 - dataset/train/metal/Metal_682.jp                                             16% 5313 - dataset/train/metal/Metal_754.jp                                             17% 5353 - dataset/train/metal/Metal_8.jp                                           17% 5384 - dataset/train/metal/default_aerosol_cans_0014__Image_156.p                                                                       18% 5461 - dataset/train/metal/default_aerosol_cans_0141__Image_71.pn                                                                       18% 5538 - dataset/train/metal/default_aluminum_food_cans_0034__Image_245.p                                                                             18% 5614 - dataset/train/metal/default_aluminum_food_cans_0154__Image_246.p                                                                             18% 5684 - dataset/train/metal/default_aluminum_soda_cans_0019__Image_160.p                                                                             19% 5685 - dataset/train/metal/default_aluminum_soda_cans_0020__Image_120.p                                                                             19% 5754 - dataset/train/metal/default_aluminum_soda_cans_0125__Image_29.pn                                                                             19% 5827 - dataset/train/metal/default_aluminum_soda_cans_0238__Image_230.p                                                                             19% 5901 - dataset/train/metal/default_steel_food_cans_0134__Image_218.pn                                                                           20% 5977 - dataset/train/metal/metal108.j                                           20% 6013 - dataset/train/metal/metal140.j                                           20% 6265 - dataset/train/metal/metal372.j                                           20% 6285 - dataset/train/metal/metal391.j                                           20% 6547 - dataset/train/metal/metal645.j                                           21% 6702 - dataset/train/metal/metal98.jp                                           21% 6773 - dataset/train/metal/real_world_aerosol_cans_0119__Image_236.pn                                                                           21% 6809 - dataset/train/metal/real_world_aerosol_cans_0186__Image_242.pn                                                                           21% 6844 - dataset/train/metal/real_world . m_food_cans_0004__Image_37.pn                                                                           22% 6903 - dataset/train/metal/real_world . m_food_cans_0115__Image_142.p                                                                           22% 6968 - dataset/train/metal/real_world . m_food_cans_0239__Image_250.p                                                                           22% 7015 - dataset/train/metal/real_world . m_soda_cans_0059__Image_183.p                                                                           22% 7027 - dataset/train/metal/real_world . m_soda_cans_0080__Image_31.pn                                                                           23% 7084 - dataset/train/metal/real_world . m_soda_cans_0166__Image_10.pn                                                                           23% 7143 - dataset/train/metal/real_world . m_soda_cans_0243__Image_98.pn                                                                           23% 7186 - dataset/train/metal/real_world_steel_food_cans_0071__Image_82.pn                                                                             23% 7206 - dataset/train/metal/real_world_steel_food_cans_0110__Image_59.pn                                                                             24% 7274 - dataset/train/metal/real_world_steel_food_cans_0240__Image_36.pn                                                                             24% 7349 - dataset/train/organic/Food Organics_163.jp                                                       25% 7395 - dataset/train/organic/Food Organics_204.jp                                                       26% 7441 - dataset/train/organic/Food Organics_246.jp                                                       26% 7462 - dataset/train/organic/Food Organics_265.jp                                                       27% 7496 - dataset/train/organic/Food Organics_296.jp                                                       27% 7524 - dataset/train/organic/Food Organics_320.jp                                                       28% 7546 - dataset/train/organic/Food Organics_340.jp                                                       28% 7587 - dataset/train/organic/Food Organics_378.jp                                                       28% 7606 - dataset/train/organic/Food Organics_395.jp                                                       29% 7630 - dataset/train/organic/Food Organics_46.j                                                     30% 7681 - dataset/train/organic/Food Organics_93.j                                                     30% 7701 - dataset/train/organic/Vegetation_110.j                                                   30% 7721 - dataset/train/organic/Vegetation_129.j                                                   31% 7740 - dataset/train/organic/Vegetation_146.j                                                   31% 7760 - dataset/train/organic/Vegetation_164.j                                                   31% 7779 - dataset/train/organic/Vegetation_181.j                                                   32% 7798 - dataset/train/organic/Vegetation_199.j                                                   32% 7836 - dataset/train/organic/Vegetation_232.j                                                   33% 7877 - dataset/train/organic/Vegetation_27.jp                                                   34% 7920 - dataset/train/organic/Vegetation_308.j                                                   34% 7941 - dataset/train/organic/Vegetation_327.j                                                   34% 7963 - dataset/train/organic/Vegetation_347.j                                                   35% 8003 - dataset/train/organic/Vegetation_383.j                                                   36% 8046 - dataset/train/organic/Vegetation_421.j                                                   36% 8068 - dataset/train/organic/Vegetation_49.jp                                                   36% 8089 - dataset/train/organic/Vegetation_68.jp                                                   37% 8109 - dataset/train/organic/Vegetation_86.jp                                                   37% 8225 - dataset/train/organic/biological190.jp                                                   37% 8569 - dataset/train/organic/biological504.jp                                                   37% 8721 - dataset/train/organic/biological642.jp                                                   37% 8889 - dataset/train/organic/biological796.jp                                                   38% 9105 - dataset/train/organic/default_coffee_grounds_0014__Image_156.p                                                                           38% 9155 - dataset/train/organic/default_coffee_grounds_0107__Image_33.pn                                                                           38% 9164 - dataset/train/organic/default_coffee_grounds_0128__Image_231.p                                                                           38% 9205 - dataset/train/organic/default_coffee_grounds_0201__Image_53.pn                                                                           39% 9259 - dataset/train/organic/default_eggshells_0047__Image_200.pn                                                                       39% 9313 - dataset/train/organic/default_eggshells_0128__Image_231.pn                                                                       39% 9370 - dataset/train/organic/default_eggshells_0214__Image_68.p                                                                     40% 9425 - dataset/train/organic/default_food_waste_0047__Image_200.p                                                                       40% 9477 - dataset/train/organic/default_food_waste_0143__Image_178.p                                                                       40% 9528 - dataset/train/organic/default_tea_bags_0004__Image_37.pn                                                                     41% 9584 - dataset/train/organic/default_tea_bags_0095__Image_182.p                                                                     41% 9648 - dataset/train/organic/default_tea_bags_0182__Image_83.pn                                                                     41% 9761 - dataset/train/organic/organic_005205_photo.j                                                         41% 9819 - dataset/train/organic/organic_009003_photo.j                                                         42% 9925 - dataset/train/organic/real_world_coffee_grounds_0074__Image_212.pn                                                                               42% 9947 - dataset/train/organic/real_world_coffee_grounds_0107__Image_33.p                                                                             42% 9974 - dataset/train/organic/real_world_coffee_grounds_0155__Image_113.pn                                                                               42% 10024 - dataset/train/organic/real_world_coffee_grounds_0247__Image_60.pn                                                                               43% 10085 - dataset/train/organic/real_world_eggshells_0096__Image_194.pn                                                                           43% 10141 - dataset/train/organic/real_world_eggshells_0186__Image_242.pn                                                                           43% 10174 - dataset/train/organic/real_world_eggshells_0229__Image_240.pn                                                                           44% 10196 - dataset/train/organic/real_world_food_waste_0024__Image_217.p                                                                           44% 10247 - dataset/train/organic/real_world_food_waste_0131__Image_193.p                                                                           44% 10299 - dataset/train/organic/real_world_food_waste_0228__Image_239.p                                                                           44% 10354 - dataset/train/organic/real_world_tea_bags_0058__Image_5.p                                                                       45% 10386 - dataset/train/organic/real_world_tea_bags_0102__Image_247.p                                                                         45% 10410 - dataset/train/organic/real_world_tea_bags_0138__Image_129.p                                                                         45% 10474 - dataset/train/organic/real_world_tea_bags_0228__Image_239.p                                                                         46% 10508 - dataset/train/paper/Cardboard_117.j                                                 46% 10562 - dataset/train/paper/Cardboard_166.j                                                 47% 10627 - dataset/train/paper/Cardboard_224.j                                                 47% 10666 - dataset/train/paper/Cardboard_26.jp                                                 48% 10742 - dataset/train/paper/Cardboard_328.j                                                 48% 10779 - dataset/train/paper/Cardboard_361.j                                                 49% 10855 - dataset/train/paper/Cardboard_43.jp                                                 49% 10893 - dataset/train/paper/Cardboard_49.jp                                                 50% 10955 - dataset/train/paper/Paper_104.j                                             50% 10985 - dataset/train/paper/Paper_131.j                                             51% 11056 - dataset/train/paper/Paper_196.j                                             51% 11092 - dataset/train/paper/Paper_228.j                                             52% 11158 - dataset/train/paper/Paper_288.j                                             52% 11197 - dataset/train/paper/Paper_322.j                                             53% 11254 - dataset/train/paper/Paper_374.j                                             53% 11284 - dataset/train/paper/Paper_400.j                                             54% 11336 - dataset/train/paper/Paper_448.j                                             54% 11403 - dataset/train/paper/Paper_58.jp                                             55% 11436 - dataset/train/paper/Paper_88.jp                                             55% 11562 - dataset/train/paper/cardboard299.jp                                                 55% 11682 - dataset/train/paper/cardboard49.j                                               55% 11968 - dataset/train/paper/default_cardboard_boxes_0054__Image_28.pn                                                                           56% 12052 - dataset/train/paper/default_cardboard_boxes_0222__Image_72.pn                                                                           56% 12133 - dataset/train/paper/default_c . _packaging_0161__Image_206.pn                                                                           56% 12195 - dataset/train/paper/default_magazines_0018__Image_126.p                                                                     57% 12240 - dataset/train/paper/default_magazines_0088__Image_67.pn                                                                     57% 12325 - dataset/train/paper/default_magazines_0204__Image_52.pn                                                                     58% 12370 - dataset/train/paper/default_newspaper_0017__Image_103.p                                                                     58% 12371 - dataset/train/paper/default_newspaper_0018__Image_126.p                                                                     58% 12423 - dataset/train/paper/default_newspaper_0080__Image_31.pn                                                                     59% 12477 - dataset/train/paper/default_newspaper_0145__Image_134.p                                                                     59% 12527 - dataset/train/paper/default_newspaper_0208__Image_128.p                                                                     59% 12582 - dataset/train/paper/default_office_paper_0021__Image_13.p                                                                       59% 12583 - dataset/train/paper/default_office_paper_0022__Image_40.p                                                                       60% 12655 - dataset/train/paper/default_office_paper_0115__Image_142.pn                                                                         60% 12723 - dataset/train/paper/default_office_paper_0199__Image_151.pn                                                                         60% 12794 - dataset/train/paper/default_paper_cups_0029__Image_57.p                                                                     60% 12809 - dataset/train/paper/default_paper_cups_0059__Image_183.pn                                                                       61% 12869 - dataset/train/paper/default_paper_cups_0147__Image_173.pn                                                                       61% 12980 - dataset/train/paper/paper168.jp                                             61% 13024 - dataset/train/paper/paper262.jp                                             61% 13204 - dataset/train/paper/paper572.jp                                             61% 13233 - dataset/train/paper/paper652.jp                                             61% 13323 - dataset/train/paper/paper827.jp                                             62% 13429 - dataset/train/paper/real_world_cardboard_boxes_0010__Image_138.pn                                                                               62% 13488 - dataset/train/paper/real_world_cardboard_boxes_0102__Image_247.pn                                                                               62% 13495 - dataset/train/paper/real_world_cardboard_boxes_0111__Image_169.pn                                                                               62% 13568 - dataset/train/paper/real_world_cardboard_boxes_0222__Image_72.p                                                                             62% 13619 - dataset/train/paper/real_world_ . d_packaging_0046__Image_124.p                                                                             63% 13642 - dataset/train/paper/real_world . rd_packaging_0088__Image_67.pn                                                                             63% 13720 - dataset/train/paper/real_world_ . d_packaging_0202__Image_190.p                                                                             63% 13777 - dataset/train/paper/real_world_magazines_0035__Image_58.p                                                                       63% 13824 - dataset/train/paper/real_world_magazines_0096__Image_194.pn                                                                         64% 13867 - dataset/train/paper/real_world_magazines_0150__Image_79.p                                                                       64% 13903 - dataset/train/paper/real_world_magazines_0204__Image_52.p                                                                       64% 13929 - dataset/train/paper/real_world_magazines_0235__Image_4.pn                                                                       65% 13962 - dataset/train/paper/real_world_newspaper_0021__Image_13.p                                                                       65% 14016 - dataset/train/paper/real_world_newspaper_0083__Image_244.pn                                                                         65% 14032 - dataset/train/paper/real_world_newspaper_0105__Image_147.pn                                                                         65% 14071 - dataset/train/paper/real_world_newspaper_0150__Image_79.p                                                                       66% 14125 - dataset/train/paper/real_world_newspaper_0211__Image_141.pn                                                                         66% 14150 - dataset/train/paper/real_world_newspaper_0237__Image_237.pn                                                                         66% 14188 - dataset/train/paper/real_world_office_paper_0037__Image_25.pn                                                                           66% 14245 - dataset/train/paper/real_world_office_paper_0116__Image_32.pn                                                                           66% 14248 - dataset/train/paper/real_world_office_paper_0120__Image_143.p                                                                           67% 14312 - dataset/train/paper/real_world_office_paper_0208__Image_128.p                                                                           67% 14375 - dataset/train/paper/real_world_paper_cups_0038__Image_101.p                                                                         67% 14386 - dataset/train/paper/real_world_paper_cups_0051__Image_55.pn                                                                         67% 14451 - dataset/train/paper/real_world_paper_cups_0136__Image_222.p                                                                         67% 14487 - dataset/train/paper/real_world_paper_cups_0185__Image_107.p                                                                         68% 14526 - dataset/train/paper/real_world_paper_cups_0242__Image_161.p                                                                         68% 14593 - dataset/train/plastic/Plastic_156.j                                                 69% 14661 - dataset/train/plastic/Plastic_217.j                                                 69% 14697 - dataset/train/plastic/Plastic_250.j                                                 70% 14754 - dataset/train/plastic/Plastic_301.j                                                 71% 14808 - dataset/train/plastic/Plastic_350.j                                                 71% 14856 - dataset/train/plastic/Plastic_394.j                                                 72% 14911 - dataset/train/plastic/Plastic_443.j                                                 73% 14973 - dataset/train/plastic/Plastic_5.j                                               73% 15023 - dataset/train/plastic/Plastic_544.j                                                 74% 15078 - dataset/train/plastic/Plastic_594.j                                                 75% 15132 - dataset/train/plastic/Plastic_642.j                                                 75% 15185 - dataset/train/plastic/Plastic_690.j                                                 76% 15236 - dataset/train/plastic/Plastic_736.j                                                 77% 15290 - dataset/train/plastic/Plastic_785.j                                                 77% 15327 - dataset/train/plastic/Plastic_818.j                                                 78% 15395 - dataset/train/plastic/Plastic_88.jp                                                 78% 15428 - dataset/train/plastic/Plastic_909.j                                                 78% 15482 - dataset/train/plastic/default_plastic_cup_lids_0066__Image_227.pn                                                                               79% 15554 - dataset/train/plastic/default_plastic_cup_lids_0178__Image_38.p                                                                             79% 15650 - dataset/train/plastic/default . t_bottles_0090__Image_228.p                                                                         79% 15760 - dataset/train/plastic/defaul . ntainers_0008__Image_150.p                                                                       80% 15824 - dataset/train/plastic/default_p . od_containers_0125__Image_29.pn                                                                               80% 15888 - dataset/train/plastic/default_p . od_containers_0240__Image_36.pn                                                                               80% 15954 - dataset/train/plastic/default_p . hopping_bags_0096__Image_194.pn                                                                               81% 16026 - dataset/train/plastic/default_ . shopping_bags_0235__Image_4.pn                                                                             81% 16106 - dataset/train/plastic/default_ . soda_bottles_0141__Image_71.pn                                                                             82% 16219 - dataset/train/plastic/default_plastic_straws_0090__Image_228.pn                                                                             82% 16281 - dataset/train/plastic/default_plastic_straws_0191__Image_232.pn                                                                             82% 16340 - dataset/train/plastic/default . _trash_bags_0062__Image_11.pn                                                                           83% 16404 - dataset/train/plastic/default . _trash_bags_0201__Image_53.pn                                                                           83% 16481 - dataset/train/plastic/default_p . ater_bottles_0087__Image_210.pn                                                                               83% 16486 - dataset/train/plastic/default_p . ater_bottles_0092__Image_197.pn                                                                               84% 16555 - dataset/train/plastic/default_p . ater_bottles_0192__Image_94.p                                                                             84% 16634 - dataset/train/plastic/real_wor . ic_cup_lids_0082__Image_20.p                                                                           84% 16708 - dataset/train/plastic/real_wor . ic_cup_lids_0218__Image_211.pn                                                                             84% 16791 - dataset/train/plastic/real_wor . ent_bottles_0095__Image_182.pn                                                                             85% 16824 - dataset/train/plastic/real_wor . ent_bottles_0143__Image_178.pn                                                                             85% 16901 - dataset/train/plastic/real_wo . containers_0016__Image_137.pn                                                                           85% 16961 - dataset/train/plastic/real_wo . containers_0129__Image_86.p                                                                         85% 17018 - dataset/train/plastic/real_wo . containers_0231__Image_75.p                                                                         86% 17027 - dataset/train/plastic/real_worl . _shopping_bags_0003__Image_6.pn                                                                               86% 17090 - dataset/train/plastic/real_w . ping_bags_0109__Image_154.pn                                                                         86% 17146 - dataset/train/plastic/real_w . ping_bags_0206__Image_17.p                                                                       86% 17208 - dataset/train/plastic/real_worl . c_soda_bottles_0058__Image_5.pn                                                                               87% 17266 - dataset/train/plastic/real_worl . _soda_bottles_0166__Image_10.pn                                                                               87% 17326 - dataset/train/plastic/real_wo . tic_straws_0018__Image_126.pn                                                                           87% 17365 - dataset/train/plastic/real_world_plastic_straws_0084__Image_56.pn                                                                               88% 17383 - dataset/train/plastic/real_world_plastic_straws_0107__Image_33.pn                                                                               88% 17442 - dataset/train/plastic/real_wo . tic_straws_0203__Image_105.pn                                                                           88% 17497 - dataset/train/plastic/real_worl . c_trash_bags_0034__Image_245.pn                                                                               88% 17498 - dataset/train/plastic/real_worl . c_trash_bags_0036__Image_166.pn                                                                               89% 17558 - dataset/train/plastic/real_worl . c_trash_bags_0125__Image_29.p                                                                             89% 17621 - dataset/train/plastic/real_worl . c_trash_bags_0237__Image_237.pn                                                                               89% 17644 - dataset/train/plastic/real_w . r_bottles_0023__Image_69.p                                                                       89% 17676 - dataset/train/plastic/real_w . r_bottles_0069__Image_140.pn                                                                         89% 17736 - dataset/train/plastic/real_w . r_bottles_0163__Image_74.p                                                                       90% 17761 - dataset/train/plastic/real_w . r_bottles_0195__Image_26.p                                                                       90% 17794 - dataset/train/textiles/clothes1.j                                               90% 17935 - dataset/train/textiles/clothes1419.jp                                                   90% 18084 - dataset/train/textiles/clothes1866.jp                                                   91% 18153 - dataset/train/textiles/clothes2107.jp                                                   91% 18233 - dataset/train/textiles/clothes2349.jp                                                   91% 18379 - dataset/train/textiles/clothes2824.jp                                                   91% 18523 - dataset/train/textiles/clothes3295.jp                                                   92% 18603 - dataset/train/textiles/clothes352.j                                                 92% 18670 - dataset/train/textiles/clothes3761.jp                                                   92% 18815 - dataset/train/textiles/clothes4257.jp                                                   92% 18957 - dataset/train/textiles/clothes470.j                                                 93% 19052 - dataset/train/textiles/clothes5005.jp                                                   93% 19112 - dataset/train/textiles/clothes5180.jp                                                   93% 19267 - dataset/train/textiles/clothes914.j                                                 93% 19335 - dataset/train/textiles/default_clothing_0043__Image_208.p                                                                       94% 19389 - dataset/train/textiles/default_clothing_0099__Image_51.pn                                                                       94% 19443 - dataset/train/textiles/default_clothing_0154__Image_246.p                                                                       94% 19498 - dataset/train/textiles/default_clothing_0212__Image_8.p                                                                     95% 19556 - dataset/train/textiles/default_shoes_0023__Image_69.p                                                                   95% 19621 - dataset/train/textiles/default_shoes_0090__Image_228.pn                                                                     95% 19642 - dataset/train/textiles/default_shoes_0111__Image_169.pn                                                                     96% 19688 - dataset/train/textiles/default_shoes_0157__Image_48.p                                                                   96% 19752 - dataset/train/textiles/default_shoes_0222__Image_72.p                                                                   96% 19814 - dataset/train/textiles/real_world_clothing_0041__Image_39.p                                                                         96% 19857 - dataset/train/textiles/real_world_clothing_0093__Image_177.pn                                                                           97% 19891 - dataset/train/textiles/real_world_clothing_0129__Image_86.p                                                                         97% 19926 - dataset/train/textiles/real_world_clothing_0171__Image_34.p                                                                         97% 19981 - dataset/train/textiles/real_world_clothing_0233__Image_35.p                                                                         98% 20041 - dataset/train/textiles/real_world_shoes_0055__Image_102.p                                                                       98% 20104 - dataset/train/textiles/real_world_shoes_0126__Image_63.pn                                                                       98% 20155 - dataset/train/textiles/real_world_shoes_0193__Image_50.pn                                                                       98% 20166 - dataset/train/textiles/real_world_shoes_0206__Image_17.pn                                                                       98% 20319 - dataset/train/textiles/shoes1134.jp                                                 99% 20394 - dataset/train/textiles/shoes1230.jp                                                 99% 20486 - dataset/train/textiles/shoes1336.jp                                                 99% 20663 - dataset/train/textiles/shoes1553.jp                                                 99% 20776 - dataset/train/textiles/shoes1691.jp                                                 99% 20809 - dataset/train/textiles/shoes1727.jp                                                 99% 20956 - dataset/train/textiles/shoes1905.jp                                                 99% 21005 - dataset/train/textiles/shoes1967.jp                                                 99% 21094 - dataset/train/textiles/shoes287.j                                               99% 21239 - dataset/train/textiles/shoes461.j                                               99% 21379 - dataset/train/textiles/shoes621.j                                               99% 21514 - dataset/train/textiles/shoes78.jp                                               99% 21586 - dataset/train/textiles/shoes876.j                                              Everything is Ok\n\nFolders: 9\nFiles: 21677\nSize:       1247128906\nCompressed: 1234923334\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"Show directory tree","metadata":{"id":"of2TWdqofglL"}},{"cell_type":"markdown","source":"### Create Validation Dataset\n\nThis dataset will be created by moving some files from training dataset.","metadata":{"id":"Ml-cAB1aAMS1"}},{"cell_type":"code","source":"from pathlib import Path\nimport random\nfrom tqdm import tqdm\nimport shutil\n\nimport os\n\ndef count_files_in_folders(base_path):\n  \"\"\"\n  Counts the number of files in each subfolder of a given path.\n\n  Args:\n    base_path (str): The path to the parent directory (e.g., 'dataset/train').\n\n  Returns:\n    dict: A dictionary with subfolder names as keys and file counts as values.\n          Returns None if the path is not found.\n  \"\"\"\n  if not os.path.isdir(base_path):\n    print(f\"Error: Directory not found at '{base_path}'\")\n    return None\n\n  counts_per_class = {}\n  # Loop through each item in the base directory\n  for class_name in os.listdir(base_path):\n    class_path = os.path.join(base_path, class_name)\n    # Ensure it is a directory\n    if os.path.isdir(class_path):\n      # Count the number of files inside the subdirectory and store it\n      file_count = len(os.listdir(class_path))\n      counts_per_class[class_name] = file_count\n  return counts_per_class\n\ndef calculate_dataset_split(counts_per_class, percentage):\n  \"\"\"\n  Calculates the number of items per class for a split based on a percentage.\n  \"\"\"\n  if not 0 <= percentage <= 100:\n    raise ValueError(\"Percentage must be between 0 and 100.\")\n\n  split_counts_result = {}\n  for class_name, total_count in counts_per_class.items():\n    split_count = total_count * (percentage / 100)\n    # Round to the nearest integer as file counts cannot be fractional\n    split_counts_result[class_name] = round(split_count)\n  return split_counts_result\n\ndef move_validation_split_custom(train_dir, val_dir, per_class_counts: dict, random_select=True):\n    train_dir = Path(train_dir)\n    val_dir = Path(val_dir)\n    val_dir.mkdir(parents=True, exist_ok=True)\n\n    for class_name, n in per_class_counts.items():\n        class_dir = train_dir / class_name\n        if not class_dir.exists():\n            print(f\"⚠️ Folder tidak ditemukan: {class_dir}\")\n            continue\n\n        images = sorted([p for p in class_dir.glob(\"*.*\") if p.suffix.lower() in {'.jpg', '.jpeg', '.png'}])\n        selected = random.sample(images, min(n, len(images))) if random_select else images[:n]\n        val_class_dir = val_dir / class_name\n        val_class_dir.mkdir(parents=True, exist_ok=True)\n\n        print(f\"📁 {class_name}: Memindahkan {len(selected)} file...\")\n        for img in tqdm(selected, desc=f\"  Pindah {class_name}\", leave=False):\n            shutil.move(str(img), str(val_class_dir / img.name))\n\n    print(\"\\n✅ Selesai membuat validasi set proporsional.\")\n","metadata":{"id":"XqGECqIqAg-p","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T04:48:00.533273Z","iopub.execute_input":"2025-08-17T04:48:00.533974Z","iopub.status.idle":"2025-08-17T04:48:00.548599Z","shell.execute_reply.started":"2025-08-17T04:48:00.533937Z","shell.execute_reply":"2025-08-17T04:48:00.548077Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Divide Dataset\n\nThere are two methods for this, `StratifiedShuffle` and `train_test_split`","metadata":{"id":"c2PqRXewJeuF"}},{"cell_type":"code","source":"from torchvision import datasets\n\nDATASET_PATH = \"dataset/train\"\nfull_dataset = datasets.ImageFolder(DATASET_PATH)\nclass_names = full_dataset.classes","metadata":{"id":"P-XfE16hRTkO","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T04:52:34.096524Z","iopub.execute_input":"2025-08-17T04:52:34.096780Z","iopub.status.idle":"2025-08-17T04:52:34.149510Z","shell.execute_reply.started":"2025-08-17T04:52:34.096763Z","shell.execute_reply":"2025-08-17T04:52:34.148941Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"#### (1) Divide: Stratified Method","metadata":{"id":"_aWo6ngmJ67p"}},{"cell_type":"code","source":"from pathlib import Path\nfrom sklearn.model_selection import StratifiedShuffleSplit, train_test_split\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nimport shutil\nfrom tqdm import tqdm\n\ndef stratified_split_imagefolder(source_dir: Path | str,\n                                  target_train: Path | str,\n                                  target_val: Path | str,\n                                  val_ratio=0.2,\n                                  random_state=42):\n    source_dir = Path(source_dir)\n    target_train = Path(target_train)\n    target_val = Path(target_val)\n    target_train.mkdir(parents=True, exist_ok=True)\n    target_val.mkdir(parents=True, exist_ok=True)\n\n    transform = transforms.Compose([transforms.ToTensor()])\n    dataset = ImageFolder(str(source_dir), transform=transform)\n\n    paths = [Path(p) for p, _ in dataset.samples]\n    labels = [label for _, label in dataset.samples]\n    class_names = dataset.classes\n\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=val_ratio, random_state=random_state)\n    train_idx, val_idx = next(sss.split(paths, labels))\n\n    print(f\"📦 Total gambar: {len(paths)}\")\n    print(f\"✅ Train: {len(train_idx)}\")\n    print(f\"✅ Val  : {len(val_idx)}\")\n\n    def copy_split(index_list, target_root):\n        for idx in tqdm(index_list, desc=f\"Salin ke {target_root.name}\"):\n            src = paths[idx]\n            label_name = class_names[labels[idx]]\n            dest_dir = target_root / label_name\n            dest_dir.mkdir(parents=True, exist_ok=True)\n            shutil.copy(src, dest_dir / src.name)\n\n    copy_split(train_idx, target_train)\n    copy_split(val_idx, target_val)\n\n    print(\"✅ Stratified split selesai.\")\n","metadata":{"id":"HqOw6PC-SVXo","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:34:57.682300Z","iopub.execute_input":"2025-08-01T07:34:57.682801Z","iopub.status.idle":"2025-08-01T07:34:58.191992Z","shell.execute_reply.started":"2025-08-01T07:34:57.682777Z","shell.execute_reply":"2025-08-01T07:34:58.191415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stratified_split_imagefolder(\n    source_dir=\"dataset/train\",\n    target_train=\"dataset_stratified/train\",\n    target_val=\"dataset_stratified/test\",\n    val_ratio=0.2,\n    random_state=42\n)","metadata":{"id":"DpgKX4XNORyn","outputId":"245bfe34-7c14-40ce-e87f-dd5b640509de","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["📦 Total gambar: 22198\n","✅ Train: 17758\n","✅ Val  : 4440\n"]},{"output_type":"stream","name":"stderr","text":["Salin ke train: 100%|██████████| 17758/17758 [00:09<00:00, 1895.10it/s]\n","Salin ke test: 100%|██████████| 4440/4440 [00:01<00:00, 2892.72it/s]"]},{"output_type":"stream","name":"stdout","text":["✅ Stratified split selesai.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"execution_count":null},{"cell_type":"markdown","source":"#### (2) Divide: train_test_split","metadata":{"id":"4b3eMIiEKKJk"}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import datasets, transforms\nfrom collections import Counter\n\n\n\n\n# 🔁 Transformasi\n# Augmentasi\ntrain_transform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.RandomGrayscale(p=0.1),\n    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n# Transformasi untuk validasi/test tanpa augmentasi acak\nval_transform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\ntargets = full_dataset.targets\ntrain_idx, val_idx = train_test_split(\n    np.arange(len(targets)),      # Buat array dari index 0 sampai N-1\n    test_size=0.2,                # Alokasikan 20% untuk validasi\n    shuffle=True,\n    stratify=targets              # INI KUNCINYA: pastikan proporsi kelas sama\n)\n\n\ntrain_dataset = Subset(full_dataset, train_idx)\ntrain_dataset.dataset.transform = train_transform\n\nval_dataset = Subset(full_dataset, val_idx)\nval_dataset.dataset.transform = val_transform\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\nprint(f\"Total data: {len(full_dataset)} gambar\")\nprint(f\"Data Training: {len(train_dataset)} gambar\")\nprint(f\"Data Validasi: {len(val_dataset)} gambar\")\nprint(f\"Nama Kelas: {class_names}\")\n\ntrain_labels = [targets[i] for i in train_idx]\nprint(f\"Distribusi kelas di Training: {Counter(train_labels)}\")\n\nval_labels = [targets[i] for i in val_idx]\nprint(f\"Distribusi kelas di Validasi: {Counter(val_labels)}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfbdY9yfKUgt","outputId":"d0f00232-38c0-4f60-e0d6-d4c533fd05c6","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T04:52:39.789436Z","iopub.execute_input":"2025-08-17T04:52:39.789696Z","iopub.status.idle":"2025-08-17T04:52:39.814964Z","shell.execute_reply.started":"2025-08-17T04:52:39.789678Z","shell.execute_reply":"2025-08-17T04:52:39.814274Z"}},"outputs":[{"name":"stdout","text":"Total data: 21677 gambar\nData Training: 17341 gambar\nData Validasi: 4336 gambar\nNama Kelas: ['background', 'glass', 'metal', 'organic', 'paper', 'plastic', 'textiles']\nDistribusi kelas di Training: Counter({4: 3233, 6: 3114, 5: 2611, 3: 2568, 1: 2487, 2: 2122, 0: 1206})\nDistribusi kelas di Validasi: Counter({4: 809, 6: 778, 5: 653, 3: 642, 1: 622, 2: 531, 0: 301})\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Data Distribution checking","metadata":{"id":"NZwJYq_hH4zT"}},{"cell_type":"markdown","source":"## Training and Evaluation","metadata":{"id":"atrzVjhIJPyq"}},{"cell_type":"markdown","source":"#### Setup ClearML\n\nGo ahead and sign-up/sign-in to [AI Infrastructure Platform | Maximize AI Performance & Scalability | ClearML](https://clear.ml/)\n\nAfter that, go to Settings -> Workspace -> Create new credentials\n\nThe new credentials will be created and shows two options:\n\nLocal Python (Recommended)\nJupyter Notebook\nBoth actually are the same things, it only differs on how to use the new credentials.\n\nThis time, use the clearml CLI app to consume the credentials, when prompted, paste it.","metadata":{"id":"s6PsY9duJkpc"}},{"cell_type":"code","source":"!pip install clearml","metadata":{"id":"1MObF1_cNqbO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e959fcb4-4c4c-4ab7-aab5-244e36c391d4","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T04:49:22.457416Z","iopub.execute_input":"2025-08-17T04:49:22.457812Z","iopub.status.idle":"2025-08-17T04:49:27.227291Z","shell.execute_reply.started":"2025-08-17T04:49:22.457793Z","shell.execute_reply":"2025-08-17T04:49:27.226495Z"}},"outputs":[{"name":"stdout","text":"Collecting clearml\n  Downloading clearml-2.0.2-py2.py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (25.3.0)\nCollecting furl>=2.0.0 (from clearml)\n  Downloading furl-2.1.4-py2.py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (4.24.0)\nRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.11/dist-packages (from clearml) (1.26.4)\nCollecting pathlib2>=2.3.0 (from clearml)\n  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from clearml) (7.0.0)\nRequirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from clearml) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.9.0.post0)\nRequirement already satisfied: pyjwt<2.11.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.10.1)\nRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.11/dist-packages (from clearml) (6.0.2)\nRequirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (1.17.0)\nRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.5.0)\nRequirement already satisfied: Pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (11.2.1)\nRequirement already satisfied: referencing<0.40 in /usr/local/lib/python3.11/dist-packages (from clearml) (0.36.2)\nRequirement already satisfied: requests>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.32.4)\nCollecting orderedmultidict>=1.0.1 (from furl>=2.0.0->clearml)\n  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml) (2025.4.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml) (0.25.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (2.4.1)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing<0.40->clearml) (4.14.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.10->clearml) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.10->clearml) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.10->clearml) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.10->clearml) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.10->clearml) (2024.2.0)\nDownloading clearml-2.0.2-py2.py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading furl-2.1.4-py2.py3-none-any.whl (27 kB)\nDownloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\nDownloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: pathlib2, orderedmultidict, furl, clearml\nSuccessfully installed clearml-2.0.2 furl-2.1.4 orderedmultidict-1.0.1 pathlib2-2.3.7.post1\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"CLEARML_CONF = user_secrets.get_secret(\"CLEARML_CONF\")\n\n\nwith open(\"/root/clearml.conf\", \"w\") as f:\n    f.write(CLEARML_CONF)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:02:02.543762Z","iopub.execute_input":"2025-08-01T08:02:02.544414Z","iopub.status.idle":"2025-08-01T08:02:02.679335Z","shell.execute_reply.started":"2025-08-01T08:02:02.544386Z","shell.execute_reply":"2025-08-01T08:02:02.678790Z"},"id":"d1gbJSGZ1Z4b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!clearml-init","metadata":{"id":"TbVTxN62NtHk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"42518faa-461f-4c2d-fd90-33b5746a0466","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:04:10.593939Z","iopub.execute_input":"2025-08-01T08:04:10.594221Z","iopub.status.idle":"2025-08-01T08:04:15.812038Z","shell.execute_reply.started":"2025-08-01T08:04:10.594200Z","shell.execute_reply":"2025-08-01T08:04:15.811266Z"}},"outputs":[{"output_type":"stream","name":"stdout","text":["ClearML SDK setup process\n","\n","Please create new clearml credentials through the settings page in your `clearml-server` web app (e.g. http://localhost:8080//settings/workspace-configuration) \n","Or create a free account at https://app.clear.ml/settings/workspace-configuration\n","\n","In settings page, press \"Create new credentials\", then press \"Copy to clipboard\".\n","\n","Paste copied configuration here:\n","api {   # Redi Ahmad Supriyatna's workspace   web_server: https://app.clear.ml/   api_server: https://api.clear.ml   files_server: https://files.clear.ml   credentials {     \"access_key\" = \"XP018Y5KX0LBYJ9JY0LSA1F8BRATNJ\"     \"secret_key\" = \"Tt_arUNOmgaL3_VIsCUmPAHXGYRpY70dKLnyh7Vln6Ew5eRUHdeeU8ODfiEHoRd0kT8\"   } }\n","Detected credentials key=\"XP018Y5KX0LBYJ9JY0LSA1F8BRATNJ\" secret=\"Tt_a***\"\n","\n","ClearML Hosts configuration:\n","Web App: https://app.clear.ml/\n","API: https://api.clear.ml\n","File Store: https://files.clear.ml\n","\n","Verifying credentials ...\n","Credentials verified!\n","\n","New configuration stored in /root/clearml.conf\n","ClearML setup completed successfully.\n"]}],"execution_count":null},{"cell_type":"code","source":"!pip install torch torchvision matplotlib","metadata":{"id":"9Ry525mbBaZW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"21f5972d-0e61-4ed3-c39a-e5650c3c7ad9","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T04:49:37.389213Z","iopub.execute_input":"2025-08-17T04:49:37.389478Z","iopub.status.idle":"2025-08-17T04:50:45.481533Z","shell.execute_reply.started":"2025-08-17T04:49:37.389456Z","shell.execute_reply":"2025-08-17T04:50:45.480772Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"#@title <b>Time Out Preventer (Advanced) </b></strong>\n%%capture\nAUTO_RECONNECT = True #@param {type:\"boolean\"}\n#@markdown **Run this code to prevent Google Colab from Timeout**\nfrom os import makedirs\nmakedirs(\"/root/.config/rclone\", exist_ok = True)\nif AUTO_RECONNECT:\n  import IPython\n  from google.colab import output\n\n  display(IPython.display.Javascript('''\n  function ClickConnect(){\n    btn = document.querySelector(\"colab-connect-button\")\n    if (btn != null){\n      console.log(\"Click colab-connect-button\");\n      btn.click()\n      }\n\n    btn = document.getElementById('ok')\n    if (btn != null){\n      console.log(\"Click reconnect\");\n      btn.click()\n      }\n    }\n\n  setInterval(ClickConnect,60000)\n  '''))","metadata":{"id":"1B-wiSQryw5C"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"while True:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:06:17.949923Z","iopub.execute_input":"2025-08-01T08:06:17.950217Z","iopub.status.idle":"2025-08-01T08:08:02.367528Z","shell.execute_reply.started":"2025-08-01T08:06:17.950194Z","shell.execute_reply":"2025-08-01T08:08:02.366287Z"},"id":"FAHo8dPY1Z4d","outputId":"95a1a037-4257-4ca9-9837-d2cae90c3199"},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2044646855.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":null},{"cell_type":"markdown","source":"### Training Options (Choose one of these)","metadata":{"id":"kVvKfsV9rx3r"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\n\ndef create_model(model_name: str, num_classes: int, feature_extract: bool = True):\n    \"\"\"\n    Memuat pre-trained model dari torchvision menggunakan pendekatan hardcode yang andal\n    dan menyesuaikannya untuk transfer learning. ✅\n\n    Args:\n        model_name (str): Nama model yang didukung (contoh: 'resnet50', 'mobilenet_v3_small').\n        num_classes (int): Jumlah kelas output untuk dataset baru.\n        feature_extract (bool): Jika True, bekukan bobot kecuali layer terakhir.\n                              Jika False, seluruh model akan dilatih (fine-tuning).\n\n    Returns:\n        torch.nn.Module: Model yang sudah disesuaikan dan siap pakai.\n    \"\"\"\n\n    # --- Langkah 1: Tentukan model yang didukung secara eksplisit ---\n    # Pendekatan ini lebih aman dan mencegah error akibat penamaan yang tidak konsisten.\n    supported_models = {\n        # ResNet Family\n        \"resnet18\": (models.resnet18, models.ResNet18_Weights.DEFAULT),\n        \"resnet50\": (models.resnet50, models.ResNet50_Weights.DEFAULT),\n        # MobileNet Family\n        \"mobilenet_v2\": (models.mobilenet_v2, models.MobileNet_V2_Weights.DEFAULT),\n        \"mobilenet_v3_small\": (models.mobilenet_v3_small, models.MobileNet_V3_Small_Weights.DEFAULT),\n        \"mobilenet_v3_large\": (models.mobilenet_v3_large, models.MobileNet_V3_Large_Weights.DEFAULT),\n        # EfficientNet Family\n        \"efficientnet_b0\": (models.efficientnet_b0, models.EfficientNet_B0_Weights.DEFAULT),\n        \"efficientnet_b7\": (models.efficientnet_b7, models.EfficientNet_B7_Weights.DEFAULT),\n        # Other Architectures\n        \"vgg16\": (models.vgg16, models.VGG16_Weights.DEFAULT),\n        \"densenet121\": (models.densenet121, models.DenseNet121_Weights.DEFAULT),\n        \"vit_b_16\": (models.vit_b_16, models.ViT_B_16_Weights.DEFAULT),\n        \"swin_t\": (models.swin_t, models.Swin_T_Weights.DEFAULT),\n    }\n\n    if model_name not in supported_models:\n        raise ValueError(\n            f\"Model '{model_name}' tidak didukung.\\n\"\n            f\"Model yang tersedia: {list(supported_models.keys())}\"\n        )\n\n    # Ambil constructor dan bobot dari dictionary\n    model_constructor, weights = supported_models[model_name]\n\n    # Buat instance model dengan bobot pre-trained\n    model = model_constructor(weights=weights)\n\n    # --- Langkah 2: Membekukan Bobot (jika feature_extract=True) ---\n    if feature_extract:\n        for param in model.parameters():\n            param.requires_grad = False\n\n    # --- Langkah 3: Mengganti Layer Klasifikasi Terakhir ---\n    # Logika ini tetap sama karena sudah cukup robust\n    if hasattr(model, 'fc'): # Untuk ResNet, dll.\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, num_classes)\n\n    elif hasattr(model, 'classifier'):\n        if isinstance(model.classifier, nn.Sequential): # Untuk VGG, MobileNet, EfficientNet\n            last_layer = model.classifier[-1]\n            if isinstance(last_layer, nn.Linear):\n                num_ftrs = last_layer.in_features\n                model.classifier[-1] = nn.Linear(num_ftrs, num_classes)\n            else:\n                raise TypeError(f\"Layer terakhir dari classifier ({type(last_layer)}) bukan nn.Linear.\")\n        elif isinstance(model.classifier, nn.Linear): # Untuk DenseNet\n            num_ftrs = model.classifier.in_features\n            model.classifier = nn.Linear(num_ftrs, num_classes)\n        else:\n            raise TypeError(f\"Tipe classifier ({type(model.classifier)}) tidak didukung.\")\n\n    elif hasattr(model, 'head'): # Untuk Vision Transformer, Swin Transformer\n        num_ftrs = model.head.in_features\n        model.head = nn.Linear(num_ftrs, num_classes)\n\n    else:\n        raise NameError(f\"Layer klasifikasi untuk '{model_name}' tidak ditemukan.\")\n\n    return model","metadata":{"id":"GnSRiWhuqaNx","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T04:53:11.487450Z","iopub.execute_input":"2025-08-17T04:53:11.487715Z","iopub.status.idle":"2025-08-17T04:53:11.496888Z","shell.execute_reply.started":"2025-08-17T04:53:11.487697Z","shell.execute_reply":"2025-08-17T04:53:11.496338Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"#### (1) Training with early stopping - Recommended","metadata":{"id":"ILDzO2myN_Pg"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom collections import Counter\nfrom sklearn.utils.class_weight import compute_class_weight\nimport time\nimport os\n\n\n\n\n# Impor ClearML hanya jika diperlukan\nif USE_CLEARML:\n    from clearml import Task, Logger\n\n# ⚙️ Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nmodel = create_model(model_name=\"resnet50\", num_classes=len(class_names))\nmodel = model.to(device)\n\n# Penanganan Dataset Tidak Seimbang\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(class_names),\n    y=class_names\n)\nweights = torch.tensor(class_weights, dtype=torch.float).to(device)\ncriterion = nn.CrossEntropyLoss(weight=weights)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n\n# Kurangi LR saat val_loss tidak membaik\nscheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True)\n\n# 🔁 Pengaturan Training Loop\nepochs = 32\npatience = 5\ntrain_accs, val_accs = [], []\ntrain_losses, val_losses = [], []\nbest_val_acc = 0\nearly_stop_counter = 0\n\n# Penyimpanan Model\nmodel_name = model.__class__.__name__\n# if USE_GOOGLE_COLAB:\n#     save_dir = \"/content/drive/MyDrive/AI_Models\"\n\nsave_dir = \"Models\"\nos.makedirs(save_dir, exist_ok=True)\nbest_model_path = os.path.join(save_dir, f\"{model_name}_best_model.pt\")\nlatest_model_path = os.path.join(save_dir, f\"{model_name}_latest_model.pt\")\n\n# Inisialisasi ClearML jika diaktifkan\nif USE_CLEARML:\n    task = Task.init(\n        project_name=\"EcoSort CNN\",\n        task_name=f\"{model_name} Training {time.strftime('%a, %b %-d, %Y - %H:%M:%S')}\",\n        task_type=Task.TaskTypes.training\n    )\n    logger = task.get_logger()\n\n# 🔍 Fungsi logging yang lebih fleksibel\ndef log_matplotlib_figure(fig, title, series, epoch):\n    if USE_CLEARML:\n        logger.report_matplotlib_figure(title=title, series=series, figure=fig, iteration=epoch)\n    plt.close(fig)\n\n# 🏃 Training dimulai\ntry:\n    for epoch in range(epochs):\n        start_time = time.time()\n        model.train()\n        train_loss, correct, total = 0, 0, 0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            correct += torch.sum(preds == labels)\n            total += labels.size(0)\n        train_acc = correct / total\n        train_loss_avg = train_loss / len(train_loader)\n        train_accs.append(train_acc.item()); train_losses.append(train_loss_avg)\n\n        if USE_CLEARML:\n            logger.report_scalar(\"Accuracy\", \"Train\", value=train_acc.item(), iteration=epoch)\n            logger.report_scalar(\"Loss\", \"Train\", value=train_loss_avg, iteration=epoch)\n            logger.report_scalar(\"LR\", \"Learning Rate\", value=optimizer.param_groups[0]['lr'], iteration=epoch)\n\n        # 🔍 Validasi\n        model.eval()\n        val_loss, correct, total = 0, 0, 0\n        y_true, y_pred = [], []\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, preds = torch.max(outputs, 1)\n                correct += torch.sum(preds == labels)\n                total += labels.size(0)\n                y_true.extend(labels.cpu().numpy()); y_pred.extend(preds.cpu().numpy())\n        val_acc = correct / total\n        val_loss_avg = val_loss / len(val_loader)\n        val_accs.append(val_acc.item()); val_losses.append(val_loss_avg)\n        scheduler.step(val_loss_avg)\n\n        if USE_CLEARML:\n            logger.report_scalar(\"Accuracy\", \"Validation\", value=val_acc.item(), iteration=epoch)\n            logger.report_scalar(\"Loss\", \"Validation\", value=val_loss_avg, iteration=epoch)\n\n            # Classification Report & Metrics\n            report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n            for class_name, metrics in report.items():\n                if isinstance(metrics, dict): # Hindari 'accuracy' yang bukan dict\n                    logger.report_scalar(f\"F1-Score/{class_name}\", \"Validation\", value=metrics[\"f1-score\"], iteration=epoch)\n\n            # Confusion Matrix\n            cm = confusion_matrix(y_true, y_pred)\n            fig_cm, ax = plt.subplots(figsize=(8, 8))\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)\n            ax.set_title(\"Confusion Matrix\")\n            ax.set_xlabel(\"Predicted Label\")\n            ax.set_ylabel(\"True Label\")\n            log_matplotlib_figure(fig_cm, \"Confusion Matrix\", \"Validation\", epoch)\n\n        print(f\"🔁 Epoch {epoch+1}/{epochs}\")\n        print(f\"  → Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n        print(f\"  → Train Loss: {train_loss_avg:.4f} | Val Loss: {val_loss_avg:.4f}\")\n\n\n        # Simpan model\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            early_stop_counter = 0\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"🏆 Model terbaik disimpan ke {best_model_path}\")\n        else:\n            early_stop_counter += 1\n            torch.save(model.state_dict(), latest_model_path)\n            print(f\"📦 Model terbaru disimpan ke {latest_model_path}\")\n            if early_stop_counter >= patience:\n                print(\"⏹️ Early stopping terpicu.\")\n                break\n\n        duration = time.time() - start_time\n        print(f\"⏱️ Waktu epoch: {duration:.2f} detik\")\n        if USE_CLEARML:\n            logger.report_scalar(\"Epoch Time (sec)\", \"Duration\", value=duration, iteration=epoch)\n\n        print()\n\nfinally:\n    # 🎉 Selesai\n    print(\"\\n=== Laporan Klasifikasi Akhir ===\")\n    print(classification_report(y_true, y_pred, target_names=class_names))\n    if USE_CLEARML and 'task' in locals():\n        print(\"Menutup task ClearML.\")\n        task.close()","metadata":{"id":"nUEZ24awJXcT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e66e0e79-af49-4c9d-fd30-2beef996dae5","trusted":true,"execution":{"iopub.status.busy":"2025-08-17T05:28:02.430548Z","iopub.execute_input":"2025-08-17T05:28:02.431092Z","iopub.status.idle":"2025-08-17T05:40:45.916319Z","shell.execute_reply.started":"2025-08-17T05:28:02.431067Z","shell.execute_reply":"2025-08-17T05:40:45.915694Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 194MB/s]\n/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"🔁 Epoch 1/32\n  → Train Acc: 0.7690 | Val Acc: 0.8379\n  → Train Loss: 0.7165 | Val Loss: 0.4923\n🏆 Model terbaik disimpan ke Models/ResNet_best_model.pt\n⏱️ Waktu epoch: 75.79 detik\n\n🔁 Epoch 2/32\n  → Train Acc: 0.8342 | Val Acc: 0.8494\n  → Train Loss: 0.4946 | Val Loss: 0.5273\n🏆 Model terbaik disimpan ke Models/ResNet_best_model.pt\n⏱️ Waktu epoch: 75.68 detik\n\n🔁 Epoch 3/32\n  → Train Acc: 0.8509 | Val Acc: 0.8605\n  → Train Loss: 0.4385 | Val Loss: 0.4207\n🏆 Model terbaik disimpan ke Models/ResNet_best_model.pt\n⏱️ Waktu epoch: 75.74 detik\n\n🔁 Epoch 4/32\n  → Train Acc: 0.8533 | Val Acc: 0.8619\n  → Train Loss: 0.4203 | Val Loss: 0.4258\n🏆 Model terbaik disimpan ke Models/ResNet_best_model.pt\n⏱️ Waktu epoch: 75.61 detik\n\n🔁 Epoch 5/32\n  → Train Acc: 0.8622 | Val Acc: 0.8706\n  → Train Loss: 0.3948 | Val Loss: 0.3961\n🏆 Model terbaik disimpan ke Models/ResNet_best_model.pt\n⏱️ Waktu epoch: 76.11 detik\n\n🔁 Epoch 6/32\n  → Train Acc: 0.8699 | Val Acc: 0.8637\n  → Train Loss: 0.3760 | Val Loss: 0.3998\n📦 Model terbaru disimpan ke Models/ResNet_latest_model.pt\n⏱️ Waktu epoch: 76.24 detik\n\n🔁 Epoch 7/32\n  → Train Acc: 0.8729 | Val Acc: 0.8619\n  → Train Loss: 0.3677 | Val Loss: 0.4139\n📦 Model terbaru disimpan ke Models/ResNet_latest_model.pt\n⏱️ Waktu epoch: 76.53 detik\n\n🔁 Epoch 8/32\n  → Train Acc: 0.8747 | Val Acc: 0.8595\n  → Train Loss: 0.3588 | Val Loss: 0.5153\n📦 Model terbaru disimpan ke Models/ResNet_latest_model.pt\n⏱️ Waktu epoch: 75.93 detik\n\n🔁 Epoch 9/32\n  → Train Acc: 0.8796 | Val Acc: 0.8565\n  → Train Loss: 0.3420 | Val Loss: 0.5215\n📦 Model terbaru disimpan ke Models/ResNet_latest_model.pt\n⏱️ Waktu epoch: 77.49 detik\n\n🔁 Epoch 10/32\n  → Train Acc: 0.8808 | Val Acc: 0.8676\n  → Train Loss: 0.3421 | Val Loss: 0.4016\n📦 Model terbaru disimpan ke Models/ResNet_latest_model.pt\n⏹️ Early stopping terpicu.\n\n=== Laporan Klasifikasi Akhir ===\n              precision    recall  f1-score   support\n\n  background       1.00      0.99      0.99       301\n       glass       0.83      0.88      0.85       622\n       metal       0.86      0.76      0.81       531\n     organic       0.86      0.90      0.88       642\n       paper       0.88      0.85      0.86       809\n     plastic       0.76      0.78      0.77       653\n    textiles       0.95      0.95      0.95       778\n\n    accuracy                           0.87      4336\n   macro avg       0.88      0.87      0.87      4336\nweighted avg       0.87      0.87      0.87      4336\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"#### (2) Training without early stopping","metadata":{"id":"RRpj1OvSsAMc"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom collections import Counter\nimport time\n\n# Transform\ntransform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\n# Dataset\ntrain_dataset = datasets.ImageFolder(\"dataset/train\", transform=transform)\nclass_names = train_dataset.classes\nprint(\"Label mapping:\", train_dataset.class_to_idx)\nprint(\"Distribusi:\", Counter([label for _, label in train_dataset]))\n\nval_dataset = datasets.ImageFolder(\"dataset/test\", transform=transform)\nprint(\"Label mapping:\", val_dataset.class_to_idx)\nprint(\"Distribusi:\", Counter([label for _, label in val_dataset]))\n\n# Split\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16)\n\n# Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.resnet18(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, len(class_names))\nmodel = model.to(device)\n\n# Loss & Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# Training\nepochs = 6\ntrain_accs, val_accs = [], []\nbest_val_acc = 0\n\nfor epoch in range(epochs):\n    model.train()\n    correct, total, loss_total = 0, 0, 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        loss_total += loss.item()\n        _, preds = torch.max(outputs, 1)\n        correct += torch.sum(preds == labels)\n        total += labels.size(0)\n\n    train_acc = correct / total\n    train_accs.append(train_acc.item())\n    print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.4f}\")\n\n    # Validasi\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            correct += torch.sum(preds == labels)\n            total += labels.size(0)\n\n    val_acc = correct / total\n    val_accs.append(val_acc.item())\n    print(f\"            → Val Acc: {val_acc:.4f}\")\n\n# Simpan\ntorch.save(model.state_dict(), \"model_cnn.pt\")\nprint(\"✅ Model disimpan.\")","metadata":{"id":"z04jGaYgsFLW"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluation","metadata":{"id":"OG66ezAGOKAn"}},{"cell_type":"code","source":"# 📊 Evaluasi dengan laporan & Confusion Matrix\nmodel.eval()\ny_true, y_pred = [], []\n\nfor images, labels in val_loader:\n    images = images.to(device)\n    outputs = model(images)\n    _, preds = torch.max(outputs, 1)\n\n    y_true.extend(labels.numpy())\n    y_pred.extend(preds.cpu().numpy())\n\nprint(\"\\n=== Classification Report ===\")\nprint(classification_report(y_true, y_pred, target_names=class_names))\n\n# Confusion Matrix\ncm = confusion_matrix(y_true, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# Plot akurasi training & val\nplt.plot(train_accs, label=\"Train\")\nplt.plot(val_accs, label=\"Validation\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.title(\"Train vs Validation Accuracy\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"id":"9wqOURnbONd4"},"outputs":[],"execution_count":null}]}