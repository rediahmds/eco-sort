{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","include_colab_link":true},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/rediahmds/eco-sort/blob/main/train/train_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"## Connect to Google Drive","metadata":{"id":"Hi1UbGUd2K1n"}},{"cell_type":"code","source":"USE_GOOGLE_COLAB = False\n\nif USE_GOOGLE_COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\nelse:\n    !pip install PyDrive2\n\n    from pydrive2.auth import GoogleAuth\n    from pydrive2.drive import GoogleDrive\n\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    GCP_CLIENT_SECRET = user_secrets.get_secret(\"GCP_CLIENT_SECRET\")\n\n    with open(\"client_secrets.json\", \"w\") as f:\n        f.write(GCP_CLIENT_SECRET)\n\n\n    gauth = GoogleAuth()\n    gauth.CommandLineAuth()\n\n    drive = GoogleDrive(gauth)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htmo7u-i2J65","outputId":"fed6cb26-6063-4d5b-d3ab-9a59a507e3ca","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T09:32:27.591366Z","iopub.execute_input":"2025-08-01T09:32:27.592098Z","iopub.status.idle":"2025-08-01T09:32:56.057228Z","shell.execute_reply.started":"2025-08-01T09:32:27.592065Z","shell.execute_reply":"2025-08-01T09:32:56.056372Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: PyDrive2 in /usr/local/lib/python3.11/dist-packages (1.21.3)\nRequirement already satisfied: google-api-python-client>=1.12.5 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (2.173.0)\nRequirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (4.1.3)\nRequirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (6.0.2)\nRequirement already satisfied: cryptography<44 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (43.0.3)\nRequirement already satisfied: pyOpenSSL<=24.2.1,>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from PyDrive2) (24.2.1)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<44->PyDrive2) (1.17.1)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (0.22.0)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (2.40.3)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (1.34.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.5->PyDrive2) (4.2.0)\nRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->PyDrive2) (0.6.1)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->PyDrive2) (0.4.2)\nRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->PyDrive2) (4.9.1)\nRequirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client>=4.0.0->PyDrive2) (1.17.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<44->PyDrive2) (2.22)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (1.70.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (3.20.3)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2.32.4)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.12.5->PyDrive2) (5.5.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=1.12.5->PyDrive2) (3.0.9)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.5->PyDrive2) (2025.6.15)\nGo to the following link in your browser:\n\n    https://accounts.google.com/o/oauth2/auth?client_id=991309652978-hpmqspbdt0bccglf6iklc3er1d9naa8q.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=online&response_type=code\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter verification code:  4/1AVMBsJjo1BvxCy51gQF5v6h7e37YmgrTaTbal6M2Z9Dx6qYNSmqI0nc9YTA\n"},{"name":"stdout","text":"Authentication successful.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## Prepare dataset (Run only once)\n\nRun for the first time only. when starting new session, dont run it.","metadata":{"id":"HYavOwVuEkGf"}},{"cell_type":"markdown","source":"### Download","metadata":{"id":"oCK3f0-SFms6"}},{"cell_type":"code","source":"import shutil\nimport os\n\ndef copy_file_to_folder(source_path: str, destination_folder: str, preserve_metadata: bool = False):\n    \"\"\"\n    Copies a file to a specified folder, creating the folder if it doesn't exist.\n\n    Args:\n        source_path (str): The full path to the source file.\n        destination_folder (str): The path to the destination folder.\n        preserve_metadata (bool): If True, preserves file metadata (uses shutil.copy2).\n                                  Defaults to False.\n\n    Returns:\n        bool: True if the copy was successful, False otherwise.\n    \"\"\"\n    try:\n        # Create the destination folder if it doesn't exist\n        os.makedirs(destination_folder, exist_ok=True)\n\n        # Choose the copy function based on the preserve_metadata flag\n        if preserve_metadata:\n            shutil.copy2(source_path, destination_folder)\n        else:\n            shutil.copy(source_path, destination_folder)\n\n        print(f\"File '{source_path}' copied successfully to '{destination_folder}'. ✅\")\n\n        return True\n\n    except FileNotFoundError:\n        print(f\"Error: The source file was not found at '{source_path}'.\")\n        return False\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return False","metadata":{"id":"wGsUlIFaIND-"},"outputs":[],"execution_count":4},{"cell_type":"code","source":"if USE_GOOGLE_COLAB:\n    DATASET_PATH = \"/content/drive/MyDrive/Cool Lee Yeah/8th Semester/Skripsi/Datasets/dataset.7z\"\n    copy_file_to_folder(DATASET_PATH, \"/content/\")\nelse:\n    GDRIVE_DATASET_FILE_ID = user_secrets.get_secret(\"GDRIVE_DATASET_FILE_ID\")\n    file_id = GDRIVE_DATASET_FILE_ID\n    local_filename = \"dataset.7z\" # save as\n\n    try:\n        file_to_download = drive.CreateFile({'id': file_id})\n\n        print(f\"⬇️ Downloading file: '{file_to_download['title']}'...\")\n        file_to_download.GetContentFile(local_filename)\n\n        print(f\"✅ Downloaded successfully and saved as '{local_filename}'\")\n\n    except Exception as e:\n        print(f\"Error: {e}\")","metadata":{"id":"3JmiaTh-JqS9","outputId":"2820d032-1738-4f48-ac78-d2123c9eac85","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:31:15.226537Z","iopub.execute_input":"2025-08-01T07:31:15.227205Z","iopub.status.idle":"2025-08-01T07:31:43.840775Z","shell.execute_reply.started":"2025-08-01T07:31:15.227183Z","shell.execute_reply":"2025-08-01T07:31:43.840143Z"}},"outputs":[{"name":"stdout","text":"⬇️ Downloading file: 'dataset.7z'...\n✅ Downloaded successfully and saved as 'dataset.7z'\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Extract the Dataset","metadata":{"id":"SNy902YmKCeq"}},{"cell_type":"code","source":"!7z x dataset.7z","metadata":{"id":"nt-XR1nuKIss","outputId":"af8d9289-319b-4a4b-d226-c07c5ffada5e","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:41:48.473697Z","iopub.execute_input":"2025-08-01T08:41:48.474005Z","iopub.status.idle":"2025-08-01T08:42:58.982748Z","shell.execute_reply.started":"2025-08-01T08:41:48.473975Z","shell.execute_reply":"2025-08-01T08:42:58.981983Z"}},"outputs":[{"name":"stdout","text":"\n7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\np7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n\nScanning the drive for archives:\n  0M Sca        1 file, 1259629201 bytes (1202 MiB)\n\nExtracting archive: dataset.7z\n--\nPath = dataset.7z\nType = 7z\nPhysical Size = 1259629201\nHeaders Size = 183102\nMethod = LZMA2:24\nSolid = +\nBlocks = 1\n\n      0% 1        0% 583 - dataset/train/background/158.jp                                            0% 775 - dataset/train/background/330.jp                                            0% 1212 - dataset/train/background/724.j                                            0% 1339 - dataset/train/background/839.j                                            1% 1532 - dataset/train/glass/Glass_112.jp                                              1% 1600 - dataset/train/glass/Glass_174.jp                                              2% 1651 - dataset/train/glass/Glass_22.j                                            2% 1687 - dataset/train/glass/Glass_252.jp                                              3% 1764 - dataset/train/glass/Glass_321.jp                                              3% 1805 - dataset/train/glass/Glass_359.jp                                              4% 1865 - dataset/train/glass/Glass_412.jp                                              4% 1898 - dataset/train/glass/Glass_64.j                                            4% 1945 - dataset/train/glass/brown-glass107.j                                                  5% 2235 - dataset/train/glass/brown-glass371.j                                                  5% 2581 - dataset/train/glass/default_gla . age_bottles_0070__Image_205.pn                                                                              5% 2672 - dataset/train/glass/default_gl . rage_bottles_0216__Image_61.p                                                                            6% 2753 - dataset/train/glass/default_glas . c_containers_0108__Image_167.pn                                                                                6% 2832 - dataset/train/glass/default_glas . c_containers_0238__Image_230.pn                                                                                6% 2886 - dataset/train/glass/default_glass_food_jars_0066__Image_227.pn                                                                            6% 2929 - dataset/train/glass/default_glass_food_jars_0137__Image_219.pn                                                                            7% 2968 - dataset/train/glass/default_glass_food_jars_0197__Image_202.pn                                                                            7% 3175 - dataset/train/glass/green-glass273.j                                                  7% 3305 - dataset/train/glass/green-glass395.j                                                  7% 3459 - dataset/train/glass/green-glass554.j                                                  7% 3620 - dataset/train/glass/real_world_ . erage_bottles_0088__Image_67.p                                                                              8% 3695 - dataset/train/glass/real_world_ . erage_bottles_0206__Image_17.p                                                                              8% 3753 - dataset/train/glass/real_worl . containers_0065__Image_174.p                                                                          8% 3776 - dataset/train/glass/real_worl . containers_0099__Image_51.pn                                                                          8% 3858 - dataset/train/glass/real_worl . containers_0243__Image_98.pn                                                                          9% 3933 - dataset/train/glass/real_world_glass_food_jars_0110__Image_59.pn                                                                              9% 3988 - dataset/train/glass/real_world_glass_food_jars_0187__Image_49.pn                                                                              9% 4001 - dataset/train/glass/real_world_glass_food_jars_0205__Image_95.pn                                                                              9% 4160 - dataset/train/glass/white-glass252.j                                                  9% 4335 - dataset/train/glass/white-glass460.j                                                  9% 4370 - dataset/train/glass/white-glass502.j                                                  9% 4534 - dataset/train/glass/white-glass702.j                                                 10% 4639 - dataset/train/metal/Metal_111.jp                                             10% 4712 - dataset/train/metal/Metal_181.jp                                             11% 4747 - dataset/train/metal/Metal_214.jp                                             11% 4806 - dataset/train/metal/Metal_27.j                                           12% 4867 - dataset/train/metal/Metal_328.jp                                             12% 4900 - dataset/train/metal/Metal_358.jp                                             13% 4965 - dataset/train/metal/Metal_42.j                                           13% 5001 - dataset/train/metal/Metal_454.jp                                             14% 5069 - dataset/train/metal/Metal_518.jp                                             14% 5103 - dataset/train/metal/Metal_55.j                                           15% 5170 - dataset/train/metal/Metal_617.jp                                             15% 5205 - dataset/train/metal/Metal_65.j                                           16% 5279 - dataset/train/metal/Metal_720.jp                                             16% 5314 - dataset/train/metal/Metal_754.jp                                             17% 5384 - dataset/train/metal/default_aerosol_cans_0013__Image_198.p                                                                       17% 5462 - dataset/train/metal/default_aerosol_cans_0141__Image_71.pn                                                                       17% 5522 - dataset/train/metal/default_aluminum_food_cans_0000__Image_1.p                                                                           18% 5539 - dataset/train/metal/default_aluminum_food_cans_0034__Image_245.p                                                                             18% 5615 - dataset/train/metal/default_aluminum_food_cans_0154__Image_246.p                                                                             18% 5685 - dataset/train/metal/default_aluminum_soda_cans_0019__Image_160.p                                                                             18% 5755 - dataset/train/metal/default_aluminum_soda_cans_0125__Image_29.pn                                                                             19% 5756 - dataset/train/metal/default_aluminum_soda_cans_0126__Image_63.pn                                                                             19% 5828 - dataset/train/metal/default_aluminum_soda_cans_0238__Image_230.p                                                                             19% 5902 - dataset/train/metal/default_steel_food_cans_0134__Image_218.pn                                                                           19% 5981 - dataset/train/metal/metal110.j                                           20% 6014 - dataset/train/metal/metal140.j                                           20% 6266 - dataset/train/metal/metal372.j                                           20% 6284 - dataset/train/metal/metal39.jp                                           20% 6547 - dataset/train/metal/metal644.j                                           20% 6703 - dataset/train/metal/metal98.jp                                           20% 6774 - dataset/train/metal/real_world_aerosol_cans_0119__Image_236.pn                                                                           21% 6817 - dataset/train/metal/real_world_aerosol_cans_0200__Image_226.pn                                                                           21% 6845 - dataset/train/metal/real_world . m_food_cans_0004__Image_37.pn                                                                           21% 6904 - dataset/train/metal/real_world . m_food_cans_0115__Image_142.p                                                                           21% 6969 - dataset/train/metal/real_world . m_food_cans_0239__Image_250.p                                                                           22% 7023 - dataset/train/metal/real_world . m_soda_cans_0072__Image_16.pn                                                                           22% 7028 - dataset/train/metal/real_world . m_soda_cans_0080__Image_31.pn                                                                           22% 7085 - dataset/train/metal/real_world . m_soda_cans_0166__Image_10.pn                                                                           22% 7144 - dataset/train/metal/real_world . m_soda_cans_0243__Image_98.pn                                                                           23% 7189 - dataset/train/metal/real_world_steel_food_cans_0073__Image_155.p                                                                             23% 7207 - dataset/train/metal/real_world_steel_food_cans_0110__Image_59.pn                                                                             23% 7275 - dataset/train/metal/real_world_steel_food_cans_0240__Image_36.pn                                                                             24% 7350 - dataset/train/organic/Food Organics_163.jp                                                       25% 7396 - dataset/train/organic/Food Organics_204.jp                                                       25% 7442 - dataset/train/organic/Food Organics_246.jp                                                       26% 7463 - dataset/train/organic/Food Organics_265.jp                                                       26% 7484 - dataset/train/organic/Food Organics_284.jp                                                       27% 7504 - dataset/train/organic/Food Organics_301.jp                                                       27% 7525 - dataset/train/organic/Food Organics_320.jp                                                       27% 7547 - dataset/train/organic/Food Organics_340.jp                                                       28% 7588 - dataset/train/organic/Food Organics_378.jp                                                       28% 7607 - dataset/train/organic/Food Organics_395.jp                                                       28% 7631 - dataset/train/organic/Food Organics_46.j                                                     29% 7682 - dataset/train/organic/Food Organics_93.j                                                     29% 7702 - dataset/train/organic/Vegetation_110.j                                                   30% 7722 - dataset/train/organic/Vegetation_129.j                                                   30% 7741 - dataset/train/organic/Vegetation_146.j                                                   30% 7760 - dataset/train/organic/Vegetation_163.j                                                   31% 7779 - dataset/train/organic/Vegetation_180.j                                                   31% 7798 - dataset/train/organic/Vegetation_198.j                                                   31% 7817 - dataset/train/organic/Vegetation_214.j                                                   32% 7837 - dataset/train/organic/Vegetation_232.j                                                   32% 7878 - dataset/train/organic/Vegetation_27.jp                                                   33% 7921 - dataset/train/organic/Vegetation_308.j                                                   33% 7942 - dataset/train/organic/Vegetation_327.j                                                   34% 7963 - dataset/train/organic/Vegetation_346.j                                                   34% 7983 - dataset/train/organic/Vegetation_364.j                                                   35% 8026 - dataset/train/organic/Vegetation_402.j                                                   35% 8069 - dataset/train/organic/Vegetation_49.jp                                                   36% 8089 - dataset/train/organic/Vegetation_67.jp                                                   36% 8109 - dataset/train/organic/Vegetation_85.jp                                                   36% 8226 - dataset/train/organic/biological190.jp                                                   36% 8307 - dataset/train/organic/biological263.jp                                                   36% 8695 - dataset/train/organic/biological618.jp                                                   37% 8722 - dataset/train/organic/biological642.jp                                                   37% 8997 - dataset/train/organic/biological893.jp                                                   37% 9106 - dataset/train/organic/default_coffee_grounds_0014__Image_156.p                                                                           37% 9156 - dataset/train/organic/default_coffee_grounds_0107__Image_33.pn                                                                           37% 9206 - dataset/train/organic/default_coffee_grounds_0201__Image_53.pn                                                                           38% 9237 - dataset/train/organic/default_eggshells_0008__Image_150.pn                                                                       38% 9260 - dataset/train/organic/default_eggshells_0047__Image_200.pn                                                                       38% 9314 - dataset/train/organic/default_eggshells_0128__Image_231.pn                                                                       39% 9371 - dataset/train/organic/default_eggshells_0214__Image_68.p                                                                     39% 9426 - dataset/train/organic/default_food_waste_0047__Image_200.p                                                                       39% 9478 - dataset/train/organic/default_food_waste_0143__Image_178.p                                                                       39% 9529 - dataset/train/organic/default_tea_bags_0004__Image_37.pn                                                                     40% 9585 - dataset/train/organic/default_tea_bags_0095__Image_182.p                                                                     40% 9649 - dataset/train/organic/default_tea_bags_0182__Image_83.pn                                                                     40% 9691 - dataset/train/organic/organic_000243_photo.j                                                         41% 9820 - dataset/train/organic/organic_009003_photo.j                                                         41% 9886 - dataset/train/organic/real_world_coffee_grounds_0007__Image_85.p                                                                             41% 9926 - dataset/train/organic/real_world_coffee_grounds_0074__Image_212.pn                                                                               41% 9975 - dataset/train/organic/real_world_coffee_grounds_0155__Image_113.pn                                                                               41% 10025 - dataset/train/organic/real_world_coffee_grounds_0247__Image_60.pn                                                                               42% 10048 - dataset/train/organic/real_world_eggshells_0035__Image_58.p                                                                         42% 10086 - dataset/train/organic/real_world_eggshells_0096__Image_194.pn                                                                           42% 10142 - dataset/train/organic/real_world_eggshells_0186__Image_242.pn                                                                           42% 10197 - dataset/train/organic/real_world_food_waste_0024__Image_217.p                                                                           43% 10230 - dataset/train/organic/real_world_food_waste_0092__Image_197.p                                                                           43% 10248 - dataset/train/organic/real_world_food_waste_0131__Image_193.p                                                                           43% 10300 - dataset/train/organic/real_world_food_waste_0228__Image_239.p                                                                           44% 10355 - dataset/train/organic/real_world_tea_bags_0058__Image_5.p                                                                       44% 10411 - dataset/train/organic/real_world_tea_bags_0138__Image_129.p                                                                         44% 10434 - dataset/train/organic/real_world_tea_bags_0169__Image_109.p                                                                         44% 10481 - dataset/train/organic/real_world_tea_bags_0239__Image_250.p                                                                         45% 10539 - dataset/train/paper/Cardboard_144.j                                                 46% 10593 - dataset/train/paper/Cardboard_193.j                                                 46% 10666 - dataset/train/paper/Cardboard_259.j                                                 47% 10703 - dataset/train/paper/Cardboard_292.j                                                 47% 10780 - dataset/train/paper/Cardboard_361.j                                                 47% 10818 - dataset/train/paper/Cardboard_396.j                                                 48% 10856 - dataset/train/paper/Cardboard_43.jp                                                 48% 10920 - dataset/train/paper/Cardboard_72.jp                                                 49% 10956 - dataset/train/paper/Paper_104.j                                             49% 11021 - dataset/train/paper/Paper_163.j                                             50% 11057 - dataset/train/paper/Paper_196.j                                             50% 11094 - dataset/train/paper/Paper_229.j                                             51% 11166 - dataset/train/paper/Paper_294.j                                             51% 11198 - dataset/train/paper/Paper_322.j                                             52% 11259 - dataset/train/paper/Paper_378.j                                             52% 11309 - dataset/train/paper/Paper_422.j                                             53% 11364 - dataset/train/paper/Paper_472.j                                             53% 11404 - dataset/train/paper/Paper_58.jp                                             54% 11437 - dataset/train/paper/Paper_88.jp                                             54% 11563 - dataset/train/paper/cardboard299.jp                                                 54% 11837 - dataset/train/paper/cardboard725.jp                                                 54% 11969 - dataset/train/paper/default_cardboard_boxes_0054__Image_28.pn                                                                           55% 12053 - dataset/train/paper/default_cardboard_boxes_0222__Image_72.pn                                                                           55% 12134 - dataset/train/paper/default_c . _packaging_0161__Image_206.pn                                                                           55% 12196 - dataset/train/paper/default_magazines_0018__Image_126.p                                                                     56% 12241 - dataset/train/paper/default_magazines_0088__Image_67.pn                                                                     56% 12326 - dataset/train/paper/default_magazines_0204__Image_52.pn                                                                     57% 12371 - dataset/train/paper/default_newspaper_0017__Image_103.p                                                                     57% 12382 - dataset/train/paper/default_newspaper_0033__Image_76.pn                                                                     57% 12424 - dataset/train/paper/default_newspaper_0080__Image_31.pn                                                                     57% 12478 - dataset/train/paper/default_newspaper_0145__Image_134.p                                                                     58% 12528 - dataset/train/paper/default_newspaper_0208__Image_128.p                                                                     58% 12583 - dataset/train/paper/default_office_paper_0021__Image_13.p                                                                       58% 12584 - dataset/train/paper/default_office_paper_0022__Image_40.p                                                                       58% 12656 - dataset/train/paper/default_office_paper_0115__Image_142.pn                                                                         59% 12724 - dataset/train/paper/default_office_paper_0199__Image_151.pn                                                                         59% 12795 - dataset/train/paper/default_paper_cups_0029__Image_57.p                                                                     59% 12824 - dataset/train/paper/default_paper_cups_0083__Image_244.pn                                                                       59% 12870 - dataset/train/paper/default_paper_cups_0147__Image_173.pn                                                                       59% 12975 - dataset/train/paper/paper16.j                                           60% 12981 - dataset/train/paper/paper168.jp                                             60% 13150 - dataset/train/paper/paper486.jp                                             60% 13234 - dataset/train/paper/paper652.jp                                             60% 13293 - dataset/train/paper/paper754.jp                                             60% 13430 - dataset/train/paper/real_world_cardboard_boxes_0010__Image_138.pn                                                                               60% 13454 - dataset/train/paper/real_world_cardboard_boxes_0047__Image_200.pn                                                                               61% 13496 - dataset/train/paper/real_world_cardboard_boxes_0111__Image_169.pn                                                                               61% 13569 - dataset/train/paper/real_world_cardboard_boxes_0222__Image_72.p                                                                             61% 13589 - dataset/train/paper/real_world_ . d_packaging_0002__Image_221.p                                                                             61% 13643 - dataset/train/paper/real_world . rd_packaging_0088__Image_67.pn                                                                             62% 13721 - dataset/train/paper/real_world_ . d_packaging_0202__Image_190.p                                                                             62% 13778 - dataset/train/paper/real_world_magazines_0035__Image_58.p                                                                       62% 13822 - dataset/train/paper/real_world_magazines_0093__Image_177.pn                                                                         62% 13858 - dataset/train/paper/real_world_magazines_0139__Image_104.pn                                                                         63% 13869 - dataset/train/paper/real_world_magazines_0151__Image_42.p                                                                       63% 13915 - dataset/train/paper/real_world_magazines_0217__Image_47.p                                                                       63% 13963 - dataset/train/paper/real_world_newspaper_0021__Image_13.p                                                                       63% 14017 - dataset/train/paper/real_world_newspaper_0083__Image_244.pn                                                                         64% 14018 - dataset/train/paper/real_world_newspaper_0085__Image_168.pn                                                                         64% 14072 - dataset/train/paper/real_world_newspaper_0150__Image_79.p                                                                       64% 14126 - dataset/train/paper/real_world_newspaper_0211__Image_141.pn                                                                         64% 14127 - dataset/train/paper/real_world_newspaper_0212__Image_8.pn                                                                       65% 14189 - dataset/train/paper/real_world_office_paper_0037__Image_25.pn                                                                           65% 14217 - dataset/train/paper/real_world_office_paper_0072__Image_16.pn                                                                           65% 14248 - dataset/train/paper/real_world_office_paper_0119__Image_236.p                                                                           65% 14313 - dataset/train/paper/real_world_office_paper_0208__Image_128.p                                                                           65% 14318 - dataset/train/paper/real_world_office_paper_0214__Image_68.pn                                                                           66% 14386 - dataset/train/paper/real_world_paper_cups_0050__Image_201.p                                                                         66% 14438 - dataset/train/paper/real_world_paper_cups_0118__Image_185.p                                                                         66% 14452 - dataset/train/paper/real_world_paper_cups_0136__Image_222.p                                                                         66% 14520 - dataset/train/paper/real_world_paper_cups_0232__Image_27.pn                                                                         67% 14559 - dataset/train/plastic/Plastic_124.j                                                 67% 14628 - dataset/train/plastic/Plastic_187.j                                                 68% 14698 - dataset/train/plastic/Plastic_250.j                                                 68% 14730 - dataset/train/plastic/Plastic_28.jp                                                 69% 14781 - dataset/train/plastic/Plastic_325.j                                                 70% 14835 - dataset/train/plastic/Plastic_374.j                                                 70% 14882 - dataset/train/plastic/Plastic_416.j                                                 71% 14943 - dataset/train/plastic/Plastic_471.j                                                 72% 14998 - dataset/train/plastic/Plastic_520.j                                                 72% 15049 - dataset/train/plastic/Plastic_567.j                                                 73% 15107 - dataset/train/plastic/Plastic_619.j                                                 73% 15160 - dataset/train/plastic/Plastic_667.j                                                 74% 15212 - dataset/train/plastic/Plastic_713.j                                                 75% 15262 - dataset/train/plastic/Plastic_759.j                                                 75% 15296 - dataset/train/plastic/Plastic_79.jp                                                 76% 15362 - dataset/train/plastic/Plastic_849.j                                                 76% 15396 - dataset/train/plastic/Plastic_88.jp                                                 77% 15436 - dataset/train/plastic/Plastic_915.j                                                 77% 15484 - dataset/train/plastic/default_plastic_cup_lids_0069__Image_140.pn                                                                               77% 15556 - dataset/train/plastic/default_plastic_cup_lids_0179__Image_209.pn                                                                               78% 15652 - dataset/train/plastic/default . t_bottles_0091__Image_144.p                                                                         78% 15761 - dataset/train/plastic/defaul . ntainers_0008__Image_150.p                                                                       78% 15825 - dataset/train/plastic/default_p . od_containers_0125__Image_29.pn                                                                               79% 15889 - dataset/train/plastic/default_p . od_containers_0240__Image_36.pn                                                                               79% 15955 - dataset/train/plastic/default_p . hopping_bags_0096__Image_194.pn                                                                               79% 16026 - dataset/train/plastic/default_p . hopping_bags_0234__Image_62.p                                                                             80% 16091 - dataset/train/plastic/default_p . oda_bottles_0106__Image_106.p                                                                             80% 16220 - dataset/train/plastic/default_plastic_straws_0090__Image_228.pn                                                                             81% 16282 - dataset/train/plastic/default_plastic_straws_0191__Image_232.pn                                                                             81% 16341 - dataset/train/plastic/default . _trash_bags_0062__Image_11.pn                                                                           81% 16405 - dataset/train/plastic/default . _trash_bags_0201__Image_53.pn                                                                           81% 16482 - dataset/train/plastic/default_p . ater_bottles_0087__Image_210.pn                                                                               82% 16511 - dataset/train/plastic/default_p . ater_bottles_0127__Image_64.p                                                                             82% 16556 - dataset/train/plastic/default_p . ater_bottles_0192__Image_94.p                                                                             82% 16635 - dataset/train/plastic/real_wor . ic_cup_lids_0082__Image_20.p                                                                           82% 16709 - dataset/train/plastic/real_wor . ic_cup_lids_0218__Image_211.pn                                                                             83% 16740 - dataset/train/plastic/real_wor . ent_bottles_0015__Image_108.pn                                                                             83% 16808 - dataset/train/plastic/real_wor . ent_bottles_0119__Image_236.pn                                                                             83% 16902 - dataset/train/plastic/real_wo . containers_0016__Image_137.pn                                                                           83% 16962 - dataset/train/plastic/real_wo . containers_0129__Image_86.p                                                                         84% 17027 - dataset/train/plastic/real_w . ping_bags_0002__Image_221.pn                                                                         84% 17057 - dataset/train/plastic/real_w . ping_bags_0048__Image_175.pn                                                                         84% 17091 - dataset/train/plastic/real_w . ping_bags_0109__Image_154.pn                                                                         84% 17147 - dataset/train/plastic/real_w . ping_bags_0206__Image_17.p                                                                       85% 17209 - dataset/train/plastic/real_worl . c_soda_bottles_0058__Image_5.pn                                                                               85% 17267 - dataset/train/plastic/real_worl . _soda_bottles_0166__Image_10.pn                                                                               85% 17311 - dataset/train/plastic/real_worl . _soda_bottles_0243__Image_98.pn                                                                               86% 17328 - dataset/train/plastic/real_wo . tic_straws_0020__Image_120.pn                                                                           86% 17383 - dataset/train/plastic/real_wo . tic_straws_0105__Image_147.pn                                                                           86% 17443 - dataset/train/plastic/real_wo . tic_straws_0203__Image_105.pn                                                                           86% 17498 - dataset/train/plastic/real_worl . c_trash_bags_0034__Image_245.pn                                                                               87% 17513 - dataset/train/plastic/real_worl . c_trash_bags_0054__Image_28.p                                                                             87% 17559 - dataset/train/plastic/real_worl . c_trash_bags_0125__Image_29.p                                                                             87% 17622 - dataset/train/plastic/real_worl . c_trash_bags_0237__Image_237.pn                                                                               87% 17650 - dataset/train/plastic/real_w . r_bottles_0030__Image_248.pn                                                                         87% 17678 - dataset/train/plastic/real_w . r_bottles_0071__Image_82.p                                                                       88% 17737 - dataset/train/plastic/real_w . r_bottles_0163__Image_74.p                                                                       88% 17795 - dataset/train/styrofoam/default_styrofoam_cups_0001__Image_213.pn                                                                               88% 17881 - dataset/train/styrofoam/default_styrofoam_cups_0170__Image_111.pn                                                                               89% 17979 - dataset/train/styrofoam/defau . _containers_0123__Image_97.pn                                                                           89% 18059 - dataset/train/styrofoam/real_w . rofoam_cups_0037__Image_25.p                                                                           89% 18140 - dataset/train/styrofoam/real_w . rofoam_cups_0184__Image_130.pn                                                                             90% 18224 - dataset/train/styrofoam/real_wo . d_containers_0086__Image_15.p                                                                             90% 18313 - dataset/train/styrofoam/real_wo . d_containers_0240__Image_36.p                                                                             90% 18454 - dataset/train/textiles/clothes1415.jp                                                   90% 18455 - dataset/train/textiles/clothes1416.jp                                                   91% 18602 - dataset/train/textiles/clothes1859.jp                                                   91% 18753 - dataset/train/textiles/clothes2345.jp                                                   91% 18898 - dataset/train/textiles/clothes281.j                                                 92% 19042 - dataset/train/textiles/clothes3288.jp                                                   92% 19043 - dataset/train/textiles/clothes329.j                                                 92% 19190 - dataset/train/textiles/clothes3756.jp                                                   92% 19333 - dataset/train/textiles/clothes424.j                                                 92% 19475 - dataset/train/textiles/clothes4682.jp                                                   93% 19476 - dataset/train/textiles/clothes4691.jp                                                   93% 19632 - dataset/train/textiles/clothes5178.jp                                                   93% 19784 - dataset/train/textiles/clothes905.j                                                 93% 19825 - dataset/train/textiles/default_clothing_0009__Image_180.p                                                                       94% 19889 - dataset/train/textiles/default_clothing_0077__Image_114.p                                                                       94% 19911 - dataset/train/textiles/default_clothing_0099__Image_51.pn                                                                       94% 19964 - dataset/train/textiles/default_clothing_0153__Image_123.p                                                                       95% 20020 - dataset/train/textiles/default_clothing_0212__Image_8.p                                                                     95% 20076 - dataset/train/textiles/default_shoes_0021__Image_13.p                                                                   95% 20143 - dataset/train/textiles/default_shoes_0090__Image_228.pn                                                                     96% 20209 - dataset/train/textiles/default_shoes_0156__Image_220.pn                                                                     96% 20265 - dataset/train/textiles/default_shoes_0213__Image_146.pn                                                                     96% 20273 - dataset/train/textiles/default_shoes_0221__Image_127.pn                                                                     96% 20335 - dataset/train/textiles/real_world_clothing_0040__Image_2.pn                                                                         97% 20393 - dataset/train/textiles/real_world_clothing_0107__Image_33.p                                                                         97% 20446 - dataset/train/textiles/real_world_clothing_0169__Image_109.pn                                                                           97% 20489 - dataset/train/textiles/real_world_clothing_0219__Image_207.pn                                                                           97% 20502 - dataset/train/textiles/real_world_clothing_0232__Image_27.p                                                                         98% 20562 - dataset/train/textiles/real_world_shoes_0054__Image_28.pn                                                                       98% 20625 - dataset/train/textiles/real_world_shoes_0125__Image_29.pn                                                                       98% 20687 - dataset/train/textiles/real_world_shoes_0205__Image_95.pn                                                                       98% 20688 - dataset/train/textiles/real_world_shoes_0206__Image_17.pn                                                                       98% 20881 - dataset/train/textiles/shoes1185.jp                                                 99% 20906 - dataset/train/textiles/shoes1218.jp                                                 99% 21024 - dataset/train/textiles/shoes1354.jp                                                 99% 21195 - dataset/train/textiles/shoes1564.jp                                                 99% 21287 - dataset/train/textiles/shoes1677.jp                                                 99% 21349 - dataset/train/textiles/shoes1748.jp                                                 99% 21502 - dataset/train/textiles/shoes1939.jp                                                 99% 21523 - dataset/train/textiles/shoes1962.jp                                                 99% 21637 - dataset/train/textiles/shoes315.j                                               99% 21782 - dataset/train/textiles/shoes484.j                                               99% 21915 - dataset/train/textiles/shoes638.j                                               99% 22048 - dataset/train/textiles/shoes796.j                                               99% 22118 - dataset/train/textiles/shoes888.j                                              Everything is Ok\n\nFolders: 10\nFiles: 22198\nSize:       1272375944\nCompressed: 1259629201\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"Show directory tree","metadata":{"id":"of2TWdqofglL"}},{"cell_type":"markdown","source":"### Create Validation Dataset\n\nThis dataset will be created by moving some files from training dataset.","metadata":{"id":"Ml-cAB1aAMS1"}},{"cell_type":"code","source":"from pathlib import Path\nimport random\nfrom tqdm import tqdm\nimport shutil\n\nimport os\n\ndef count_files_in_folders(base_path):\n  \"\"\"\n  Counts the number of files in each subfolder of a given path.\n\n  Args:\n    base_path (str): The path to the parent directory (e.g., 'dataset/train').\n\n  Returns:\n    dict: A dictionary with subfolder names as keys and file counts as values.\n          Returns None if the path is not found.\n  \"\"\"\n  if not os.path.isdir(base_path):\n    print(f\"Error: Directory not found at '{base_path}'\")\n    return None\n\n  counts_per_class = {}\n  # Loop through each item in the base directory\n  for class_name in os.listdir(base_path):\n    class_path = os.path.join(base_path, class_name)\n    # Ensure it is a directory\n    if os.path.isdir(class_path):\n      # Count the number of files inside the subdirectory and store it\n      file_count = len(os.listdir(class_path))\n      counts_per_class[class_name] = file_count\n  return counts_per_class\n\ndef calculate_dataset_split(counts_per_class, percentage):\n  \"\"\"\n  Calculates the number of items per class for a split based on a percentage.\n  \"\"\"\n  if not 0 <= percentage <= 100:\n    raise ValueError(\"Percentage must be between 0 and 100.\")\n\n  split_counts_result = {}\n  for class_name, total_count in counts_per_class.items():\n    split_count = total_count * (percentage / 100)\n    # Round to the nearest integer as file counts cannot be fractional\n    split_counts_result[class_name] = round(split_count)\n  return split_counts_result\n\ndef move_validation_split_custom(train_dir, val_dir, per_class_counts: dict, random_select=True):\n    train_dir = Path(train_dir)\n    val_dir = Path(val_dir)\n    val_dir.mkdir(parents=True, exist_ok=True)\n\n    for class_name, n in per_class_counts.items():\n        class_dir = train_dir / class_name\n        if not class_dir.exists():\n            print(f\"⚠️ Folder tidak ditemukan: {class_dir}\")\n            continue\n\n        images = sorted([p for p in class_dir.glob(\"*.*\") if p.suffix.lower() in {'.jpg', '.jpeg', '.png'}])\n        selected = random.sample(images, min(n, len(images))) if random_select else images[:n]\n        val_class_dir = val_dir / class_name\n        val_class_dir.mkdir(parents=True, exist_ok=True)\n\n        print(f\"📁 {class_name}: Memindahkan {len(selected)} file...\")\n        for img in tqdm(selected, desc=f\"  Pindah {class_name}\", leave=False):\n            shutil.move(str(img), str(val_class_dir / img.name))\n\n    print(\"\\n✅ Selesai membuat validasi set proporsional.\")\n","metadata":{"id":"XqGECqIqAg-p","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:34:25.457350Z","iopub.execute_input":"2025-08-01T07:34:25.458072Z","iopub.status.idle":"2025-08-01T07:34:25.473878Z","shell.execute_reply.started":"2025-08-01T07:34:25.458040Z","shell.execute_reply":"2025-08-01T07:34:25.473159Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Divide Dataset\n\nThere are two methods for this, `StratifiedShuffle` and `train_test_split`","metadata":{"id":"c2PqRXewJeuF"}},{"cell_type":"markdown","source":"#### (1) Divide: Stratified Method","metadata":{"id":"_aWo6ngmJ67p"}},{"cell_type":"code","source":"from torchvision import datasets\n\nDATASET_PATH = \"dataset/train\"\nfull_dataset = datasets.ImageFolder(DATASET_PATH)\nclass_names = full_dataset.classes","metadata":{"id":"P-XfE16hRTkO","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T09:33:14.803747Z","iopub.execute_input":"2025-08-01T09:33:14.804056Z","iopub.status.idle":"2025-08-01T09:33:14.858583Z","shell.execute_reply.started":"2025-08-01T09:33:14.804029Z","shell.execute_reply":"2025-08-01T09:33:14.857781Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from pathlib import Path\nfrom sklearn.model_selection import StratifiedShuffleSplit, train_test_split\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nimport shutil\nfrom tqdm import tqdm\n\ndef stratified_split_imagefolder(source_dir: Path | str,\n                                  target_train: Path | str,\n                                  target_val: Path | str,\n                                  val_ratio=0.2,\n                                  random_state=42):\n    source_dir = Path(source_dir)\n    target_train = Path(target_train)\n    target_val = Path(target_val)\n    target_train.mkdir(parents=True, exist_ok=True)\n    target_val.mkdir(parents=True, exist_ok=True)\n\n    transform = transforms.Compose([transforms.ToTensor()])\n    dataset = ImageFolder(str(source_dir), transform=transform)\n\n    paths = [Path(p) for p, _ in dataset.samples]\n    labels = [label for _, label in dataset.samples]\n    class_names = dataset.classes\n\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=val_ratio, random_state=random_state)\n    train_idx, val_idx = next(sss.split(paths, labels))\n\n    print(f\"📦 Total gambar: {len(paths)}\")\n    print(f\"✅ Train: {len(train_idx)}\")\n    print(f\"✅ Val  : {len(val_idx)}\")\n\n    def copy_split(index_list, target_root):\n        for idx in tqdm(index_list, desc=f\"Salin ke {target_root.name}\"):\n            src = paths[idx]\n            label_name = class_names[labels[idx]]\n            dest_dir = target_root / label_name\n            dest_dir.mkdir(parents=True, exist_ok=True)\n            shutil.copy(src, dest_dir / src.name)\n\n    copy_split(train_idx, target_train)\n    copy_split(val_idx, target_val)\n\n    print(\"✅ Stratified split selesai.\")\n","metadata":{"id":"HqOw6PC-SVXo","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:34:57.682300Z","iopub.execute_input":"2025-08-01T07:34:57.682801Z","iopub.status.idle":"2025-08-01T07:34:58.191992Z","shell.execute_reply.started":"2025-08-01T07:34:57.682777Z","shell.execute_reply":"2025-08-01T07:34:58.191415Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"stratified_split_imagefolder(\n    source_dir=\"dataset/train\",\n    target_train=\"dataset_stratified/train\",\n    target_val=\"dataset_stratified/test\",\n    val_ratio=0.2,\n    random_state=42\n)","metadata":{"id":"DpgKX4XNORyn","outputId":"245bfe34-7c14-40ce-e87f-dd5b640509de","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["📦 Total gambar: 22198\n","✅ Train: 17758\n","✅ Val  : 4440\n"]},{"output_type":"stream","name":"stderr","text":["Salin ke train: 100%|██████████| 17758/17758 [00:09<00:00, 1895.10it/s]\n","Salin ke test: 100%|██████████| 4440/4440 [00:01<00:00, 2892.72it/s]"]},{"output_type":"stream","name":"stdout","text":["✅ Stratified split selesai.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"execution_count":9},{"cell_type":"markdown","source":"#### (2) Divide: train_test_split","metadata":{"id":"4b3eMIiEKKJk"}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import datasets, transforms\nfrom collections import Counter\n\n\n\n\n# 🔁 Transformasi\n# Augmentasi\ntrain_transform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.RandomGrayscale(p=0.1),\n    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n# Transformasi untuk validasi/test tanpa augmentasi acak\nval_transform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\ntargets = full_dataset.targets\ntrain_idx, val_idx = train_test_split(\n    np.arange(len(targets)),      # Buat array dari index 0 sampai N-1\n    test_size=0.2,                # Alokasikan 20% untuk validasi\n    shuffle=True,\n    stratify=targets              # INI KUNCINYA: pastikan proporsi kelas sama\n)\n\n\ntrain_dataset = Subset(full_dataset, train_idx)\ntrain_dataset.dataset.transform = train_transform\n\nval_dataset = Subset(full_dataset, val_idx)\nval_dataset.dataset.transform = val_transform\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\nprint(f\"Total data: {len(full_dataset)} gambar\")\nprint(f\"Data Training: {len(train_dataset)} gambar\")\nprint(f\"Data Validasi: {len(val_dataset)} gambar\")\nprint(f\"Nama Kelas: {class_names}\")\n\ntrain_labels = [targets[i] for i in train_idx]\nprint(f\"Distribusi kelas di Training: {Counter(train_labels)}\")\n\nval_labels = [targets[i] for i in val_idx]\nprint(f\"Distribusi kelas di Validasi: {Counter(val_labels)}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfbdY9yfKUgt","outputId":"c964f9da-3f7c-4247-c392-2b376c494e42","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:44:34.321863Z","iopub.execute_input":"2025-08-01T08:44:34.322379Z","iopub.status.idle":"2025-08-01T08:44:34.345984Z","shell.execute_reply.started":"2025-08-01T08:44:34.322355Z","shell.execute_reply":"2025-08-01T08:44:34.345253Z"}},"outputs":[{"name":"stdout","text":"Total data: 22198 gambar\nData Training: 17758 gambar\nData Validasi: 4440 gambar\nNama Kelas: ['background', 'glass', 'metal', 'organic', 'paper', 'plastic', 'styrofoam', 'textiles']\nDistribusi kelas di Training: Counter({4: 3233, 7: 3114, 5: 2611, 3: 2568, 1: 2487, 2: 2122, 0: 1206, 6: 417})\nDistribusi kelas di Validasi: Counter({4: 809, 7: 778, 5: 653, 3: 642, 1: 622, 2: 531, 0: 301, 6: 104})\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"### Data Distribution checking","metadata":{"id":"NZwJYq_hH4zT"}},{"cell_type":"markdown","source":"## Training and Evaluation","metadata":{"id":"atrzVjhIJPyq"}},{"cell_type":"markdown","source":"#### Setup ClearML\n\nGo ahead and sign-up/sign-in to [AI Infrastructure Platform | Maximize AI Performance & Scalability | ClearML](https://clear.ml/)\n\nAfter that, go to Settings -> Workspace -> Create new credentials\n\nThe new credentials will be created and shows two options:\n\nLocal Python (Recommended)\nJupyter Notebook\nBoth actually are the same things, it only differs on how to use the new credentials.\n\nThis time, use the clearml CLI app to consume the credentials, when prompted, paste it.","metadata":{"id":"s6PsY9duJkpc"}},{"cell_type":"code","source":"!pip install clearml","metadata":{"id":"1MObF1_cNqbO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8cc5e643-32d2-463c-fbce-e73fbf1c80ae","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:36:54.933889Z","iopub.execute_input":"2025-08-01T07:36:54.934499Z","iopub.status.idle":"2025-08-01T07:36:59.766750Z","shell.execute_reply.started":"2025-08-01T07:36:54.934461Z","shell.execute_reply":"2025-08-01T07:36:59.765955Z"}},"outputs":[{"name":"stdout","text":"Collecting clearml\n  Downloading clearml-2.0.2-py2.py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (25.3.0)\nCollecting furl>=2.0.0 (from clearml)\n  Downloading furl-2.1.4-py2.py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (4.24.0)\nRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.11/dist-packages (from clearml) (1.26.4)\nCollecting pathlib2>=2.3.0 (from clearml)\n  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from clearml) (7.0.0)\nRequirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from clearml) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.9.0.post0)\nRequirement already satisfied: pyjwt<2.11.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.10.1)\nRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.11/dist-packages (from clearml) (6.0.2)\nRequirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (1.17.0)\nRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.5.0)\nRequirement already satisfied: Pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (11.2.1)\nRequirement already satisfied: referencing<0.40 in /usr/local/lib/python3.11/dist-packages (from clearml) (0.36.2)\nRequirement already satisfied: requests>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from clearml) (2.32.4)\nCollecting orderedmultidict>=1.0.1 (from furl>=2.0.0->clearml)\n  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml) (2025.4.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6.0->clearml) (0.25.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10->clearml) (2.4.1)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing<0.40->clearml) (4.14.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.0->clearml) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.10->clearml) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.10->clearml) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.10->clearml) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.10->clearml) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.10->clearml) (2024.2.0)\nDownloading clearml-2.0.2-py2.py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading furl-2.1.4-py2.py3-none-any.whl (27 kB)\nDownloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\nDownloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: pathlib2, orderedmultidict, furl, clearml\nSuccessfully installed clearml-2.0.2 furl-2.1.4 orderedmultidict-1.0.1 pathlib2-2.3.7.post1\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!ls /root","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:02:07.161857Z","iopub.execute_input":"2025-08-01T08:02:07.162146Z","iopub.status.idle":"2025-08-01T08:02:07.302978Z","shell.execute_reply.started":"2025-08-01T08:02:07.162121Z","shell.execute_reply":"2025-08-01T08:02:07.301958Z"}},"outputs":[{"name":"stdout","text":"clearml.conf  src\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"\nCLEARML_CONF = user_secrets.get_secret(\"CLEARML_CONF\")\n\n\nwith open(\"/root/clearml.conf\", \"w\") as f:\n    f.write(CLEARML_CONF)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:02:02.543762Z","iopub.execute_input":"2025-08-01T08:02:02.544414Z","iopub.status.idle":"2025-08-01T08:02:02.679335Z","shell.execute_reply.started":"2025-08-01T08:02:02.544386Z","shell.execute_reply":"2025-08-01T08:02:02.678790Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"!clearml-init","metadata":{"id":"TbVTxN62NtHk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"44110c88-0e89-48f0-f076-6f0cc8703856","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:04:10.593939Z","iopub.execute_input":"2025-08-01T08:04:10.594221Z","iopub.status.idle":"2025-08-01T08:04:15.812038Z","shell.execute_reply.started":"2025-08-01T08:04:10.594200Z","shell.execute_reply":"2025-08-01T08:04:15.811266Z"}},"outputs":[{"name":"stdout","text":"ClearML SDK setup process\nConfiguration file already exists: /root/clearml.conf\nLeaving setup, feel free to edit the configuration file.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"!pip install torch torchvision matplotlib","metadata":{"id":"9Ry525mbBaZW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"01ee5010-fb89-42bf-a22b-9f15e34d4340","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T07:49:28.147889Z","iopub.execute_input":"2025-08-01T07:49:28.148207Z","iopub.status.idle":"2025-08-01T07:50:38.444661Z","shell.execute_reply.started":"2025-08-01T07:49:28.148182Z","shell.execute_reply":"2025-08-01T07:50:38.443870Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"#@title <b>Time Out Preventer (Advanced) </b></strong>\n%%capture\nAUTO_RECONNECT = True #@param {type:\"boolean\"}\n#@markdown **Run this code to prevent Google Colab from Timeout**\nfrom os import makedirs\nmakedirs(\"/root/.config/rclone\", exist_ok = True)\nif AUTO_RECONNECT:\n  import IPython\n  from google.colab import output\n\n  display(IPython.display.Javascript('''\n  function ClickConnect(){\n    btn = document.querySelector(\"colab-connect-button\")\n    if (btn != null){\n      console.log(\"Click colab-connect-button\");\n      btn.click()\n      }\n\n    btn = document.getElementById('ok')\n    if (btn != null){\n      console.log(\"Click reconnect\");\n      btn.click()\n      }\n    }\n\n  setInterval(ClickConnect,60000)\n  '''))","metadata":{"id":"1B-wiSQryw5C"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"while True:\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T08:06:17.949923Z","iopub.execute_input":"2025-08-01T08:06:17.950217Z","iopub.status.idle":"2025-08-01T08:08:02.367528Z","shell.execute_reply.started":"2025-08-01T08:06:17.950194Z","shell.execute_reply":"2025-08-01T08:08:02.366287Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2044646855.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":38},{"cell_type":"markdown","source":"### Training Options (Choose one of these)","metadata":{"id":"kVvKfsV9rx3r"}},{"cell_type":"markdown","source":"#### (1) Training with early stopping - Recommended","metadata":{"id":"ILDzO2myN_Pg"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom collections import Counter\nfrom sklearn.utils.class_weight import compute_class_weight\nimport time\nimport os\nfrom clearml import Task, Logger, OutputModel\n\n\n# ⚙️ Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n# model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\nmodel = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n# model.fc = nn.Linear(model.fc.in_features, len(class_names))\n\n# model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.DEFAULT)\nmodel.classifier[0] = nn.Linear(in_features=model.classifier[0].in_features, out_features=len(class_names))\nmodel = model.to(device)\n\n# Inbalanced dataset\nclass_weights = compute_class_weight(class_weight='balanced',\n                                     classes=np.unique(class_names),\n                                     y=class_names)\n\nweights = torch.tensor(class_weights, dtype=torch.float).to(device)\ncriterion = nn.CrossEntropyLoss(weight=weights)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n\n# Reduce LR when val_loss not getting better\nscheduler = ReduceLROnPlateau(optimizer,\n                              mode=\"min\",\n                              factor=0.1,\n                              patience=2,\n                              verbose=True\n)\n\n# 🔁 Training loop\nepochs = 32\npatience = 5\ntrain_accs, val_accs = [], []\ntrain_losses, val_losses = [], []\nbest_val_acc = 0\nearly_stop_counter = 0\n\n# Model Storage\nmodel_name = model.__class__.__name__\nif USE_GOOGLE_COLAB:\n    best_model_path = f\"/content/drive/MyDrive/{model_name}_best_model.pt\"\n    latest_model_path = f\"/content/drive/MyDrive/{model_name}_latest_model.pt\"\n    os.makedirs(os.path.dirname(\"/content/drive/MyDrive/Cool Lee Yeah/8th Semester/Skripsi/AI Models\"), exist_ok=True)\nelse:\n    # os.makedirs(os.path.dirname(\"Models\"), exist_ok=True)\n    best_model_path = f\"Models/{model_name}_best_model.pt\"\n    latest_model_path = f\"Models/{model_name}_latest_model.pt\"\n\n# task = Task.init(\n#     project_name=\"EcoSort CNN\",\n#     task_name=f\"{model_name} Training {time.strftime('%a, %b %-d, %Y - %H:%M:%S')}\",\n#     task_type=Task.TaskTypes.training\n# )\n# logger = task.get_logger()\n\n# 🔍 Logging sample predictions\ndef log_predictions(images, labels, preds, class_names, epoch):\n    fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n    for i in range(min(5, len(images))):\n        img = images[i].cpu().permute(1, 2, 0) * 0.5 + 0.5  # unnormalize\n        axs[i].imshow(img.numpy())\n        axs[i].axis('off')\n        axs[i].set_title(f\"T: {class_names[labels[i]]}\\nP: {class_names[preds[i]]}\")\n    # logger.report_matplotlib_figure(title=\"Sample Predictions\", series=\"Validation\", figure=fig, iteration=epoch)\n    plt.close(fig)\n\n# 🏃 Training starts\ntry:\n  for epoch in range(epochs):\n      start_time = time.time()\n\n      model.train()\n      train_loss = 0\n      correct, total = 0, 0\n\n      for images, labels in train_loader:\n          images, labels = images.to(device), labels.to(device)\n          optimizer.zero_grad()\n          outputs = model(images)\n          loss = criterion(outputs, labels)\n          loss.backward()\n          optimizer.step()\n\n          train_loss += loss.item()\n          _, preds = torch.max(outputs, 1)\n          correct += torch.sum(preds == labels)\n          total += labels.size(0)\n\n      train_acc = correct / total\n      train_accs.append(train_acc.item())\n      train_losses.append(train_loss / len(train_loader))\n\n      # ClearML Logging (Train)\n      # logger.report_scalar(\"Accuracy\", \"Train\", value=train_acc.item(), iteration=epoch)\n      # logger.report_scalar(\"Loss\", \"Train\", value=train_loss / len(train_loader), iteration=epoch)\n      # logger.report_scalar(\"LR\", \"Learning Rate\", value=optimizer.param_groups[0]['lr'], iteration=epoch)\n\n      # 🔍 Validasi\n      model.eval()\n      val_loss = 0\n      correct, total = 0, 0\n      y_true, y_pred = [], []\n      last_batch_images, last_batch_labels, last_batch_preds = None, None, None\n\n      with torch.no_grad():\n          for images, labels in val_loader:\n              images, labels = images.to(device), labels.to(device)\n              outputs = model(images)\n              loss = criterion(outputs, labels)\n\n              val_loss += loss.item()\n              _, preds = torch.max(outputs, 1)\n              correct += torch.sum(preds == labels)\n              total += labels.size(0)\n\n              y_true.extend(labels.cpu().numpy())\n              y_pred.extend(preds.cpu().numpy())\n\n              last_batch_images = images\n              last_batch_labels = labels\n              last_batch_preds = preds\n\n      val_acc = correct / total\n      val_accs.append(val_acc.item())\n      val_loss_avg = val_loss / len(val_loader)\n      val_losses.append(val_loss_avg)\n\n      scheduler.step(val_loss_avg)\n\n      # ClearML Logging (Val)\n      # logger.report_scalar(\"Accuracy\", \"Validation\", value=val_acc.item(), iteration=epoch)\n      # logger.report_scalar(\"Loss\", \"Validation\", value=val_loss / len(val_loader), iteration=epoch)\n\n      # Classification Report\n      report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n      # for class_name in class_names:\n      #     logger.report_scalar(\"Precision\", class_name, value=report[class_name][\"precision\"], iteration=epoch)\n      #     logger.report_scalar(\"Recall\", class_name, value=report[class_name][\"recall\"], iteration=epoch)\n      #     logger.report_scalar(\"F1-Score\", class_name, value=report[class_name][\"f1-score\"], iteration=epoch)\n      # logger.report_scalar(\"F1-Score\", \"Macro Avg\", value=report[\"macro avg\"][\"f1-score\"], iteration=epoch)\n\n      # Confusion Matrix\n      cm = confusion_matrix(y_true, y_pred)\n      fig, ax = plt.subplots(figsize=(6, 6))\n      disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n      disp.plot(cmap=\"Blues\", ax=ax)\n      plt.title(\"Confusion Matrix\")\n      # logger.report_matplotlib_figure(title=\"Confusion Matrix\", series=\"Validation\", figure=fig, iteration=epoch)\n      plt.close(fig)\n\n      # Sample Prediction Logging\n      log_predictions(last_batch_images, last_batch_labels, last_batch_preds, class_names, epoch)\n      print(f\"🔁 Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.4f} - Val Acc: {val_acc:.4f}\")\n\n      # Save model\n      if val_acc >= best_val_acc:\n          best_val_acc = val_acc\n          early_stop_counter = 0\n          torch.save(model.state_dict(), best_model_path)\n          print(f\"🏆 (Best) Model saved\")\n\n      else:\n          torch.save(model.state_dict(), latest_model_path)\n          print(f\"📦 (Latest) Model saved\")\n          early_stop_counter += 1\n          if early_stop_counter >= patience:\n              print(\"⏹️ Early stopping triggered.\")\n              break\n\n      duration = time.time() - start_time\n      eta = (epochs - epoch - 1) * duration\n      print(f\"⏱️ Epoch time: Took {duration:.2f}s - ETA: ~{eta/60:.1f} min\")\n      # logger.report_scalar(\"Epoch Time (sec)\", \"Duration\", value=duration, iteration=epoch)\n      print(\"\\n\")\n\n  # 🎉 Done\n  print(\"=== Final Classification Report ===\")\n  print(classification_report(y_true, y_pred, target_names=class_names))\n\n  task.mark_completed()\n\nexcept Exception:\n    task.mark_failed()\n","metadata":{"id":"nUEZ24awJXcT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"71fe438f-dcb9-43cb-f159-6c8476678347","trusted":true,"execution":{"iopub.status.busy":"2025-08-01T09:34:27.364397Z","iopub.execute_input":"2025-08-01T09:34:27.365157Z","iopub.status.idle":"2025-08-01T09:34:27.676883Z","shell.execute_reply.started":"2025-08-01T09:34:27.365132Z","shell.execute_reply":"2025-08-01T09:34:27.675807Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n100%|██████████| 13.6M/13.6M [00:00<00:00, 131MB/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_248/3571075847.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.DEFAULT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'Dropout' object has no attribute 'in_features'"],"ename":"AttributeError","evalue":"'Dropout' object has no attribute 'in_features'","output_type":"error"}],"execution_count":23},{"cell_type":"markdown","source":"#### (2) Training without early stopping","metadata":{"id":"RRpj1OvSsAMc"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom collections import Counter\nimport time\n\n# Transform\ntransform = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\n# Dataset\ntrain_dataset = datasets.ImageFolder(\"dataset/train\", transform=transform)\nclass_names = train_dataset.classes\nprint(\"Label mapping:\", train_dataset.class_to_idx)\nprint(\"Distribusi:\", Counter([label for _, label in train_dataset]))\n\nval_dataset = datasets.ImageFolder(\"dataset/test\", transform=transform)\nprint(\"Label mapping:\", val_dataset.class_to_idx)\nprint(\"Distribusi:\", Counter([label for _, label in val_dataset]))\n\n# Split\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16)\n\n# Model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.resnet18(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, len(class_names))\nmodel = model.to(device)\n\n# Loss & Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# Training\nepochs = 6\ntrain_accs, val_accs = [], []\nbest_val_acc = 0\n\nfor epoch in range(epochs):\n    model.train()\n    correct, total, loss_total = 0, 0, 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        loss_total += loss.item()\n        _, preds = torch.max(outputs, 1)\n        correct += torch.sum(preds == labels)\n        total += labels.size(0)\n\n    train_acc = correct / total\n    train_accs.append(train_acc.item())\n    print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.4f}\")\n\n    # Validasi\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            correct += torch.sum(preds == labels)\n            total += labels.size(0)\n\n    val_acc = correct / total\n    val_accs.append(val_acc.item())\n    print(f\"            → Val Acc: {val_acc:.4f}\")\n\n# Simpan\ntorch.save(model.state_dict(), \"model_cnn.pt\")\nprint(\"✅ Model disimpan.\")","metadata":{"id":"z04jGaYgsFLW"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluation","metadata":{"id":"OG66ezAGOKAn"}},{"cell_type":"code","source":"# 📊 Evaluasi dengan laporan & Confusion Matrix\nmodel.eval()\ny_true, y_pred = [], []\n\nfor images, labels in val_loader:\n    images = images.to(device)\n    outputs = model(images)\n    _, preds = torch.max(outputs, 1)\n\n    y_true.extend(labels.numpy())\n    y_pred.extend(preds.cpu().numpy())\n\nprint(\"\\n=== Classification Report ===\")\nprint(classification_report(y_true, y_pred, target_names=class_names))\n\n# Confusion Matrix\ncm = confusion_matrix(y_true, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# Plot akurasi training & val\nplt.plot(train_accs, label=\"Train\")\nplt.plot(val_accs, label=\"Validation\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.title(\"Train vs Validation Accuracy\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"id":"9wqOURnbONd4"},"outputs":[],"execution_count":null}]}